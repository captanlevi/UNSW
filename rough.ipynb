{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from flowprintOptimal.sekigo.flowUtils.conversions import convertPacketRepToTimeslotRepEffecient\n",
    "from flowprintOptimal.sekigo.modeling.neuralNetworks import LSTMDuelingNetwork\n",
    "from flowprintOptimal.sekigo.core.flowRepresentation import PacketFlowRepressentation,TimeslotRepresentation\n",
    "from flowprintOptimal.sekigo.flowUtils.commons import getActivityArrayFromTimeslotRep, loadFlows\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from flowprintOptimal.sekigo.utils.documentor import Documenter\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from flowprintOptimal.sekigo.flowUtils.packetDropping import getPacketDroppedPacketDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.700439718141092"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log2(1/13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "packet_documenter = Documenter.load(\"vnat_ood\")\n",
    "timeslot_documenter = Documenter.load(\"vnat_timeslot_ood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<flowprintOptimal.sekigo.flowUtils.flowDatasets.DDQNActivityDataset at 0x75be207c2050>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeslot_documenter.train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packet_documenter.train_dataset[0][\"data\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2073.000000\n",
       "mean       13.051134\n",
       "std         2.567297\n",
       "min         8.000000\n",
       "25%        11.000000\n",
       "50%        15.000000\n",
       "75%        15.000000\n",
       "max        15.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(map(lambda x : len(x[\"data\"]), timeslot_documenter.train_dataset)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<flowprintOptimal.sekigo.core.flowRepresentation.TimeslotRepresentation at 0x75be20508220>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeslot_documenter.test_dataset.flows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedEval:\n",
    "    def __init__(self,packet_documenter : Documenter, timeslot_documenter : Documenter,device, threshold = .25):\n",
    "        self.packet_documenter = packet_documenter\n",
    "        self.timeslot_documenter = timeslot_documenter\n",
    "        self.threshold = threshold\n",
    "\n",
    "        self.packet_documenter.early_model.to(device)\n",
    "        self.timeslot_documenter.early_model.to(device)\n",
    "        self.grain = timeslot_documenter.train_dataset.flow_config.grain\n",
    "        self.band_threshold = timeslot_documenter.train_dataset.flow_config.band_thresholds\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "        self.rearrange_indices = np.array(CombinedEval.getRearrangingIndices(packet_documenter.train_dataset.label_to_index,timeslot_documenter.train_dataset.label_to_index))\n",
    "\n",
    "    @staticmethod\n",
    "    def getRearrangingIndices(src_dct,dst_dct):\n",
    "        assert len(src_dct) == len(dst_dct) \n",
    "        re_arrange = [None]*len(src_dct)\n",
    "\n",
    "        for key,index in src_dct.items():\n",
    "            re_arrange[index] = dst_dct[key]\n",
    "        \n",
    "        return re_arrange + [len(src_dct)]\n",
    "    \n",
    "\n",
    "    def __processSinglePrediction(self,prediction,num_classes):\n",
    "        \"\"\"\n",
    "        predictions are of shape (seq_len)\n",
    "        \"\"\"\n",
    "        # min_steps - 1 as if the min steps is 5 then after proccessing the 5th timestep index will be 4 !!!!\n",
    "        for time in range(self.min_steps -1,len(prediction)):\n",
    "            if prediction[time] < num_classes:\n",
    "                return (prediction[time],time + 1)\n",
    "        \n",
    "        return (-1,len(prediction))\n",
    "    \n",
    "    \n",
    "\n",
    "    def getConfidence(self,output):\n",
    "        \"\"\"\n",
    "        output is if shape (TS,num_classes)\n",
    "\n",
    "        returns maximal class and its score\n",
    "        \"\"\"\n",
    "        def softmax(x):\n",
    "            # x is of dim (TS,num_classes)\n",
    "            e_x = np.exp(x)\n",
    "            return e_x / e_x.sum(axis=1, keepdims = True)\n",
    "        confs = softmax(output[:,:-1])\n",
    "        return np.argmax(confs,axis = 1), np.max(confs, axis= 1)\n",
    "\n",
    "\n",
    "    def proccessPacketSlots(self,packet_out,timeslot_out,packet_nums):\n",
    "        def makeRangesFromPacketNums(packet_nums):\n",
    "            ranges = []\n",
    "            for packet_num in packet_nums:\n",
    "                if len(ranges) == 0:\n",
    "                    ranges.append((0,packet_num - 1))\n",
    "                else:\n",
    "                    start = ranges[-1][1] + 1\n",
    "                    ranges.append((start, start + packet_num - 1))\n",
    "            return ranges\n",
    "        \n",
    "        def processRange(packet_range_out, timeslot_index):\n",
    "            p_val = -1\n",
    "            p_conf = 0\n",
    "            ts_val, ts_conf = self.getConfidence(output= timeslot_out[timeslot_index:timeslot_index+1])\n",
    "            ts_val = self.rearrange_indices[ts_val]\n",
    "            packet_preds = np.argmax(packet_range_out, axis= 1)\n",
    "            max_p_conf,max_p_val = 0,-1\n",
    "            packets_used = 0\n",
    "\n",
    "            for i in range(len(packet_range_out)):\n",
    "                packets_used += 1\n",
    "                if packet_preds[i] != len(packet_range_out[0]) - 1:\n",
    "                    p_val,p_conf = self.getConfidence(output= packet_range_out[i:i+1])\n",
    "                    if max_p_conf < p_conf:\n",
    "                        max_p_conf = p_conf\n",
    "                        max_p_val = p_val\n",
    "\n",
    "                    assert p_val == packet_preds[i]\n",
    "                    \n",
    "                    if p_val != -1:\n",
    "                        # packet prediction is made\n",
    "                        if p_conf > self.threshold:\n",
    "                            return p_val.item(),packets_used\n",
    "\n",
    "\n",
    "\n",
    "            if max_p_val != -1:\n",
    "                if max_p_val == ts_val:\n",
    "                    #print(\"ts used\")\n",
    "                    return max_p_val.item(),packet_nums[timeslot_index]\n",
    "            \n",
    "            return -1,packet_nums[timeslot_index]\n",
    "                \n",
    "        ranges = makeRangesFromPacketNums(packet_nums= packet_nums)\n",
    "\n",
    "\n",
    "        output_prediction = -1\n",
    "        packets_taken = 0\n",
    "        for i,p_range in enumerate(ranges):\n",
    "            prediction,r_packet_taken = processRange(packet_out[p_range[0]:p_range[1]+1],i)\n",
    "            packets_taken += r_packet_taken\n",
    "            if prediction != -1:\n",
    "                output_prediction = prediction\n",
    "                break\n",
    "            \n",
    "\n",
    "        return output_prediction,packets_taken\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def infer(self,packet_flow_rep : PacketFlowRepressentation):\n",
    "        #class_type = self.packet_documenter.train_dataset.label_to_index[packet_flow_rep.class_type]\n",
    "        timeslot_rep : TimeslotRepresentation = convertPacketRepToTimeslotRepEffecient(packet_flow_rep= packet_flow_rep,grain= self.grain, band_thresholds=self.band_threshold)\n",
    "\n",
    "\n",
    "        if len(timeslot_rep) > 15:\n",
    "            timeslot_rep = timeslot_rep.getSubFlow(start_index= 0, length= 15)\n",
    "\n",
    "        packet_nums = (timeslot_rep.down_packets + timeslot_rep.up_packets).sum(axis = 0) # this is a list with the number of packets\n",
    "        total_packets = packet_nums.sum()\n",
    "       \n",
    "        \n",
    "        if len(packet_flow_rep) > total_packets:\n",
    "            packet_flow_rep = packet_flow_rep.getSubFlow(start_index= 0, length= total_packets)\n",
    "\n",
    "      \n",
    "\n",
    "        packet_flow_input = np.array([packet_flow_rep.lengths,packet_flow_rep.inter_arrival_times,packet_flow_rep.directions]).T\n",
    "        packet_flow_input = torch.tensor(packet_flow_input).unsqueeze(0).to(self.device).float()\n",
    "        timeslot_flow_input = getActivityArrayFromTimeslotRep(timeslot_rep)\n",
    "        timeslot_flow_input = torch.tensor(timeslot_flow_input).unsqueeze(0).to(self.device).float()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            packet_out,_ = self.packet_documenter.early_model.earlyClassificationForward(packet_flow_input)\n",
    "            timeslot_out,_ = self.timeslot_documenter.early_model.earlyClassificationForward(timeslot_flow_input)\n",
    "    \n",
    "        packet_out = packet_out[0].cpu().numpy()\n",
    "        timeslot_out = timeslot_out[0].cpu().numpy()\n",
    "\n",
    "        prediction,packets_taken = self.proccessPacketSlots(packet_out= packet_out, timeslot_out= timeslot_out, packet_nums= packet_nums)\n",
    "        return prediction,packets_taken\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_eval = CombinedEval(packet_documenter,timeslot_documenter,device=device, threshold= .35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(packet_documenter.test_dataset.flows[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "packet_dropped_dataset = getPacketDroppedPacketDataset(packet_dataset= packet_documenter.test_dataset, max_drop_rate= .05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "519it [00:03, 161.36it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "true = []\n",
    "packets_taken = []\n",
    "for i,flow_rep in tqdm(enumerate(packet_documenter.test_dataset.flows)):\n",
    "    p,pt = combined_eval.infer(flow_rep)\n",
    "    predicted.append(p)\n",
    "    packets_taken.append(pt)\n",
    "    true.append(packet_documenter.test_dataset[i][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "459it [00:01, 306.77it/s]\n"
     ]
    }
   ],
   "source": [
    "ood_predictions = []\n",
    "for i,flow_rep in tqdm(enumerate(packet_documenter.ood_dataset.flows)):\n",
    "    p,pt = combined_eval.infer(flow_rep)\n",
    "    ood_predictions.append(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10023it [00:33, 296.73it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "true = []\n",
    "packets_taken = []\n",
    "for i,flow_rep in tqdm(enumerate(packet_dropped_dataset.flows)):\n",
    "    p,pt = combined_eval.infer(flow_rep)\n",
    "    predicted.append(p)\n",
    "    packets_taken.append(pt)\n",
    "    true.append(packet_documenter.test_dataset[i][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9923913043478261, 0.9962151728768043, 0.9942848457631964, None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = np.array(predicted)\n",
    "packets_taken = np.array(packets_taken)\n",
    "true = np.array(true)\n",
    "included = predicted != -1\n",
    "precision_recall_fscore_support(y_true= true[included], y_pred= predicted[included], average= \"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "included.sum()/len(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9791983764586504"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(true[included] == predicted[included]).sum()/included.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8921001926782273"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packets_taken.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006535947712418301"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(ood_predictions) == -1).sum()/len(ood_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " -1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " -1,\n",
       " 2,\n",
       " -1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ood_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
