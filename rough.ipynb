{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from typing import List, Dict\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from flowprintOptimal.sekigo.core.flowRepresentation import FlowRepresentation,PacketFlowRepressentation\n",
    "from flowprintOptimal.sekigo.dataAnalysis.vNATDataFrameProcessor import VNATDataFrameProcessor\n",
    "from flowprintOptimal.sekigo.core.flowConfig import FlowConfig\n",
    "import random\n",
    "from flowprintOptimal.sekigo.flowUtils.flowDatasets import PacketFlowDataset\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from flowprintOptimal.sekigo.flowUtils.commons import normalizePacketRep\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "from flowprintOptimal.sekigo.flowUtils.commons import saveFlows,loadFlows\n",
    "from flowprintOptimal.sekigo.dataAnalysis.dataFrameProcessor import UTMobileNetProcessor\n",
    "from flowprintOptimal.sekigo.flowUtils.dataGetter import getTrainTestOOD\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import json\n",
    "from flowprintOptimal.sekigo.modeling.trainers import NNClassificationTrainer\n",
    "from flowprintOptimal.sekigo.modeling.neuralNetworks import LSTMNetwork,TransformerGenerator,CNNNetwork1D\n",
    "from flowprintOptimal.sekigo.modeling.loggers import Logger\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "from flowprintOptimal.sekigo.earlyClassification.DQL.core import MemoryElement,Rewarder,State\n",
    "from flowprintOptimal.sekigo.earlyClassification.DQL.memoryFiller import MemoryFiller\n",
    "from flowprintOptimal.sekigo.earlyClassification.DQL.datasets import MemoryDataset\n",
    "from flowprintOptimal.sekigo.earlyClassification.DQL.trainers import EarlyClassificationtrainer\n",
    "from flowprintOptimal.sekigo.utils.documentor import Documenter\n",
    "from flowprintOptimal.sekigo.utils.evaluations import Evaluator,EarlyEvaluation\n",
    "from flowprintOptimal.sekigo.flowUtils.commons import getTimeStampsFromIAT, getIATFromTimeStamps\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "l = 15\n",
    "lam = .15\n",
    "for i in range(5,l+1):\n",
    "    arr.append(lam*(i/l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0999999999999999"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = dict(\n",
    "    name = \"UTMobileNet2021_no_sample_ood_alpha\",\n",
    "    description = \"UTMobileNet2021 with OOD detection (no balancers used) no ood samples generated alpha of .5\",\n",
    "    \n",
    "    common_config = dict(\n",
    "        max_length = 15\n",
    "    ),\n",
    "    \n",
    "    full_model_kwargs = dict(\n",
    "        lstm_hidden_size = 256,\n",
    "        layers= 2, lstm_input_size = 3\n",
    "    ),\n",
    "\n",
    "    early_model_kwargs = dict(\n",
    "        lstm_input_size= 3,lstm_hidden_size= 256,layers = 2        \n",
    "    ),\n",
    "    \n",
    "    data_config = dict(\n",
    "        dataset_name = \"UTMobileNet2021\",\n",
    "        subsampleConfig = None,#dict(max_gap = 20, min_gap = 5),\n",
    "        max_flow_length = 80, # in seconds  ( each flow sample cannot excede this length)\n",
    "        test_size = .2,\n",
    "        ood_classes = [\"google-maps\", \"youtube\",\"messenger\"],\n",
    "        do_balance = False\n",
    "\n",
    "    ),\n",
    "\n",
    "    rewarder_config = dict(\n",
    "        l = .1\n",
    "    ),\n",
    "\n",
    "    dataset_config = dict(\n",
    "        aug = [0,.2]\n",
    "    ),\n",
    "\n",
    "    memory_fillter_config = dict(\n",
    "        ood_config = None,#dict(ood_aug = [.6,.9], ood_prob = .2),\n",
    "        min_length = 5,\n",
    "        use_balancer = False\n",
    "    ),\n",
    "    full_trainer_config = dict(\n",
    "        use_sampler = False\n",
    "    ),\n",
    "    early_trainer_config = dict(\n",
    "        use_sampler = False  # this is for giving more weight to wait samples\n",
    "    )\n",
    "\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full class distrubation\n",
      "google-maps     3256\n",
      "netflix         2081\n",
      "reddit          1609\n",
      "facebook        1312\n",
      "youtube         1309\n",
      "pinterest       1233\n",
      "instagram       1222\n",
      "spotify          878\n",
      "google-drive     877\n",
      "twitter          847\n",
      "gmail            511\n",
      "hangout          426\n",
      "messenger        411\n",
      "Name: count, dtype: int64\n",
      "using no sampling\n",
      "filtering max_flow_length = 80\n",
      "post num packet filter class distrubation\n",
      "google-maps     3256\n",
      "netflix         2081\n",
      "reddit          1609\n",
      "facebook        1312\n",
      "youtube         1309\n",
      "pinterest       1233\n",
      "instagram       1222\n",
      "spotify          878\n",
      "google-drive     877\n",
      "twitter          847\n",
      "gmail            511\n",
      "hangout          426\n",
      "messenger        409\n",
      "Name: count, dtype: int64\n",
      "------------------------------\n",
      "train class distrubation\n",
      "netflix         1681\n",
      "reddit          1290\n",
      "facebook        1025\n",
      "pinterest        990\n",
      "instagram        973\n",
      "google-drive     711\n",
      "spotify          704\n",
      "twitter          682\n",
      "gmail            412\n",
      "hangout          328\n",
      "Name: count, dtype: int64\n",
      "test class distrubation\n",
      "netflix         400\n",
      "reddit          319\n",
      "facebook        287\n",
      "instagram       249\n",
      "pinterest       243\n",
      "spotify         174\n",
      "google-drive    166\n",
      "twitter         165\n",
      "gmail            99\n",
      "hangout          98\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_flows,test_flows,ood_flows = getTrainTestOOD(**configs[\"data_config\"], packet_limit= configs[\"common_config\"][\"max_length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PacketFlowDataset(flows= train_flows,label_to_index= None,aug= configs[\"dataset_config\"][\"aug\"])\n",
    "test_dataset = PacketFlowDataset(flows= test_flows,label_to_index= train_dataset.label_to_index)\n",
    "ood_dataset = PacketFlowDataset(flows= ood_flows, label_to_index= None) if (ood_flows != None and len(ood_flows) != 0) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_IAT = train_flows[0].inter_arrival_times\n",
    "timestamps = getTimeStampsFromIAT(original_IAT)\n",
    "processed_IAT = getIATFromTimeStamps(timestamps= timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05066667, 0.        , 0.        ],\n",
       "       [0.05066667, 0.66044052, 1.        ],\n",
       "       [0.04533333, 0.35332852, 0.        ],\n",
       "       [0.194     , 0.47408577, 0.        ],\n",
       "       [0.04533333, 0.65617666, 1.        ],\n",
       "       [0.87066667, 0.56168224, 1.        ],\n",
       "       [0.04533333, 0.29616328, 0.        ],\n",
       "       [0.87066667, 0.46921004, 1.        ],\n",
       "       [0.04533333, 0.27765287, 0.        ],\n",
       "       [0.85866667, 0.23180299, 1.        ],\n",
       "       [0.04533333, 0.26721528, 0.        ],\n",
       "       [0.10733333, 0.51535638, 0.        ],\n",
       "       [0.40266667, 0.66347016, 0.        ],\n",
       "       [0.21933333, 0.42096119, 1.        ],\n",
       "       [0.07533333, 0.34416099, 1.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(a= np.arange(10), size= 2, replace= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5913333333333334,\n",
       " 0.06866666666666667,\n",
       " 0.04533333333333334,\n",
       " 0.8706666666666667,\n",
       " 0.04533333333333334,\n",
       " 0.75,\n",
       " 0.04533333333333334,\n",
       " 0.8706666666666667,\n",
       " 0.574,\n",
       " 0.04533333333333334,\n",
       " 0.06866666666666667,\n",
       " 0.04533333333333334,\n",
       " 0.3466666666666667,\n",
       " 0.06866666666666667,\n",
       " 0.04533333333333334]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow_rep = train_flows[0]\n",
    "flow_rep.lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flow_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "aug_rep = dropPacketAug(flow_rep= flow_rep, required_length= 10, max_drop_rate= .9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
