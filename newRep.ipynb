{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from typing import List, Dict\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from flowprintOptimal.sekigo.core.flowRepresentation import FlowRepresentation,PacketFlowRepressentation\n",
    "from flowprintOptimal.sekigo.dataAnalysis.vNATDataFrameProcessor import VNATDataFrameProcessor\n",
    "from flowprintOptimal.sekigo.core.flowConfig import FlowConfig\n",
    "import random\n",
    "from flowprintOptimal.sekigo.flowUtils.flowDatasets import PacketFlowDataset\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from flowprintOptimal.sekigo.flowUtils.commons import normalizePacketRep\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "from flowprintOptimal.sekigo.flowUtils.commons import saveFlows,loadFlows\n",
    "from flowprintOptimal.sekigo.dataAnalysis.dataFrameProcessor import UTMobileNetProcessor\n",
    "from flowprintOptimal.sekigo.flowUtils.dataGetter import getTrainTestOOD\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import json\n",
    "from flowprintOptimal.sekigo.modeling.trainers import NNClassificationTrainer\n",
    "from flowprintOptimal.sekigo.modeling.neuralNetworks import LSTMNetwork,TransformerGenerator,CNNNetwork1D\n",
    "from flowprintOptimal.sekigo.modeling.loggers import Logger\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "from flowprintOptimal.sekigo.earlyClassification.DQL.core import MemoryElement,Rewarder,State\n",
    "from flowprintOptimal.sekigo.earlyClassification.DQL.memoryFiller import MemoryFiller\n",
    "from flowprintOptimal.sekigo.earlyClassification.DQL.datasets import MemoryDataset\n",
    "from flowprintOptimal.sekigo.earlyClassification.DQL.trainers import EarlyClassificationtrainer\n",
    "from flowprintOptimal.sekigo.utils.documentor import Documenter\n",
    "from flowprintOptimal.sekigo.utils.evaluations import Evaluator,EarlyEvaluation\n",
    "import warnings\n",
    "from flowprintOptimal.sekigo.flowUtils.commons import dropPacketFromPacketRep\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = dict(\n",
    "    name = \"UTMobileNet2021_no_sample_ood_alpha_ood_samples\",\n",
    "    description = \"UTMobileNet2021 with OOD detection (no balancers used) no ood samples generated alpha of .5 and hint gap at .05 with ood samples\",\n",
    "    \n",
    "    common_config = dict(\n",
    "        max_length = 15\n",
    "    ),\n",
    "    \n",
    "    full_model_kwargs = dict(\n",
    "        lstm_hidden_size = 256,\n",
    "        layers= 2, lstm_input_size = 3\n",
    "    ),\n",
    "\n",
    "    early_model_kwargs = dict(\n",
    "        lstm_input_size= 3,lstm_hidden_size= 256,layers = 2        \n",
    "    ),\n",
    "    \n",
    "    data_config = dict(\n",
    "        dataset_name = \"UTMobileNet2021\",\n",
    "        subsampleConfig = None,#dict(max_gap = 20, min_gap = 5),\n",
    "        max_flow_length = 80, # in seconds  ( each flow sample cannot excede this length)\n",
    "        test_size = .2,\n",
    "        ood_classes = [\"google-maps\", \"youtube\",\"messenger\"],\n",
    "        do_balance = False\n",
    "\n",
    "    ),\n",
    "\n",
    "    rewarder_config = dict(\n",
    "        l = .5\n",
    "    ),\n",
    "\n",
    "    dataset_config = dict(\n",
    "        aug = [0,.2]\n",
    "    ),\n",
    "\n",
    "    memory_fillter_config = dict(\n",
    "        ood_config = dict(ood_aug = [.6,.9], ood_prob = .2),\n",
    "        min_length = 5,\n",
    "        use_balancer = False\n",
    "    ),\n",
    "    full_trainer_config = dict(\n",
    "        use_sampler = False\n",
    "    ),\n",
    "    early_trainer_config = dict(\n",
    "        use_sampler = False  # this is for giving more weight to wait samples\n",
    "    )\n",
    "\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# code to read and save packet flow reps UTMobileNet2021\\nutc_mobile_processor = UTMobileNetProcessor(base_path= \"data/UTMobileNet2021\")\\nflows = utc_mobile_processor.processData()\\nsaveFlows(path  = \"data/UTMobileNet2021/mobilenetPacketRep.json\", flows = flows)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# code to read and save packet flow reps UTMobileNet2021\n",
    "utc_mobile_processor = UTMobileNetProcessor(base_path= \"data/UTMobileNet2021\")\n",
    "flows = utc_mobile_processor.processData()\n",
    "saveFlows(path  = \"data/UTMobileNet2021/mobilenetPacketRep.json\", flows = flows)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full class distrubation\n",
      "google-maps     3256\n",
      "netflix         2081\n",
      "reddit          1609\n",
      "facebook        1312\n",
      "youtube         1309\n",
      "pinterest       1233\n",
      "instagram       1222\n",
      "spotify          878\n",
      "google-drive     877\n",
      "twitter          847\n",
      "gmail            511\n",
      "hangout          426\n",
      "messenger        411\n",
      "Name: count, dtype: int64\n",
      "using no sampling\n",
      "filtering max_flow_length = 80\n",
      "post num packet filter class distrubation\n",
      "google-maps     3256\n",
      "netflix         2081\n",
      "reddit          1609\n",
      "facebook        1312\n",
      "youtube         1309\n",
      "pinterest       1233\n",
      "instagram       1222\n",
      "spotify          878\n",
      "google-drive     877\n",
      "twitter          847\n",
      "gmail            511\n",
      "hangout          426\n",
      "messenger        409\n",
      "Name: count, dtype: int64\n",
      "------------------------------\n",
      "train class distrubation\n",
      "netflix         1658\n",
      "reddit          1289\n",
      "facebook        1027\n",
      "pinterest        976\n",
      "instagram        975\n",
      "spotify          711\n",
      "google-drive     702\n",
      "twitter          674\n",
      "gmail            426\n",
      "hangout          358\n",
      "Name: count, dtype: int64\n",
      "test class distrubation\n",
      "netflix         423\n",
      "reddit          320\n",
      "facebook        285\n",
      "pinterest       257\n",
      "instagram       247\n",
      "google-drive    175\n",
      "twitter         173\n",
      "spotify         167\n",
      "gmail            85\n",
      "hangout          68\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_flows,test_flows,ood_flows = getTrainTestOOD(**configs[\"data_config\"], packet_limit= configs[\"common_config\"][\"max_length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PacketFlowDataset(flows= train_flows,label_to_index= None,aug= configs[\"dataset_config\"][\"aug\"])\n",
    "test_dataset = PacketFlowDataset(flows= test_flows,label_to_index= train_dataset.label_to_index)\n",
    "ood_dataset = PacketFlowDataset(flows= ood_flows, label_to_index= None) if (ood_flows != None and len(ood_flows) != 0) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(train_dataset.label_to_index)\n",
    "configs[\"full_model_kwargs\"][\"output_dim\"] = num_labels \n",
    "configs[\"early_model_kwargs\"][\"output_dim\"] = num_labels + 1\n",
    "configs[\"rewarder_config\"][\"num_labels\"] = num_labels\n",
    "configs[\"rewarder_config\"][\"max_length\"] = configs[\"common_config\"][\"max_length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification ---- 1 metric test_f1 = 0.014736842105263156\n",
      "classification ---- 1 metric test_accuracy = 0.07954545454545454\n",
      "classification ---- 1 metric train_accuracy = 0.07980900409276943\n",
      "classification ---- 1 metric train_f1 = 0.014782059380922299\n",
      "classification ---- 10 metric train_loss = 2.2860644817352296\n",
      "classification ---- 20 metric train_loss = 2.2491039991378785\n",
      "classification ---- 30 metric train_loss = 2.214844560623169\n",
      "classification ---- 40 metric train_loss = 2.2170629501342773\n",
      "classification ---- 50 metric train_loss = 2.167871189117432\n",
      "classification ---- 60 metric train_loss = 2.137901473045349\n",
      "classification ---- 70 metric train_loss = 2.063964879512787\n",
      "classification ---- 80 metric train_loss = 1.9758317708969115\n",
      "classification ---- 90 metric train_loss = 1.9700603008270263\n",
      "classification ---- 100 metric train_loss = 1.8896385192871095\n",
      "classification ---- 110 metric train_loss = 1.9407173633575439\n",
      "classification ---- 120 metric train_loss = 1.9106585741043092\n",
      "classification ---- 130 metric train_loss = 1.9359731316566466\n",
      "classification ---- 140 metric train_loss = 1.9019786596298218\n",
      "classification ---- 150 metric train_loss = 1.90535169839859\n",
      "classification ---- 160 metric train_loss = 1.8779237389564514\n",
      "classification ---- 170 metric train_loss = 1.9122070908546447\n",
      "classification ---- 180 metric train_loss = 1.8574520826339722\n",
      "classification ---- 190 metric train_loss = 1.8840388655662537\n",
      "classification ---- 200 metric train_loss = 1.8871965646743774\n",
      "classification ---- 210 metric train_loss = 1.8905553698539734\n",
      "classification ---- 220 metric train_loss = 1.8846100211143493\n",
      "classification ---- 230 metric train_loss = 1.8905930638313293\n",
      "classification ---- 240 metric train_loss = 1.8416622638702393\n",
      "classification ---- 250 metric train_loss = 1.899595820903778\n",
      "classification ---- 260 metric train_loss = 1.8687185287475585\n",
      "classification ---- 270 metric train_loss = 1.8810457468032837\n",
      "classification ---- 280 metric train_loss = 1.8449367523193358\n",
      "classification ---- 290 metric train_loss = 1.7856449127197265\n",
      "classification ---- 300 metric train_loss = 1.8333587646484375\n",
      "classification ---- 310 metric train_loss = 1.84595228433609\n",
      "classification ---- 320 metric train_loss = 1.780247700214386\n",
      "classification ---- 330 metric train_loss = 1.8156980395317077\n",
      "classification ---- 340 metric train_loss = 1.7714555740356446\n",
      "classification ---- 350 metric train_loss = 1.7347829461097717\n",
      "classification ---- 360 metric train_loss = 1.7521559953689576\n",
      "classification ---- 370 metric train_loss = 1.7420920968055724\n",
      "classification ---- 380 metric train_loss = 1.7554876804351807\n",
      "classification ---- 390 metric train_loss = 1.698439371585846\n",
      "classification ---- 400 metric train_loss = 1.722638237476349\n",
      "classification ---- 410 metric train_loss = 1.681550920009613\n",
      "classification ---- 420 metric train_loss = 1.643037700653076\n",
      "classification ---- 430 metric train_loss = 1.6683212161064147\n",
      "classification ---- 440 metric train_loss = 1.6392228722572326\n",
      "classification ---- 450 metric train_loss = 1.6733046412467956\n",
      "classification ---- 460 metric train_loss = 1.631501019001007\n",
      "classification ---- 470 metric train_loss = 1.618659770488739\n",
      "classification ---- 480 metric train_loss = 1.6521487474441527\n",
      "classification ---- 490 metric train_loss = 1.6621259927749634\n",
      "classification ---- 500 metric train_loss = 1.6343862533569335\n",
      "classification ---- 2 metric test_f1 = 0.3624434970963252\n",
      "classification ---- 2 metric test_accuracy = 0.455\n",
      "classification ---- 510 metric train_loss = 1.607823634147644\n",
      "classification ---- 520 metric train_loss = 1.624418032169342\n",
      "classification ---- 530 metric train_loss = 1.5730170726776123\n",
      "classification ---- 540 metric train_loss = 1.5728115558624267\n",
      "classification ---- 550 metric train_loss = 1.599601638317108\n",
      "classification ---- 560 metric train_loss = 1.5944174170494079\n",
      "classification ---- 570 metric train_loss = 1.5586609601974488\n",
      "classification ---- 580 metric train_loss = 1.5276195287704468\n",
      "classification ---- 590 metric train_loss = 1.5917402148246764\n",
      "classification ---- 600 metric train_loss = 1.517258608341217\n",
      "classification ---- 610 metric train_loss = 1.5403738498687745\n",
      "classification ---- 620 metric train_loss = 1.59851176738739\n",
      "classification ---- 630 metric train_loss = 1.5494410276412964\n",
      "classification ---- 640 metric train_loss = 1.4531246304512024\n",
      "classification ---- 650 metric train_loss = 1.5491933584213258\n",
      "classification ---- 660 metric train_loss = 1.5215773224830627\n",
      "classification ---- 670 metric train_loss = 1.5481640338897704\n",
      "classification ---- 680 metric train_loss = 1.4484101772308349\n",
      "classification ---- 690 metric train_loss = 1.5805609107017518\n",
      "classification ---- 700 metric train_loss = 1.5249487638473511\n",
      "classification ---- 710 metric train_loss = 1.5057276606559753\n",
      "classification ---- 720 metric train_loss = 1.3945515990257262\n",
      "classification ---- 730 metric train_loss = 1.4502371311187745\n",
      "classification ---- 740 metric train_loss = 1.4873254418373107\n",
      "classification ---- 750 metric train_loss = 1.4750581741333009\n",
      "classification ---- 760 metric train_loss = 1.430013358592987\n",
      "classification ---- 770 metric train_loss = 1.4192688107490539\n",
      "classification ---- 780 metric train_loss = 1.3802798628807067\n",
      "classification ---- 790 metric train_loss = 1.4604875326156617\n",
      "classification ---- 800 metric train_loss = 1.4741508722305299\n",
      "classification ---- 810 metric train_loss = 1.4589938282966615\n",
      "classification ---- 820 metric train_loss = 1.3785910725593566\n",
      "classification ---- 830 metric train_loss = 1.4638691902160645\n",
      "classification ---- 840 metric train_loss = 1.3765473127365113\n",
      "classification ---- 850 metric train_loss = 1.3807096481323242\n",
      "classification ---- 860 metric train_loss = 1.393045222759247\n",
      "classification ---- 870 metric train_loss = 1.4151354074478149\n",
      "classification ---- 880 metric train_loss = 1.4064065575599671\n",
      "classification ---- 890 metric train_loss = 1.436635422706604\n",
      "classification ---- 900 metric train_loss = 1.3764968514442444\n",
      "classification ---- 910 metric train_loss = 1.3674127578735351\n",
      "classification ---- 920 metric train_loss = 1.3431028246879577\n",
      "classification ---- 930 metric train_loss = 1.3863862752914429\n",
      "classification ---- 940 metric train_loss = 1.382630670070648\n",
      "classification ---- 950 metric train_loss = 1.3435823798179627\n",
      "classification ---- 960 metric train_loss = 1.3560408353805542\n",
      "classification ---- 970 metric train_loss = 1.3389022827148438\n",
      "classification ---- 980 metric train_loss = 1.4364129900932312\n",
      "classification ---- 990 metric train_loss = 1.3712929964065552\n",
      "classification ---- 1000 metric train_loss = 1.379520046710968\n",
      "classification ---- 3 metric test_f1 = 0.5543624487983762\n",
      "classification ---- 3 metric test_accuracy = 0.59\n",
      "classification ---- 2 metric train_accuracy = 0.5324010914051842\n",
      "classification ---- 2 metric train_f1 = 0.5079782356179608\n",
      "classification ---- 1010 metric train_loss = 1.3059857368469239\n",
      "classification ---- 1020 metric train_loss = 1.3417835474014281\n",
      "classification ---- 1030 metric train_loss = 1.2565430045127868\n",
      "classification ---- 1040 metric train_loss = 1.4262272834777832\n",
      "classification ---- 1050 metric train_loss = 1.3395815372467041\n",
      "classification ---- 1060 metric train_loss = 1.2725628733634948\n",
      "classification ---- 1070 metric train_loss = 1.2267906308174132\n",
      "classification ---- 1080 metric train_loss = 1.386804711818695\n",
      "classification ---- 1090 metric train_loss = 1.3176494717597962\n",
      "classification ---- 1100 metric train_loss = 1.3107216477394104\n",
      "classification ---- 1110 metric train_loss = 1.3159332036972047\n",
      "classification ---- 1120 metric train_loss = 1.3230035543441772\n",
      "classification ---- 1130 metric train_loss = 1.420625877380371\n",
      "classification ---- 1140 metric train_loss = 1.2907793283462525\n",
      "classification ---- 1150 metric train_loss = 1.2628027319908142\n",
      "classification ---- 1160 metric train_loss = 1.222864043712616\n",
      "classification ---- 1170 metric train_loss = 1.2859460949897765\n",
      "classification ---- 1180 metric train_loss = 1.2277307629585266\n",
      "classification ---- 1190 metric train_loss = 1.2997416973114013\n",
      "classification ---- 1200 metric train_loss = 1.2786969423294068\n",
      "classification ---- 1210 metric train_loss = 1.2520329117774964\n",
      "classification ---- 1220 metric train_loss = 1.2698945641517638\n",
      "classification ---- 1230 metric train_loss = 1.2308225154876709\n",
      "classification ---- 1240 metric train_loss = 1.2262387096881866\n",
      "classification ---- 1250 metric train_loss = 1.2579335927963258\n",
      "classification ---- 1260 metric train_loss = 1.2156859159469604\n",
      "classification ---- 1270 metric train_loss = 1.1681704640388488\n",
      "classification ---- 1280 metric train_loss = 1.2945996046066284\n",
      "classification ---- 1290 metric train_loss = 1.2489469647407532\n",
      "classification ---- 1300 metric train_loss = 1.2375431537628174\n",
      "classification ---- 1310 metric train_loss = 1.3166666388511659\n",
      "classification ---- 1320 metric train_loss = 1.2567695021629333\n",
      "classification ---- 1330 metric train_loss = 1.2492830276489257\n",
      "classification ---- 1340 metric train_loss = 1.1716425895690918\n",
      "classification ---- 1350 metric train_loss = 1.203025186061859\n",
      "classification ---- 1360 metric train_loss = 1.2347463607788085\n",
      "classification ---- 1370 metric train_loss = 1.2479406714439392\n",
      "classification ---- 1380 metric train_loss = 1.1956073462963104\n",
      "classification ---- 1390 metric train_loss = 1.1942291855812073\n",
      "classification ---- 1400 metric train_loss = 1.2119625806808472\n",
      "classification ---- 1410 metric train_loss = 1.1849465012550353\n",
      "classification ---- 1420 metric train_loss = 1.2484274625778198\n",
      "classification ---- 1430 metric train_loss = 1.137261575460434\n",
      "classification ---- 1440 metric train_loss = 1.1211229801177978\n",
      "classification ---- 1450 metric train_loss = 1.1433438777923584\n",
      "classification ---- 1460 metric train_loss = 1.1823752701282502\n",
      "classification ---- 1470 metric train_loss = 1.237761664390564\n",
      "classification ---- 1480 metric train_loss = 1.2428413033485413\n",
      "classification ---- 1490 metric train_loss = 1.1900150656700135\n",
      "classification ---- 1500 metric train_loss = 1.1010984182357788\n",
      "classification ---- 4 metric test_f1 = 0.6087272454860975\n",
      "classification ---- 4 metric test_accuracy = 0.6613636363636364\n",
      "classification ---- 1510 metric train_loss = 1.223519617319107\n",
      "classification ---- 1520 metric train_loss = 1.1715243339538575\n",
      "classification ---- 1530 metric train_loss = 1.2036175727844238\n",
      "classification ---- 1540 metric train_loss = 1.190588903427124\n",
      "classification ---- 1550 metric train_loss = 1.1071539282798768\n",
      "classification ---- 1560 metric train_loss = 1.184139657020569\n",
      "classification ---- 1570 metric train_loss = 1.143224060535431\n",
      "classification ---- 1580 metric train_loss = 1.103529006242752\n",
      "classification ---- 1590 metric train_loss = 1.2401669859886169\n",
      "classification ---- 1600 metric train_loss = 1.0791296184062957\n",
      "classification ---- 1610 metric train_loss = 1.0768716752529144\n",
      "classification ---- 1620 metric train_loss = 1.1678659796714783\n",
      "classification ---- 1630 metric train_loss = 1.2328820765018462\n",
      "classification ---- 1640 metric train_loss = 1.0943110942840577\n",
      "classification ---- 1650 metric train_loss = 1.2217854142189026\n",
      "classification ---- 1660 metric train_loss = 1.2354516863822937\n",
      "classification ---- 1670 metric train_loss = 1.1145487308502198\n",
      "classification ---- 1680 metric train_loss = 1.0877722442150115\n",
      "classification ---- 1690 metric train_loss = 1.1171640574932098\n",
      "classification ---- 1700 metric train_loss = 1.022839504480362\n",
      "classification ---- 1710 metric train_loss = 1.110435539484024\n",
      "classification ---- 1720 metric train_loss = 1.0828033626079558\n",
      "classification ---- 1730 metric train_loss = 1.1749394297599793\n",
      "classification ---- 1740 metric train_loss = 1.1213339805603026\n",
      "classification ---- 1750 metric train_loss = 1.0790364801883698\n",
      "classification ---- 1760 metric train_loss = 1.0346693217754364\n",
      "classification ---- 1770 metric train_loss = 1.1144922018051147\n",
      "classification ---- 1780 metric train_loss = 1.0730245769023896\n",
      "classification ---- 1790 metric train_loss = 1.069576120376587\n",
      "classification ---- 1800 metric train_loss = 1.1370314478874206\n",
      "classification ---- 1810 metric train_loss = 1.118682676553726\n",
      "classification ---- 1820 metric train_loss = 1.1035796403884888\n",
      "classification ---- 1830 metric train_loss = 1.085030883550644\n",
      "classification ---- 1840 metric train_loss = 1.0655505299568175\n",
      "classification ---- 1850 metric train_loss = 1.1017078161239624\n",
      "classification ---- 1860 metric train_loss = 1.1328438818454742\n",
      "classification ---- 1870 metric train_loss = 1.066193151473999\n",
      "classification ---- 1880 metric train_loss = 1.0493301272392273\n",
      "classification ---- 1890 metric train_loss = 1.0418851256370545\n",
      "classification ---- 1900 metric train_loss = 0.9715191721916199\n",
      "classification ---- 1910 metric train_loss = 1.0195786476135253\n",
      "classification ---- 1920 metric train_loss = 1.058388453722\n",
      "classification ---- 1930 metric train_loss = 1.0761570036411285\n",
      "classification ---- 1940 metric train_loss = 1.1004462897777558\n",
      "classification ---- 1950 metric train_loss = 1.0390449345111847\n",
      "classification ---- 1960 metric train_loss = 1.0579716980457305\n",
      "classification ---- 1970 metric train_loss = 0.9974821865558624\n",
      "classification ---- 1980 metric train_loss = 0.9907571196556091\n",
      "classification ---- 1990 metric train_loss = 1.0406126737594605\n",
      "classification ---- 2000 metric train_loss = 1.031556087732315\n",
      "classification ---- 5 metric test_f1 = 0.7283726364957712\n",
      "classification ---- 5 metric test_accuracy = 0.7368181818181818\n",
      "classification ---- 3 metric train_accuracy = 0.6629149613460664\n",
      "classification ---- 3 metric train_f1 = 0.6532337599922433\n",
      "classification ---- 2010 metric train_loss = 1.1032684206962586\n",
      "classification ---- 2020 metric train_loss = 1.0276073038578033\n",
      "classification ---- 2030 metric train_loss = 1.0101491928100585\n",
      "classification ---- 2040 metric train_loss = 1.0172006726264953\n",
      "classification ---- 2050 metric train_loss = 0.935150396823883\n",
      "classification ---- 2060 metric train_loss = 0.9519011974334717\n",
      "classification ---- 2070 metric train_loss = 0.9699797689914703\n",
      "classification ---- 2080 metric train_loss = 1.0845876157283783\n",
      "classification ---- 2090 metric train_loss = 0.9491856694221497\n",
      "classification ---- 2100 metric train_loss = 1.0162813007831573\n",
      "classification ---- 2110 metric train_loss = 0.9281059622764587\n",
      "classification ---- 2120 metric train_loss = 0.9880108296871185\n",
      "classification ---- 2130 metric train_loss = 1.0293381989002228\n",
      "classification ---- 2140 metric train_loss = 0.9428094327449799\n",
      "classification ---- 2150 metric train_loss = 0.9672767996788025\n",
      "classification ---- 2160 metric train_loss = 1.0242822468280792\n",
      "classification ---- 2170 metric train_loss = 1.0282719671726226\n",
      "classification ---- 2180 metric train_loss = 0.9491712331771851\n",
      "classification ---- 2190 metric train_loss = 0.9896806001663208\n",
      "classification ---- 2200 metric train_loss = 0.9755200922489167\n",
      "classification ---- 2210 metric train_loss = 0.948873656988144\n",
      "classification ---- 2220 metric train_loss = 1.0511585116386413\n",
      "classification ---- 2230 metric train_loss = 1.0116892218589784\n",
      "classification ---- 2240 metric train_loss = 1.021871280670166\n",
      "classification ---- 2250 metric train_loss = 0.9422648012638092\n",
      "classification ---- 2260 metric train_loss = 0.9376854717731475\n",
      "classification ---- 2270 metric train_loss = 0.986440122127533\n",
      "classification ---- 2280 metric train_loss = 0.9110726058483124\n",
      "classification ---- 2290 metric train_loss = 0.9318789660930633\n",
      "classification ---- 2300 metric train_loss = 0.910715651512146\n",
      "classification ---- 2310 metric train_loss = 1.0879729866981507\n",
      "classification ---- 2320 metric train_loss = 0.9297035038471222\n",
      "classification ---- 2330 metric train_loss = 0.893225246667862\n",
      "classification ---- 2340 metric train_loss = 0.9569976568222046\n",
      "classification ---- 2350 metric train_loss = 0.9692429780960083\n",
      "classification ---- 2360 metric train_loss = 0.989219605922699\n",
      "classification ---- 2370 metric train_loss = 0.946261978149414\n",
      "classification ---- 2380 metric train_loss = 0.9590323448181153\n",
      "classification ---- 2390 metric train_loss = 0.9434835493564606\n",
      "classification ---- 2400 metric train_loss = 0.9605191946029663\n",
      "classification ---- 2410 metric train_loss = 0.9427200376987457\n",
      "classification ---- 2420 metric train_loss = 0.9546651184558869\n",
      "classification ---- 2430 metric train_loss = 0.8980087757110595\n",
      "classification ---- 2440 metric train_loss = 0.9035702049732208\n",
      "classification ---- 2450 metric train_loss = 0.8978216111660003\n",
      "classification ---- 2460 metric train_loss = 0.9445585548877716\n",
      "classification ---- 2470 metric train_loss = 0.8934356272220612\n",
      "classification ---- 2480 metric train_loss = 0.9756672441959381\n",
      "classification ---- 2490 metric train_loss = 0.9073427855968476\n",
      "classification ---- 2500 metric train_loss = 0.9672985732555389\n",
      "classification ---- 6 metric test_f1 = 0.7523176404780589\n",
      "classification ---- 6 metric test_accuracy = 0.7545454545454545\n",
      "classification ---- 2510 metric train_loss = 0.9989213883876801\n",
      "classification ---- 2520 metric train_loss = 1.0245250582695007\n",
      "classification ---- 2530 metric train_loss = 0.8729369759559631\n",
      "classification ---- 2540 metric train_loss = 0.8728436887264251\n",
      "classification ---- 2550 metric train_loss = 0.9346137702465057\n",
      "classification ---- 2560 metric train_loss = 0.9067453861236572\n",
      "classification ---- 2570 metric train_loss = 0.9106950044631958\n",
      "classification ---- 2580 metric train_loss = 1.0295478641986846\n",
      "classification ---- 2590 metric train_loss = 0.9368523776531219\n",
      "classification ---- 2600 metric train_loss = 0.8934198260307312\n",
      "classification ---- 2610 metric train_loss = 0.9541507244110108\n",
      "classification ---- 2620 metric train_loss = 0.9968422472476959\n",
      "classification ---- 2630 metric train_loss = 0.8852572739124298\n",
      "classification ---- 2640 metric train_loss = 0.9824893653392792\n",
      "classification ---- 2650 metric train_loss = 0.9527883887290954\n",
      "classification ---- 2660 metric train_loss = 0.8852328717708587\n",
      "classification ---- 2670 metric train_loss = 0.9424803137779236\n",
      "classification ---- 2680 metric train_loss = 0.8578209638595581\n",
      "classification ---- 2690 metric train_loss = 0.9100089073181152\n",
      "classification ---- 2700 metric train_loss = 0.898710286617279\n",
      "classification ---- 2710 metric train_loss = 0.7399258494377137\n",
      "classification ---- 2720 metric train_loss = 0.8904471695423126\n",
      "classification ---- 2730 metric train_loss = 0.8776686072349549\n",
      "classification ---- 2740 metric train_loss = 0.8945154845714569\n",
      "classification ---- 2750 metric train_loss = 0.8297594785690308\n",
      "classification ---- 2760 metric train_loss = 0.9310324013233184\n",
      "classification ---- 2770 metric train_loss = 0.8230472564697265\n",
      "classification ---- 2780 metric train_loss = 0.8948842823505402\n",
      "classification ---- 2790 metric train_loss = 0.8453740775585175\n",
      "classification ---- 2800 metric train_loss = 0.9009305894374847\n",
      "classification ---- 2810 metric train_loss = 0.9435157597064971\n",
      "classification ---- 2820 metric train_loss = 0.9031773388385773\n",
      "classification ---- 2830 metric train_loss = 0.9435319542884827\n",
      "classification ---- 2840 metric train_loss = 0.8301896631717682\n",
      "classification ---- 2850 metric train_loss = 0.8380837619304657\n",
      "classification ---- 2860 metric train_loss = 0.8417959034442901\n",
      "classification ---- 2870 metric train_loss = 0.9274042308330536\n",
      "classification ---- 2880 metric train_loss = 0.8441296637058258\n",
      "classification ---- 2890 metric train_loss = 0.8799370169639588\n",
      "classification ---- 2900 metric train_loss = 0.8781597852706909\n",
      "classification ---- 2910 metric train_loss = 0.8832742989063262\n",
      "classification ---- 2920 metric train_loss = 0.9024465978145599\n",
      "classification ---- 2930 metric train_loss = 0.8436621248722076\n",
      "classification ---- 2940 metric train_loss = 0.9034920632839203\n",
      "classification ---- 2950 metric train_loss = 0.8408375918865204\n",
      "classification ---- 2960 metric train_loss = 0.8988537728786469\n",
      "classification ---- 2970 metric train_loss = 0.7891205728054047\n",
      "classification ---- 2980 metric train_loss = 0.7891608417034149\n",
      "classification ---- 2990 metric train_loss = 0.8867623656988144\n",
      "classification ---- 3000 metric train_loss = 0.7851207077503204\n",
      "classification ---- 7 metric test_f1 = 0.8203188516145501\n",
      "classification ---- 7 metric test_accuracy = 0.8104545454545454\n",
      "classification ---- 4 metric train_accuracy = 0.7297635288767622\n",
      "classification ---- 4 metric train_f1 = 0.7288250214510403\n",
      "classification ---- 3010 metric train_loss = 0.8526793837547302\n",
      "classification ---- 3020 metric train_loss = 0.8672121584415435\n",
      "classification ---- 3030 metric train_loss = 0.8505554497241974\n",
      "classification ---- 3040 metric train_loss = 0.8619818031787873\n",
      "classification ---- 3050 metric train_loss = 0.8068728506565094\n",
      "classification ---- 3060 metric train_loss = 0.8703088521957397\n",
      "classification ---- 3070 metric train_loss = 0.8397780597209931\n",
      "classification ---- 3080 metric train_loss = 0.8508658051490784\n",
      "classification ---- 3090 metric train_loss = 0.8589844167232513\n",
      "classification ---- 3100 metric train_loss = 0.892466139793396\n",
      "classification ---- 3110 metric train_loss = 0.8497691571712493\n",
      "classification ---- 3120 metric train_loss = 0.8986271739006042\n",
      "classification ---- 3130 metric train_loss = 0.8035310506820679\n",
      "classification ---- 3140 metric train_loss = 0.8221287608146668\n",
      "classification ---- 3150 metric train_loss = 0.8345283329486847\n",
      "classification ---- 3160 metric train_loss = 0.8036217570304871\n",
      "classification ---- 3170 metric train_loss = 0.8493276536464691\n",
      "classification ---- 3180 metric train_loss = 0.8221508800983429\n",
      "classification ---- 3190 metric train_loss = 0.7528371155261994\n",
      "classification ---- 3200 metric train_loss = 0.7817755103111267\n",
      "classification ---- 3210 metric train_loss = 0.8579617977142334\n",
      "classification ---- 3220 metric train_loss = 0.794450557231903\n",
      "classification ---- 3230 metric train_loss = 0.8256422221660614\n",
      "classification ---- 3240 metric train_loss = 0.9026217937469483\n",
      "classification ---- 3250 metric train_loss = 0.742734569311142\n",
      "classification ---- 3260 metric train_loss = 0.8734985172748566\n",
      "classification ---- 3270 metric train_loss = 0.8089209735393524\n",
      "classification ---- 3280 metric train_loss = 0.8568845331668854\n",
      "classification ---- 3290 metric train_loss = 0.7943962097167969\n",
      "classification ---- 3300 metric train_loss = 0.8335505783557892\n",
      "classification ---- 3310 metric train_loss = 0.7838383078575134\n",
      "classification ---- 3320 metric train_loss = 0.7761513888835907\n",
      "classification ---- 3330 metric train_loss = 0.805976277589798\n",
      "classification ---- 3340 metric train_loss = 0.8603457927703857\n",
      "classification ---- 3350 metric train_loss = 0.8167602837085723\n",
      "classification ---- 3360 metric train_loss = 0.7835172414779663\n",
      "classification ---- 3370 metric train_loss = 0.7882264673709869\n",
      "classification ---- 3380 metric train_loss = 0.8350692987442017\n",
      "classification ---- 3390 metric train_loss = 0.7915873885154724\n",
      "classification ---- 3400 metric train_loss = 0.7815073728561401\n",
      "classification ---- 3410 metric train_loss = 0.832976496219635\n",
      "classification ---- 3420 metric train_loss = 0.773861163854599\n",
      "classification ---- 3430 metric train_loss = 0.7972509384155273\n",
      "classification ---- 3440 metric train_loss = 0.7755503296852112\n",
      "classification ---- 3450 metric train_loss = 0.8121313333511353\n",
      "classification ---- 3460 metric train_loss = 0.8207894206047058\n",
      "classification ---- 3470 metric train_loss = 0.7998008549213409\n",
      "classification ---- 3480 metric train_loss = 0.7962896704673768\n",
      "classification ---- 3490 metric train_loss = 0.7764135301113129\n",
      "classification ---- 3500 metric train_loss = 0.7615859657526016\n",
      "classification ---- 8 metric test_f1 = 0.8368657130092936\n",
      "classification ---- 8 metric test_accuracy = 0.8313636363636364\n",
      "classification ---- 3510 metric train_loss = 0.8546340584754943\n",
      "classification ---- 3520 metric train_loss = 0.8120095729827881\n",
      "classification ---- 3530 metric train_loss = 0.760543018579483\n",
      "classification ---- 3540 metric train_loss = 0.809205436706543\n",
      "classification ---- 3550 metric train_loss = 0.7535030305385589\n",
      "classification ---- 3560 metric train_loss = 0.765584933757782\n",
      "classification ---- 3570 metric train_loss = 0.7926618158817291\n",
      "classification ---- 3580 metric train_loss = 0.7996101081371307\n",
      "classification ---- 3590 metric train_loss = 0.7228316247463227\n",
      "classification ---- 3600 metric train_loss = 0.751680675148964\n",
      "classification ---- 3610 metric train_loss = 0.7643170535564423\n",
      "classification ---- 3620 metric train_loss = 0.8126675188541412\n",
      "classification ---- 3630 metric train_loss = 0.8304275333881378\n",
      "classification ---- 3640 metric train_loss = 0.7510534882545471\n",
      "classification ---- 3650 metric train_loss = 0.8058127284049987\n",
      "classification ---- 3660 metric train_loss = 0.7250270962715148\n",
      "classification ---- 3670 metric train_loss = 0.8090867459774017\n",
      "classification ---- 3680 metric train_loss = 0.8257797420024872\n",
      "classification ---- 3690 metric train_loss = 0.7572455674409866\n",
      "classification ---- 3700 metric train_loss = 0.759518027305603\n",
      "classification ---- 3710 metric train_loss = 0.7548093914985656\n",
      "classification ---- 3720 metric train_loss = 0.7858696341514587\n",
      "classification ---- 3730 metric train_loss = 0.7765292704105378\n",
      "classification ---- 3740 metric train_loss = 0.767633706331253\n",
      "classification ---- 3750 metric train_loss = 0.8001709401607513\n",
      "classification ---- 3760 metric train_loss = 0.7763191223144531\n",
      "classification ---- 3770 metric train_loss = 0.7130530327558517\n",
      "classification ---- 3780 metric train_loss = 0.7166298657655716\n",
      "classification ---- 3790 metric train_loss = 0.700783583521843\n",
      "classification ---- 3800 metric train_loss = 0.6986656486988068\n",
      "classification ---- 3810 metric train_loss = 0.715510493516922\n",
      "classification ---- 3820 metric train_loss = 0.8802579343318939\n",
      "classification ---- 3830 metric train_loss = 0.807964438199997\n",
      "classification ---- 3840 metric train_loss = 0.8134209930896759\n",
      "classification ---- 3850 metric train_loss = 0.798768413066864\n",
      "classification ---- 3860 metric train_loss = 0.7878331899642944\n",
      "classification ---- 3870 metric train_loss = 0.7657351195812225\n",
      "classification ---- 3880 metric train_loss = 0.7368791997432709\n",
      "classification ---- 3890 metric train_loss = 0.7277302443981171\n",
      "classification ---- 3900 metric train_loss = 0.805626529455185\n",
      "classification ---- 3910 metric train_loss = 0.7380531370639801\n",
      "classification ---- 3920 metric train_loss = 0.7236571162939072\n",
      "classification ---- 3930 metric train_loss = 0.7611296892166137\n",
      "classification ---- 3940 metric train_loss = 0.7480584859848023\n",
      "classification ---- 3950 metric train_loss = 0.733200091123581\n",
      "classification ---- 3960 metric train_loss = 0.7377686560153961\n",
      "classification ---- 3970 metric train_loss = 0.748892879486084\n",
      "classification ---- 3980 metric train_loss = 0.7053172409534454\n",
      "classification ---- 3990 metric train_loss = 0.7394608378410339\n",
      "classification ---- 4000 metric train_loss = 0.7047998130321502\n",
      "classification ---- 9 metric test_f1 = 0.8442610160549829\n",
      "classification ---- 9 metric test_accuracy = 0.8363636363636363\n",
      "classification ---- 5 metric train_accuracy = 0.7581855388813097\n",
      "classification ---- 5 metric train_f1 = 0.75547131655293\n",
      "classification ---- 4010 metric train_loss = 0.7034755766391754\n",
      "classification ---- 4020 metric train_loss = 0.830021059513092\n",
      "classification ---- 4030 metric train_loss = 0.7150131464004517\n",
      "classification ---- 4040 metric train_loss = 0.7367850184440613\n",
      "classification ---- 4050 metric train_loss = 0.7455237627029419\n",
      "classification ---- 4060 metric train_loss = 0.74663547873497\n",
      "classification ---- 4070 metric train_loss = 0.7227989375591278\n",
      "classification ---- 4080 metric train_loss = 0.6789816319942474\n",
      "classification ---- 4090 metric train_loss = 0.700608229637146\n",
      "classification ---- 4100 metric train_loss = 0.7991013944149017\n",
      "classification ---- 4110 metric train_loss = 0.7641383409500122\n",
      "classification ---- 4120 metric train_loss = 0.7562829852104187\n",
      "classification ---- 4130 metric train_loss = 0.7241387248039246\n",
      "classification ---- 4140 metric train_loss = 0.7346918821334839\n",
      "classification ---- 4150 metric train_loss = 0.7198696792125702\n",
      "classification ---- 4160 metric train_loss = 0.6194495558738708\n",
      "classification ---- 4170 metric train_loss = 0.7898781865835189\n",
      "classification ---- 4180 metric train_loss = 0.68332160115242\n",
      "classification ---- 4190 metric train_loss = 0.7608421087265015\n",
      "classification ---- 4200 metric train_loss = 0.750173032283783\n",
      "classification ---- 4210 metric train_loss = 0.7573776304721832\n",
      "classification ---- 4220 metric train_loss = 0.7172595679759979\n",
      "classification ---- 4230 metric train_loss = 0.792366898059845\n",
      "classification ---- 4240 metric train_loss = 0.815511804819107\n",
      "classification ---- 4250 metric train_loss = 0.7514323115348815\n",
      "classification ---- 4260 metric train_loss = 0.7571306943893432\n",
      "classification ---- 4270 metric train_loss = 0.721136850118637\n",
      "classification ---- 4280 metric train_loss = 0.6922770917415619\n",
      "classification ---- 4290 metric train_loss = 0.7191506803035737\n",
      "classification ---- 4300 metric train_loss = 0.770044955611229\n",
      "classification ---- 4310 metric train_loss = 0.6803264141082763\n",
      "classification ---- 4320 metric train_loss = 0.7195919096469879\n",
      "classification ---- 4330 metric train_loss = 0.6488768875598907\n",
      "classification ---- 4340 metric train_loss = 0.7753769397735596\n",
      "classification ---- 4350 metric train_loss = 0.7464550137519836\n",
      "classification ---- 4360 metric train_loss = 0.729064017534256\n",
      "classification ---- 4370 metric train_loss = 0.6826823353767395\n",
      "classification ---- 4380 metric train_loss = 0.7531778573989868\n",
      "classification ---- 4390 metric train_loss = 0.6515372186899185\n",
      "classification ---- 4400 metric train_loss = 0.7464995443820953\n",
      "classification ---- 4410 metric train_loss = 0.7064912796020508\n",
      "classification ---- 4420 metric train_loss = 0.751431143283844\n",
      "classification ---- 4430 metric train_loss = 0.7284618794918061\n",
      "classification ---- 4440 metric train_loss = 0.681027102470398\n",
      "classification ---- 4450 metric train_loss = 0.6856401562690735\n",
      "classification ---- 4460 metric train_loss = 0.6982043951749801\n",
      "classification ---- 4470 metric train_loss = 0.6673427402973175\n",
      "classification ---- 4480 metric train_loss = 0.7061587452888489\n",
      "classification ---- 4490 metric train_loss = 0.729422664642334\n",
      "classification ---- 4500 metric train_loss = 0.7091142356395721\n",
      "classification ---- 10 metric test_f1 = 0.8545625752613054\n",
      "classification ---- 10 metric test_accuracy = 0.85\n",
      "classification ---- 4510 metric train_loss = 0.6816436648368835\n",
      "classification ---- 4520 metric train_loss = 0.8026097774505615\n",
      "classification ---- 4530 metric train_loss = 0.6887720108032227\n",
      "classification ---- 4540 metric train_loss = 0.6174389958381653\n",
      "classification ---- 4550 metric train_loss = 0.6306874334812165\n",
      "classification ---- 4560 metric train_loss = 0.6863639712333679\n",
      "classification ---- 4570 metric train_loss = 0.6887612164020538\n",
      "classification ---- 4580 metric train_loss = 0.7119105726480484\n",
      "classification ---- 4590 metric train_loss = 0.6621172815561295\n",
      "classification ---- 4600 metric train_loss = 0.6641789495944976\n",
      "classification ---- 4610 metric train_loss = 0.7364628553390503\n",
      "classification ---- 4620 metric train_loss = 0.779636698961258\n",
      "classification ---- 4630 metric train_loss = 0.717241632938385\n",
      "classification ---- 4640 metric train_loss = 0.57635038793087\n",
      "classification ---- 4650 metric train_loss = 0.7222513794898987\n",
      "classification ---- 4660 metric train_loss = 0.652468878030777\n",
      "classification ---- 4670 metric train_loss = 0.7415387094020843\n",
      "classification ---- 4680 metric train_loss = 0.6950281798839569\n",
      "classification ---- 4690 metric train_loss = 0.6746890485286713\n",
      "classification ---- 4700 metric train_loss = 0.7191862046718598\n",
      "classification ---- 4710 metric train_loss = 0.6936454892158508\n",
      "classification ---- 4720 metric train_loss = 0.6471224755048752\n",
      "classification ---- 4730 metric train_loss = 0.7328229427337647\n",
      "classification ---- 4740 metric train_loss = 0.6897282063961029\n",
      "classification ---- 4750 metric train_loss = 0.6897392988204956\n",
      "classification ---- 4760 metric train_loss = 0.7435616552829742\n",
      "classification ---- 4770 metric train_loss = 0.7042345881462098\n",
      "classification ---- 4780 metric train_loss = 0.6411966741085052\n",
      "classification ---- 4790 metric train_loss = 0.6828141331672668\n",
      "classification ---- 4800 metric train_loss = 0.6993282854557037\n",
      "classification ---- 4810 metric train_loss = 0.6886738240718842\n",
      "classification ---- 4820 metric train_loss = 0.7272658884525299\n",
      "classification ---- 4830 metric train_loss = 0.6322980463504791\n",
      "classification ---- 4840 metric train_loss = 0.6335551410913467\n",
      "classification ---- 4850 metric train_loss = 0.6883106172084809\n",
      "classification ---- 4860 metric train_loss = 0.7118687033653259\n",
      "classification ---- 4870 metric train_loss = 0.6073925465345382\n",
      "classification ---- 4880 metric train_loss = 0.7150811076164245\n",
      "classification ---- 4890 metric train_loss = 0.6483331799507142\n",
      "classification ---- 4900 metric train_loss = 0.6053438544273376\n",
      "classification ---- 4910 metric train_loss = 0.6797289162874222\n",
      "classification ---- 4920 metric train_loss = 0.6588657855987549\n",
      "classification ---- 4930 metric train_loss = 0.7081875264644623\n",
      "classification ---- 4940 metric train_loss = 0.6665356636047364\n",
      "classification ---- 4950 metric train_loss = 0.6643004417419434\n",
      "classification ---- 4960 metric train_loss = 0.6083475649356842\n",
      "classification ---- 4970 metric train_loss = 0.6545551896095276\n",
      "classification ---- 4980 metric train_loss = 0.7112123668193817\n",
      "classification ---- 4990 metric train_loss = 0.6701707363128662\n",
      "classification ---- 5000 metric train_loss = 0.6513709992170333\n",
      "classification ---- 11 metric test_f1 = 0.8600953613868804\n",
      "classification ---- 11 metric test_accuracy = 0.8536363636363636\n",
      "classification ---- 6 metric train_accuracy = 0.7753524329240564\n",
      "classification ---- 6 metric train_f1 = 0.7724300013133393\n",
      "classification ---- 5010 metric train_loss = 0.6285266041755676\n",
      "classification ---- 5020 metric train_loss = 0.6281607627868653\n",
      "classification ---- 5030 metric train_loss = 0.6907267659902573\n",
      "classification ---- 5040 metric train_loss = 0.6922153353691101\n",
      "classification ---- 5050 metric train_loss = 0.6340373694896698\n",
      "classification ---- 5060 metric train_loss = 0.7153605043888092\n",
      "classification ---- 5070 metric train_loss = 0.7013703644275665\n",
      "classification ---- 5080 metric train_loss = 0.686250913143158\n",
      "classification ---- 5090 metric train_loss = 0.628709825873375\n",
      "classification ---- 5100 metric train_loss = 0.6202367037534714\n",
      "classification ---- 5110 metric train_loss = 0.6867473244667053\n",
      "classification ---- 5120 metric train_loss = 0.658302652835846\n",
      "classification ---- 5130 metric train_loss = 0.6869937956333161\n",
      "classification ---- 5140 metric train_loss = 0.6342521637678147\n",
      "classification ---- 5150 metric train_loss = 0.6765555262565612\n",
      "classification ---- 5160 metric train_loss = 0.7286148786544799\n",
      "classification ---- 5170 metric train_loss = 0.6941128939390182\n",
      "classification ---- 5180 metric train_loss = 0.6022781699895858\n",
      "classification ---- 5190 metric train_loss = 0.6670611679553986\n",
      "classification ---- 5200 metric train_loss = 0.6378365516662597\n",
      "classification ---- 5210 metric train_loss = 0.6683711886405945\n",
      "classification ---- 5220 metric train_loss = 0.6349153041839599\n",
      "classification ---- 5230 metric train_loss = 0.6200111657381058\n",
      "classification ---- 5240 metric train_loss = 0.6784772992134094\n",
      "classification ---- 5250 metric train_loss = 0.6920357882976532\n",
      "classification ---- 5260 metric train_loss = 0.621273934841156\n",
      "classification ---- 5270 metric train_loss = 0.5547563463449479\n",
      "classification ---- 5280 metric train_loss = 0.6084922552108765\n",
      "classification ---- 5290 metric train_loss = 0.6974037289619446\n",
      "classification ---- 5300 metric train_loss = 0.699296909570694\n",
      "classification ---- 5310 metric train_loss = 0.6118333965539933\n",
      "classification ---- 5320 metric train_loss = 0.7129671782255173\n",
      "classification ---- 5330 metric train_loss = 0.6762229472398757\n",
      "classification ---- 5340 metric train_loss = 0.6837292522192001\n",
      "classification ---- 5350 metric train_loss = 0.7183946400880814\n",
      "classification ---- 5360 metric train_loss = 0.6520378440618515\n",
      "classification ---- 5370 metric train_loss = 0.6248977810144425\n",
      "classification ---- 5380 metric train_loss = 0.6552271574735642\n",
      "classification ---- 5390 metric train_loss = 0.6176672041416168\n",
      "classification ---- 5400 metric train_loss = 0.7427569985389709\n",
      "classification ---- 5410 metric train_loss = 0.674894380569458\n",
      "classification ---- 5420 metric train_loss = 0.6073431819677353\n",
      "classification ---- 5430 metric train_loss = 0.6966598212718964\n",
      "classification ---- 5440 metric train_loss = 0.6702893793582916\n",
      "classification ---- 5450 metric train_loss = 0.5439070910215378\n",
      "classification ---- 5460 metric train_loss = 0.6214905589818954\n",
      "classification ---- 5470 metric train_loss = 0.6128802329301835\n",
      "classification ---- 5480 metric train_loss = 0.6570819735527038\n",
      "classification ---- 5490 metric train_loss = 0.6526908040046692\n",
      "classification ---- 5500 metric train_loss = 0.6493018627166748\n",
      "classification ---- 12 metric test_f1 = 0.8655448423930331\n",
      "classification ---- 12 metric test_accuracy = 0.8577272727272728\n",
      "classification ---- 5510 metric train_loss = 0.6388256847858429\n",
      "classification ---- 5520 metric train_loss = 0.6315163135528564\n",
      "classification ---- 5530 metric train_loss = 0.5636902302503586\n",
      "classification ---- 5540 metric train_loss = 0.7375404298305511\n",
      "classification ---- 5550 metric train_loss = 0.5882199972867965\n",
      "classification ---- 5560 metric train_loss = 0.6819007098674774\n",
      "classification ---- 5570 metric train_loss = 0.6400559604167938\n",
      "classification ---- 5580 metric train_loss = 0.6602141946554184\n",
      "classification ---- 5590 metric train_loss = 0.6570937842130661\n",
      "classification ---- 5600 metric train_loss = 0.6603668063879014\n",
      "classification ---- 5610 metric train_loss = 0.6070626318454743\n",
      "classification ---- 5620 metric train_loss = 0.5895470172166825\n",
      "classification ---- 5630 metric train_loss = 0.6340120017528534\n",
      "classification ---- 5640 metric train_loss = 0.655903896689415\n",
      "classification ---- 5650 metric train_loss = 0.643519589304924\n",
      "classification ---- 5660 metric train_loss = 0.7109835684299469\n",
      "classification ---- 5670 metric train_loss = 0.6267852455377578\n",
      "classification ---- 5680 metric train_loss = 0.617033651471138\n",
      "classification ---- 5690 metric train_loss = 0.608276703953743\n",
      "classification ---- 5700 metric train_loss = 0.6267648994922638\n",
      "classification ---- 5710 metric train_loss = 0.6511414974927903\n",
      "classification ---- 5720 metric train_loss = 0.6199474334716797\n",
      "classification ---- 5730 metric train_loss = 0.6489360272884369\n",
      "classification ---- 5740 metric train_loss = 0.5880784183740616\n",
      "classification ---- 5750 metric train_loss = 0.5310201317071914\n",
      "classification ---- 5760 metric train_loss = 0.6342791020870209\n",
      "classification ---- 5770 metric train_loss = 0.6835200726985932\n",
      "classification ---- 5780 metric train_loss = 0.6675317645072937\n",
      "classification ---- 5790 metric train_loss = 0.6037575453519821\n",
      "classification ---- 5800 metric train_loss = 0.6383016169071197\n",
      "classification ---- 5810 metric train_loss = 0.6243542283773422\n",
      "classification ---- 5820 metric train_loss = 0.5869591683149338\n",
      "classification ---- 5830 metric train_loss = 0.6015138328075409\n",
      "classification ---- 5840 metric train_loss = 0.6319333612918854\n",
      "classification ---- 5850 metric train_loss = 0.628057062625885\n",
      "classification ---- 5860 metric train_loss = 0.7058934211730957\n",
      "classification ---- 5870 metric train_loss = 0.6341635853052139\n",
      "classification ---- 5880 metric train_loss = 0.6309560745954513\n",
      "classification ---- 5890 metric train_loss = 0.6524130463600158\n",
      "classification ---- 5900 metric train_loss = 0.5703411519527435\n",
      "classification ---- 5910 metric train_loss = 0.6192272454500198\n",
      "classification ---- 5920 metric train_loss = 0.5998579144477845\n",
      "classification ---- 5930 metric train_loss = 0.6061970859766006\n",
      "classification ---- 5940 metric train_loss = 0.6702922761440278\n",
      "classification ---- 5950 metric train_loss = 0.5716002941131592\n",
      "classification ---- 5960 metric train_loss = 0.5704682856798172\n",
      "classification ---- 5970 metric train_loss = 0.5873673319816589\n",
      "classification ---- 5980 metric train_loss = 0.5932969391345978\n",
      "classification ---- 5990 metric train_loss = 0.5847148358821869\n",
      "classification ---- 6000 metric train_loss = 0.5682413160800934\n",
      "classification ---- 13 metric test_f1 = 0.8629747974569021\n",
      "classification ---- 13 metric test_accuracy = 0.8577272727272728\n",
      "classification ---- 7 metric train_accuracy = 0.8011596180081856\n",
      "classification ---- 7 metric train_f1 = 0.8007054535165314\n",
      "classification ---- 6010 metric train_loss = 0.6039372712373734\n",
      "classification ---- 6020 metric train_loss = 0.6309615820646286\n",
      "classification ---- 6030 metric train_loss = 0.646885359287262\n",
      "classification ---- 6040 metric train_loss = 0.6669043093919754\n",
      "classification ---- 6050 metric train_loss = 0.605018237233162\n",
      "classification ---- 6060 metric train_loss = 0.5961801081895828\n",
      "classification ---- 6070 metric train_loss = 0.6010111331939697\n",
      "classification ---- 6080 metric train_loss = 0.6341905534267426\n",
      "classification ---- 6090 metric train_loss = 0.6142347753047943\n",
      "classification ---- 6100 metric train_loss = 0.6433786958456039\n",
      "classification ---- 6110 metric train_loss = 0.6874196499586105\n",
      "classification ---- 6120 metric train_loss = 0.610240238904953\n",
      "classification ---- 6130 metric train_loss = 0.5783468246459961\n",
      "classification ---- 6140 metric train_loss = 0.5253365218639374\n",
      "classification ---- 6150 metric train_loss = 0.6066660463809967\n",
      "classification ---- 6160 metric train_loss = 0.6137324690818786\n",
      "classification ---- 6170 metric train_loss = 0.5704365402460099\n",
      "classification ---- 6180 metric train_loss = 0.6236681461334228\n",
      "classification ---- 6190 metric train_loss = 0.6001293629407882\n",
      "classification ---- 6200 metric train_loss = 0.6622883260250092\n",
      "classification ---- 6210 metric train_loss = 0.6735953092575073\n",
      "classification ---- 6220 metric train_loss = 0.6330559194087982\n",
      "classification ---- 6230 metric train_loss = 0.5648513019084931\n",
      "classification ---- 6240 metric train_loss = 0.6466860294342041\n",
      "classification ---- 6250 metric train_loss = 0.501799750328064\n",
      "classification ---- 6260 metric train_loss = 0.6058049380779267\n",
      "classification ---- 6270 metric train_loss = 0.5639708906412124\n",
      "classification ---- 6280 metric train_loss = 0.6326635628938675\n",
      "classification ---- 6290 metric train_loss = 0.6090639919042588\n",
      "classification ---- 6300 metric train_loss = 0.6638471812009812\n",
      "classification ---- 6310 metric train_loss = 0.5718456119298935\n",
      "classification ---- 6320 metric train_loss = 0.6200262010097504\n",
      "classification ---- 6330 metric train_loss = 0.5851235300302505\n",
      "classification ---- 6340 metric train_loss = 0.5590688765048981\n",
      "classification ---- 6350 metric train_loss = 0.6803144693374634\n",
      "classification ---- 6360 metric train_loss = 0.5592589646577835\n",
      "classification ---- 6370 metric train_loss = 0.5868447482585907\n",
      "classification ---- 6380 metric train_loss = 0.6074898302555084\n",
      "classification ---- 6390 metric train_loss = 0.5283976256847381\n",
      "classification ---- 6400 metric train_loss = 0.5758623778820038\n",
      "classification ---- 6410 metric train_loss = 0.5921145468950272\n",
      "classification ---- 6420 metric train_loss = 0.5257401436567306\n",
      "classification ---- 6430 metric train_loss = 0.6169112890958786\n",
      "classification ---- 6440 metric train_loss = 0.5559442162513732\n",
      "classification ---- 6450 metric train_loss = 0.5623918801546097\n",
      "classification ---- 6460 metric train_loss = 0.5713191211223603\n",
      "classification ---- 6470 metric train_loss = 0.5116501986980438\n",
      "classification ---- 6480 metric train_loss = 0.5558431357145309\n",
      "classification ---- 6490 metric train_loss = 0.6230013698339463\n",
      "classification ---- 6500 metric train_loss = 0.5688654810190201\n",
      "classification ---- 14 metric test_f1 = 0.8623534951524204\n",
      "classification ---- 14 metric test_accuracy = 0.8563636363636363\n",
      "classification ---- 6510 metric train_loss = 0.5616246223449707\n",
      "classification ---- 6520 metric train_loss = 0.6256063610315323\n",
      "classification ---- 6530 metric train_loss = 0.6665914356708527\n",
      "classification ---- 6540 metric train_loss = 0.5801280558109283\n",
      "classification ---- 6550 metric train_loss = 0.6134650379419326\n",
      "classification ---- 6560 metric train_loss = 0.6094341546297073\n",
      "classification ---- 6570 metric train_loss = 0.5721986770629883\n",
      "classification ---- 6580 metric train_loss = 0.5716909468173981\n",
      "classification ---- 6590 metric train_loss = 0.5246172606945038\n",
      "classification ---- 6600 metric train_loss = 0.5296972662210464\n",
      "classification ---- 6610 metric train_loss = 0.5547363370656967\n",
      "classification ---- 6620 metric train_loss = 0.5089903980493545\n",
      "classification ---- 6630 metric train_loss = 0.6211290299892426\n",
      "classification ---- 6640 metric train_loss = 0.5943826258182525\n",
      "classification ---- 6650 metric train_loss = 0.6140437483787536\n",
      "classification ---- 6660 metric train_loss = 0.5573153078556061\n",
      "classification ---- 6670 metric train_loss = 0.5303954988718033\n",
      "classification ---- 6680 metric train_loss = 0.5393638908863068\n",
      "classification ---- 6690 metric train_loss = 0.6385000169277191\n",
      "classification ---- 6700 metric train_loss = 0.6552128851413727\n",
      "classification ---- 6710 metric train_loss = 0.5711738348007203\n",
      "classification ---- 6720 metric train_loss = 0.6119480222463608\n",
      "classification ---- 6730 metric train_loss = 0.5879070162773132\n",
      "classification ---- 6740 metric train_loss = 0.5358873546123505\n",
      "classification ---- 6750 metric train_loss = 0.6203933209180832\n",
      "classification ---- 6760 metric train_loss = 0.5296184301376343\n",
      "classification ---- 6770 metric train_loss = 0.5562038272619247\n",
      "classification ---- 6780 metric train_loss = 0.5533000320196152\n",
      "classification ---- 6790 metric train_loss = 0.5330544859170914\n",
      "classification ---- 6800 metric train_loss = 0.6339364647865295\n",
      "classification ---- 6810 metric train_loss = 0.5504218816757203\n",
      "classification ---- 6820 metric train_loss = 0.586765518784523\n",
      "classification ---- 6830 metric train_loss = 0.60054692029953\n",
      "classification ---- 6840 metric train_loss = 0.5245342284440995\n",
      "classification ---- 6850 metric train_loss = 0.5652335703372955\n",
      "classification ---- 6860 metric train_loss = 0.5005383729934693\n",
      "classification ---- 6870 metric train_loss = 0.5733058154582977\n",
      "classification ---- 6880 metric train_loss = 0.5189304977655411\n",
      "classification ---- 6890 metric train_loss = 0.578780135512352\n",
      "classification ---- 6900 metric train_loss = 0.6116767346858978\n",
      "classification ---- 6910 metric train_loss = 0.586173239350319\n",
      "classification ---- 6920 metric train_loss = 0.546859759092331\n",
      "classification ---- 6930 metric train_loss = 0.5924951672554016\n",
      "classification ---- 6940 metric train_loss = 0.5525844246149063\n",
      "classification ---- 6950 metric train_loss = 0.5652335315942765\n",
      "classification ---- 6960 metric train_loss = 0.5729774832725525\n",
      "classification ---- 6970 metric train_loss = 0.5629763394594193\n",
      "classification ---- 6980 metric train_loss = 0.5723584681749344\n",
      "classification ---- 6990 metric train_loss = 0.5497030436992645\n",
      "classification ---- 7000 metric train_loss = 0.5738327980041504\n",
      "classification ---- 15 metric test_f1 = 0.8695897004603795\n",
      "classification ---- 15 metric test_accuracy = 0.8636363636363636\n",
      "classification ---- 8 metric train_accuracy = 0.8052523874488404\n",
      "classification ---- 8 metric train_f1 = 0.8045501564595441\n",
      "classification ---- 7010 metric train_loss = 0.6225362867116928\n",
      "classification ---- 7020 metric train_loss = 0.587372225522995\n",
      "classification ---- 7030 metric train_loss = 0.5753825426101684\n",
      "classification ---- 7040 metric train_loss = 0.5556179314851761\n",
      "classification ---- 7050 metric train_loss = 0.5536636918783188\n",
      "classification ---- 7060 metric train_loss = 0.5291138142347336\n",
      "classification ---- 7070 metric train_loss = 0.5736948609352112\n",
      "classification ---- 7080 metric train_loss = 0.6021313697099686\n",
      "classification ---- 7090 metric train_loss = 0.5688863694667816\n",
      "classification ---- 7100 metric train_loss = 0.571124118566513\n",
      "classification ---- 7110 metric train_loss = 0.5323629558086396\n",
      "classification ---- 7120 metric train_loss = 0.5145539790391922\n",
      "classification ---- 7130 metric train_loss = 0.47914305329322815\n",
      "classification ---- 7140 metric train_loss = 0.5600863426923752\n",
      "classification ---- 7150 metric train_loss = 0.5615372627973556\n",
      "classification ---- 7160 metric train_loss = 0.6079181939363479\n",
      "classification ---- 7170 metric train_loss = 0.5810264021158218\n",
      "classification ---- 7180 metric train_loss = 0.5201827973127365\n",
      "classification ---- 7190 metric train_loss = 0.5038938462734223\n",
      "classification ---- 7200 metric train_loss = 0.48251692950725555\n",
      "classification ---- 7210 metric train_loss = 0.5749899059534073\n",
      "classification ---- 7220 metric train_loss = 0.5612770706415177\n",
      "classification ---- 7230 metric train_loss = 0.5155438244342804\n",
      "classification ---- 7240 metric train_loss = 0.5607773423194885\n",
      "classification ---- 7250 metric train_loss = 0.49332092702388763\n",
      "classification ---- 7260 metric train_loss = 0.5903904557228088\n",
      "classification ---- 7270 metric train_loss = 0.46095213294029236\n",
      "classification ---- 7280 metric train_loss = 0.551510289311409\n",
      "classification ---- 7290 metric train_loss = 0.5068983256816864\n",
      "classification ---- 7300 metric train_loss = 0.49193756878376005\n",
      "classification ---- 7310 metric train_loss = 0.5113559097051621\n",
      "classification ---- 7320 metric train_loss = 0.5809765785932541\n",
      "classification ---- 7330 metric train_loss = 0.5620613604784012\n",
      "classification ---- 7340 metric train_loss = 0.5290660828351974\n",
      "classification ---- 7350 metric train_loss = 0.5635720580816269\n",
      "classification ---- 7360 metric train_loss = 0.5298935204744339\n",
      "classification ---- 7370 metric train_loss = 0.5789805591106415\n",
      "classification ---- 7380 metric train_loss = 0.5250745385885238\n",
      "classification ---- 7390 metric train_loss = 0.5314919829368592\n",
      "classification ---- 7400 metric train_loss = 0.6304145216941833\n",
      "classification ---- 7410 metric train_loss = 0.5535295709967614\n",
      "classification ---- 7420 metric train_loss = 0.5037435859441757\n",
      "classification ---- 7430 metric train_loss = 0.5692905992269516\n",
      "classification ---- 7440 metric train_loss = 0.5761126697063446\n",
      "classification ---- 7450 metric train_loss = 0.5134295642375946\n",
      "classification ---- 7460 metric train_loss = 0.41786201000213624\n",
      "classification ---- 7470 metric train_loss = 0.5609470158815384\n",
      "classification ---- 7480 metric train_loss = 0.46874155700206754\n",
      "classification ---- 7490 metric train_loss = 0.49063742756843565\n",
      "classification ---- 7500 metric train_loss = 0.5506479233503342\n",
      "classification ---- 16 metric test_f1 = 0.8925236110436355\n",
      "classification ---- 16 metric test_accuracy = 0.8886363636363637\n",
      "classification ---- 7510 metric train_loss = 0.5183615893125534\n",
      "classification ---- 7520 metric train_loss = 0.5258943378925324\n",
      "classification ---- 7530 metric train_loss = 0.541918295621872\n",
      "classification ---- 7540 metric train_loss = 0.5695988714694977\n",
      "classification ---- 7550 metric train_loss = 0.523884904384613\n",
      "classification ---- 7560 metric train_loss = 0.4937766581773758\n",
      "classification ---- 7570 metric train_loss = 0.5040539473295211\n",
      "classification ---- 7580 metric train_loss = 0.5961189359426499\n",
      "classification ---- 7590 metric train_loss = 0.5181772530078887\n",
      "classification ---- 7600 metric train_loss = 0.5746901363134385\n",
      "classification ---- 7610 metric train_loss = 0.4892837226390839\n",
      "classification ---- 7620 metric train_loss = 0.524291917681694\n",
      "classification ---- 7630 metric train_loss = 0.4996780246496201\n",
      "classification ---- 7640 metric train_loss = 0.5194733053445816\n",
      "classification ---- 7650 metric train_loss = 0.4898435950279236\n",
      "classification ---- 7660 metric train_loss = 0.5558194369077682\n",
      "classification ---- 7670 metric train_loss = 0.48543636202812196\n",
      "classification ---- 7680 metric train_loss = 0.4683028131723404\n",
      "classification ---- 7690 metric train_loss = 0.6053748577833176\n",
      "classification ---- 7700 metric train_loss = 0.5512989044189454\n",
      "classification ---- 7710 metric train_loss = 0.512206420302391\n",
      "classification ---- 7720 metric train_loss = 0.5635690242052078\n",
      "classification ---- 7730 metric train_loss = 0.5488922908902168\n",
      "classification ---- 7740 metric train_loss = 0.5212338685989379\n",
      "classification ---- 7750 metric train_loss = 0.560949781537056\n",
      "classification ---- 7760 metric train_loss = 0.5710438907146453\n",
      "classification ---- 7770 metric train_loss = 0.5335330188274383\n",
      "classification ---- 7780 metric train_loss = 0.5285784006118774\n",
      "classification ---- 7790 metric train_loss = 0.414048533141613\n",
      "classification ---- 7800 metric train_loss = 0.4633543103933334\n",
      "classification ---- 7810 metric train_loss = 0.568418437242508\n",
      "classification ---- 7820 metric train_loss = 0.5566230744123459\n",
      "classification ---- 7830 metric train_loss = 0.50015929043293\n",
      "classification ---- 7840 metric train_loss = 0.49699394404888153\n",
      "classification ---- 7850 metric train_loss = 0.5043881207704544\n",
      "classification ---- 7860 metric train_loss = 0.5078682452440262\n",
      "classification ---- 7870 metric train_loss = 0.5820032328367233\n",
      "classification ---- 7880 metric train_loss = 0.5410461366176605\n",
      "classification ---- 7890 metric train_loss = 0.45154080390930174\n",
      "classification ---- 7900 metric train_loss = 0.5560927420854569\n",
      "classification ---- 7910 metric train_loss = 0.5086925357580185\n",
      "classification ---- 7920 metric train_loss = 0.5628929555416107\n",
      "classification ---- 7930 metric train_loss = 0.4491803288459778\n",
      "classification ---- 7940 metric train_loss = 0.5644912034273147\n",
      "classification ---- 7950 metric train_loss = 0.49538969695568086\n",
      "classification ---- 7960 metric train_loss = 0.4713606804609299\n",
      "classification ---- 7970 metric train_loss = 0.4711527943611145\n",
      "classification ---- 7980 metric train_loss = 0.48877253830432893\n",
      "classification ---- 7990 metric train_loss = 0.4641193956136703\n",
      "classification ---- 8000 metric train_loss = 0.45682289004325866\n",
      "classification ---- 17 metric test_f1 = 0.892158181559069\n",
      "classification ---- 17 metric test_accuracy = 0.8877272727272727\n",
      "classification ---- 9 metric train_accuracy = 0.8327648931332424\n",
      "classification ---- 9 metric train_f1 = 0.8298299309019411\n",
      "classification ---- 8010 metric train_loss = 0.5409781634807587\n",
      "classification ---- 8020 metric train_loss = 0.4970974504947662\n",
      "classification ---- 8030 metric train_loss = 0.49345807135105135\n",
      "classification ---- 8040 metric train_loss = 0.47975126206874846\n",
      "classification ---- 8050 metric train_loss = 0.48769171833992003\n",
      "classification ---- 8060 metric train_loss = 0.5227151423692703\n",
      "classification ---- 8070 metric train_loss = 0.5747861415147781\n",
      "classification ---- 8080 metric train_loss = 0.5541489094495773\n",
      "classification ---- 8090 metric train_loss = 0.5182641804218292\n",
      "classification ---- 8100 metric train_loss = 0.5181739240884781\n",
      "classification ---- 8110 metric train_loss = 0.5202085912227631\n",
      "classification ---- 8120 metric train_loss = 0.43002825081348417\n",
      "classification ---- 8130 metric train_loss = 0.5171646326780319\n",
      "classification ---- 8140 metric train_loss = 0.5191296577453614\n",
      "classification ---- 8150 metric train_loss = 0.4228899210691452\n",
      "classification ---- 8160 metric train_loss = 0.5009215980768204\n",
      "classification ---- 8170 metric train_loss = 0.4456742763519287\n",
      "classification ---- 8180 metric train_loss = 0.5453302741050721\n",
      "classification ---- 8190 metric train_loss = 0.49940588176250456\n",
      "classification ---- 8200 metric train_loss = 0.5138675451278687\n",
      "classification ---- 8210 metric train_loss = 0.494878488779068\n",
      "classification ---- 8220 metric train_loss = 0.5186694949865341\n",
      "classification ---- 8230 metric train_loss = 0.479039853811264\n",
      "classification ---- 8240 metric train_loss = 0.5223228305578231\n",
      "classification ---- 8250 metric train_loss = 0.4867821842432022\n",
      "classification ---- 8260 metric train_loss = 0.5037700533866882\n",
      "classification ---- 8270 metric train_loss = 0.5315638333559036\n",
      "classification ---- 8280 metric train_loss = 0.49541700780391695\n",
      "classification ---- 8290 metric train_loss = 0.516019606590271\n",
      "classification ---- 8300 metric train_loss = 0.47639632523059844\n",
      "classification ---- 8310 metric train_loss = 0.5086653500795364\n",
      "classification ---- 8320 metric train_loss = 0.47472251355648043\n",
      "classification ---- 8330 metric train_loss = 0.534767884016037\n",
      "classification ---- 8340 metric train_loss = 0.5355572134256363\n",
      "classification ---- 8350 metric train_loss = 0.4845228552818298\n",
      "classification ---- 8360 metric train_loss = 0.5314807295799255\n",
      "classification ---- 8370 metric train_loss = 0.5409035623073578\n",
      "classification ---- 8380 metric train_loss = 0.5525698751211167\n",
      "classification ---- 8390 metric train_loss = 0.5106234043836594\n",
      "classification ---- 8400 metric train_loss = 0.5039068400859833\n",
      "classification ---- 8410 metric train_loss = 0.5072603583335876\n",
      "classification ---- 8420 metric train_loss = 0.44952377676963806\n",
      "classification ---- 8430 metric train_loss = 0.46831598281860354\n",
      "classification ---- 8440 metric train_loss = 0.4426462173461914\n",
      "classification ---- 8450 metric train_loss = 0.4338994026184082\n",
      "classification ---- 8460 metric train_loss = 0.47259152829647066\n",
      "classification ---- 8470 metric train_loss = 0.4588026702404022\n",
      "classification ---- 8480 metric train_loss = 0.47610729932785034\n",
      "classification ---- 8490 metric train_loss = 0.6180514127016068\n",
      "classification ---- 8500 metric train_loss = 0.4789850041270256\n",
      "classification ---- 18 metric test_f1 = 0.8775480090563524\n",
      "classification ---- 18 metric test_accuracy = 0.8759090909090909\n",
      "classification ---- 8510 metric train_loss = 0.5358905255794525\n",
      "classification ---- 8520 metric train_loss = 0.5076823770999909\n",
      "classification ---- 8530 metric train_loss = 0.5157415002584458\n",
      "classification ---- 8540 metric train_loss = 0.5567383646965027\n",
      "classification ---- 8550 metric train_loss = 0.4999401420354843\n",
      "classification ---- 8560 metric train_loss = 0.5104992628097534\n",
      "classification ---- 8570 metric train_loss = 0.5104081809520722\n",
      "classification ---- 8580 metric train_loss = 0.5000840783119201\n",
      "classification ---- 8590 metric train_loss = 0.5665532112121582\n",
      "classification ---- 8600 metric train_loss = 0.4525404214859009\n",
      "classification ---- 8610 metric train_loss = 0.5166204273700714\n",
      "classification ---- 8620 metric train_loss = 0.4285585701465607\n",
      "classification ---- 8630 metric train_loss = 0.4673537313938141\n",
      "classification ---- 8640 metric train_loss = 0.3990916520357132\n",
      "classification ---- 8650 metric train_loss = 0.4964770287275314\n",
      "classification ---- 8660 metric train_loss = 0.5313137412071228\n",
      "classification ---- 8670 metric train_loss = 0.49706433415412904\n",
      "classification ---- 8680 metric train_loss = 0.4824026107788086\n",
      "classification ---- 8690 metric train_loss = 0.5360690176486969\n",
      "classification ---- 8700 metric train_loss = 0.4972784996032715\n",
      "classification ---- 8710 metric train_loss = 0.45117148458957673\n",
      "classification ---- 8720 metric train_loss = 0.4658454567193985\n",
      "classification ---- 8730 metric train_loss = 0.46358972489833833\n",
      "classification ---- 8740 metric train_loss = 0.4651526689529419\n",
      "classification ---- 8750 metric train_loss = 0.4978426158428192\n",
      "classification ---- 8760 metric train_loss = 0.5239603012800217\n",
      "classification ---- 8770 metric train_loss = 0.456992968916893\n",
      "classification ---- 8780 metric train_loss = 0.5006621420383454\n",
      "classification ---- 8790 metric train_loss = 0.47793897390365603\n",
      "classification ---- 8800 metric train_loss = 0.4912739634513855\n",
      "classification ---- 8810 metric train_loss = 0.47604612708091737\n",
      "classification ---- 8820 metric train_loss = 0.4849628180265427\n",
      "classification ---- 8830 metric train_loss = 0.4807504743337631\n",
      "classification ---- 8840 metric train_loss = 0.43360577821731566\n",
      "classification ---- 8850 metric train_loss = 0.5092213034629822\n",
      "classification ---- 8860 metric train_loss = 0.4627884179353714\n",
      "classification ---- 8870 metric train_loss = 0.5004318594932556\n",
      "classification ---- 8880 metric train_loss = 0.4545872837305069\n",
      "classification ---- 8890 metric train_loss = 0.49267803132534027\n",
      "classification ---- 8900 metric train_loss = 0.44892254918813707\n",
      "classification ---- 8910 metric train_loss = 0.4756514966487885\n",
      "classification ---- 8920 metric train_loss = 0.5148896783590317\n",
      "classification ---- 8930 metric train_loss = 0.5104419827461243\n",
      "classification ---- 8940 metric train_loss = 0.4575973033905029\n",
      "classification ---- 8950 metric train_loss = 0.4277095764875412\n",
      "classification ---- 8960 metric train_loss = 0.43188413977622986\n",
      "classification ---- 8970 metric train_loss = 0.4710140436887741\n",
      "classification ---- 8980 metric train_loss = 0.45000462234020233\n",
      "classification ---- 8990 metric train_loss = 0.474711674451828\n",
      "classification ---- 9000 metric train_loss = 0.5279818773269653\n",
      "classification ---- 19 metric test_f1 = 0.8984522953317906\n",
      "classification ---- 19 metric test_accuracy = 0.8954545454545455\n",
      "classification ---- 10 metric train_accuracy = 0.849931787175989\n",
      "classification ---- 10 metric train_f1 = 0.8497215139732928\n",
      "classification ---- 9010 metric train_loss = 0.4543053448200226\n",
      "classification ---- 9020 metric train_loss = 0.42103156447410583\n",
      "classification ---- 9030 metric train_loss = 0.5305691838264466\n",
      "classification ---- 9040 metric train_loss = 0.5118925541639328\n",
      "classification ---- 9050 metric train_loss = 0.4449284732341766\n",
      "classification ---- 9060 metric train_loss = 0.511282029747963\n",
      "classification ---- 9070 metric train_loss = 0.39120187908411025\n",
      "classification ---- 9080 metric train_loss = 0.5139156505465508\n",
      "classification ---- 9090 metric train_loss = 0.43415496647357943\n",
      "classification ---- 9100 metric train_loss = 0.5316541790962219\n",
      "classification ---- 9110 metric train_loss = 0.49752439856529235\n",
      "classification ---- 9120 metric train_loss = 0.4715853542089462\n",
      "classification ---- 9130 metric train_loss = 0.4605181962251663\n",
      "classification ---- 9140 metric train_loss = 0.4632414489984512\n",
      "classification ---- 9150 metric train_loss = 0.4332191586494446\n",
      "classification ---- 9160 metric train_loss = 0.4191338211297989\n",
      "classification ---- 9170 metric train_loss = 0.4559368699789047\n",
      "classification ---- 9180 metric train_loss = 0.5023150205612182\n",
      "classification ---- 9190 metric train_loss = 0.4920948505401611\n",
      "classification ---- 9200 metric train_loss = 0.4754290461540222\n",
      "classification ---- 9210 metric train_loss = 0.49898832738399507\n",
      "classification ---- 9220 metric train_loss = 0.4124255836009979\n",
      "classification ---- 9230 metric train_loss = 0.4505088746547699\n",
      "classification ---- 9240 metric train_loss = 0.411972576379776\n",
      "classification ---- 9250 metric train_loss = 0.49373267889022826\n",
      "classification ---- 9260 metric train_loss = 0.4322738930583\n",
      "classification ---- 9270 metric train_loss = 0.4261732816696167\n",
      "classification ---- 9280 metric train_loss = 0.5199325501918792\n",
      "classification ---- 9290 metric train_loss = 0.4808398485183716\n",
      "classification ---- 9300 metric train_loss = 0.44124650955200195\n",
      "classification ---- 9310 metric train_loss = 0.473095640540123\n",
      "classification ---- 9320 metric train_loss = 0.44761125147342684\n",
      "classification ---- 9330 metric train_loss = 0.465938526391983\n",
      "classification ---- 9340 metric train_loss = 0.48002327382564547\n",
      "classification ---- 9350 metric train_loss = 0.3683396399021149\n",
      "classification ---- 9360 metric train_loss = 0.3906357020139694\n",
      "classification ---- 9370 metric train_loss = 0.48105702102184295\n",
      "classification ---- 9380 metric train_loss = 0.5292600482702255\n",
      "classification ---- 9390 metric train_loss = 0.4842917889356613\n",
      "classification ---- 9400 metric train_loss = 0.46627729535102846\n",
      "classification ---- 9410 metric train_loss = 0.3759083777666092\n",
      "classification ---- 9420 metric train_loss = 0.5166102707386017\n",
      "classification ---- 9430 metric train_loss = 0.47848112881183624\n",
      "classification ---- 9440 metric train_loss = 0.4941092550754547\n",
      "classification ---- 9450 metric train_loss = 0.501845759153366\n",
      "classification ---- 9460 metric train_loss = 0.4456042468547821\n",
      "classification ---- 9470 metric train_loss = 0.48017526268959043\n",
      "classification ---- 9480 metric train_loss = 0.42604720890522\n",
      "classification ---- 9490 metric train_loss = 0.431649374961853\n",
      "classification ---- 9500 metric train_loss = 0.45352114737033844\n",
      "classification ---- 20 metric test_f1 = 0.9000990710762145\n",
      "classification ---- 20 metric test_accuracy = 0.8977272727272727\n",
      "classification ---- 9510 metric train_loss = 0.40026003271341326\n",
      "classification ---- 9520 metric train_loss = 0.4633412569761276\n",
      "classification ---- 9530 metric train_loss = 0.4791798830032349\n",
      "classification ---- 9540 metric train_loss = 0.4403200179338455\n",
      "classification ---- 9550 metric train_loss = 0.46206656396389006\n",
      "classification ---- 9560 metric train_loss = 0.41176621317863465\n",
      "classification ---- 9570 metric train_loss = 0.47687438130378723\n",
      "classification ---- 9580 metric train_loss = 0.49983665645122527\n",
      "classification ---- 9590 metric train_loss = 0.43050424158573153\n",
      "classification ---- 9600 metric train_loss = 0.43034355342388153\n",
      "classification ---- 9610 metric train_loss = 0.39498759210109713\n",
      "classification ---- 9620 metric train_loss = 0.46862092316150666\n",
      "classification ---- 9630 metric train_loss = 0.42859250903129575\n",
      "classification ---- 9640 metric train_loss = 0.44696189761161803\n",
      "classification ---- 9650 metric train_loss = 0.44977793395519255\n",
      "classification ---- 9660 metric train_loss = 0.4966388404369354\n",
      "classification ---- 9670 metric train_loss = 0.4418974816799164\n",
      "classification ---- 9680 metric train_loss = 0.4944311618804932\n",
      "classification ---- 9690 metric train_loss = 0.4854627728462219\n",
      "classification ---- 9700 metric train_loss = 0.4442500829696655\n",
      "classification ---- 9710 metric train_loss = 0.46504453420639036\n",
      "classification ---- 9720 metric train_loss = 0.45863792300224304\n",
      "classification ---- 9730 metric train_loss = 0.4039143562316895\n",
      "classification ---- 9740 metric train_loss = 0.4152889043092728\n",
      "classification ---- 9750 metric train_loss = 0.4574721395969391\n",
      "classification ---- 9760 metric train_loss = 0.4428196340799332\n",
      "classification ---- 9770 metric train_loss = 0.47514883279800413\n",
      "classification ---- 9780 metric train_loss = 0.4720400482416153\n",
      "classification ---- 9790 metric train_loss = 0.4376498252153397\n",
      "classification ---- 9800 metric train_loss = 0.43952388167381284\n",
      "classification ---- 9810 metric train_loss = 0.516800907254219\n",
      "classification ---- 9820 metric train_loss = 0.40636178851127625\n",
      "classification ---- 9830 metric train_loss = 0.4138932764530182\n",
      "classification ---- 9840 metric train_loss = 0.49103931784629823\n",
      "classification ---- 9850 metric train_loss = 0.48858262598514557\n",
      "classification ---- 9860 metric train_loss = 0.39025449752807617\n",
      "classification ---- 9870 metric train_loss = 0.42571237981319426\n",
      "classification ---- 9880 metric train_loss = 0.4745777785778046\n",
      "classification ---- 9890 metric train_loss = 0.4623692035675049\n",
      "classification ---- 9900 metric train_loss = 0.47632154524326326\n",
      "classification ---- 9910 metric train_loss = 0.4397384986281395\n",
      "classification ---- 9920 metric train_loss = 0.4635018527507782\n",
      "classification ---- 9930 metric train_loss = 0.4353919953107834\n",
      "classification ---- 9940 metric train_loss = 0.4316034495830536\n",
      "classification ---- 9950 metric train_loss = 0.48596555590629575\n",
      "classification ---- 9960 metric train_loss = 0.4261653423309326\n",
      "classification ---- 9970 metric train_loss = 0.43827047348022463\n",
      "classification ---- 9980 metric train_loss = 0.4200580924749374\n",
      "classification ---- 9990 metric train_loss = 0.40500240623950956\n",
      "classification ---- 10000 metric train_loss = 0.46254244148731233\n",
      "classification ---- 21 metric test_f1 = 0.9007972197948473\n",
      "classification ---- 21 metric test_accuracy = 0.8931818181818182\n",
      "classification ---- 11 metric train_accuracy = 0.8515234197362438\n",
      "classification ---- 11 metric train_f1 = 0.8532953856846307\n",
      "classification ---- 10010 metric train_loss = 0.44738394021987915\n",
      "classification ---- 10020 metric train_loss = 0.4737643837928772\n",
      "classification ---- 10030 metric train_loss = 0.4258347675204277\n",
      "classification ---- 10040 metric train_loss = 0.4792196124792099\n",
      "classification ---- 10050 metric train_loss = 0.4425492912530899\n",
      "classification ---- 10060 metric train_loss = 0.3981610834598541\n",
      "classification ---- 10070 metric train_loss = 0.44775587916374204\n",
      "classification ---- 10080 metric train_loss = 0.40958712846040723\n",
      "classification ---- 10090 metric train_loss = 0.47679214775562284\n",
      "classification ---- 10100 metric train_loss = 0.39569070339202883\n",
      "classification ---- 10110 metric train_loss = 0.4441550374031067\n",
      "classification ---- 10120 metric train_loss = 0.37397267669439316\n",
      "classification ---- 10130 metric train_loss = 0.4445931643247604\n",
      "classification ---- 10140 metric train_loss = 0.43184466361999513\n",
      "classification ---- 10150 metric train_loss = 0.46139236986637117\n",
      "classification ---- 10160 metric train_loss = 0.4230028107762337\n",
      "classification ---- 10170 metric train_loss = 0.4905804663896561\n",
      "classification ---- 10180 metric train_loss = 0.4307187169790268\n",
      "classification ---- 10190 metric train_loss = 0.4140262231230736\n",
      "classification ---- 10200 metric train_loss = 0.4682943090796471\n",
      "classification ---- 10210 metric train_loss = 0.35628808438777926\n",
      "classification ---- 10220 metric train_loss = 0.44374013543128965\n",
      "classification ---- 10230 metric train_loss = 0.40330528020858764\n",
      "classification ---- 10240 metric train_loss = 0.4497398525476456\n",
      "classification ---- 10250 metric train_loss = 0.4378047525882721\n",
      "classification ---- 10260 metric train_loss = 0.42414188086986543\n",
      "classification ---- 10270 metric train_loss = 0.4004150003194809\n",
      "classification ---- 10280 metric train_loss = 0.4546603888273239\n",
      "classification ---- 10290 metric train_loss = 0.5616696655750275\n",
      "classification ---- 10300 metric train_loss = 0.3727039903402328\n",
      "classification ---- 10310 metric train_loss = 0.39857459664344785\n",
      "classification ---- 10320 metric train_loss = 0.410730305314064\n",
      "classification ---- 10330 metric train_loss = 0.5086698681116104\n",
      "classification ---- 10340 metric train_loss = 0.42377696335315707\n",
      "classification ---- 10350 metric train_loss = 0.4218896940350533\n",
      "classification ---- 10360 metric train_loss = 0.3910947412252426\n",
      "classification ---- 10370 metric train_loss = 0.46901301443576815\n",
      "classification ---- 10380 metric train_loss = 0.3941766157746315\n",
      "classification ---- 10390 metric train_loss = 0.42553154528141024\n",
      "classification ---- 10400 metric train_loss = 0.40327768921852114\n",
      "classification ---- 10410 metric train_loss = 0.4048401564359665\n",
      "classification ---- 10420 metric train_loss = 0.4154704809188843\n",
      "classification ---- 10430 metric train_loss = 0.4171543031930923\n",
      "classification ---- 10440 metric train_loss = 0.48812730610370636\n",
      "classification ---- 10450 metric train_loss = 0.3984617441892624\n",
      "classification ---- 10460 metric train_loss = 0.3932986229658127\n",
      "classification ---- 10470 metric train_loss = 0.4968365401029587\n",
      "classification ---- 10480 metric train_loss = 0.4169664397835732\n",
      "classification ---- 10490 metric train_loss = 0.42229037880897524\n",
      "classification ---- 10500 metric train_loss = 0.4121026277542114\n",
      "classification ---- 22 metric test_f1 = 0.9007980047345484\n",
      "classification ---- 22 metric test_accuracy = 0.8981818181818182\n",
      "classification ---- 10510 metric train_loss = 0.4797493785619736\n",
      "classification ---- 10520 metric train_loss = 0.4392235666513443\n",
      "classification ---- 10530 metric train_loss = 0.4427055537700653\n",
      "classification ---- 10540 metric train_loss = 0.4675693228840828\n",
      "classification ---- 10550 metric train_loss = 0.3867869794368744\n",
      "classification ---- 10560 metric train_loss = 0.42249888777732847\n",
      "classification ---- 10570 metric train_loss = 0.4113117799162865\n",
      "classification ---- 10580 metric train_loss = 0.37756896317005156\n",
      "classification ---- 10590 metric train_loss = 0.4248833298683167\n",
      "classification ---- 10600 metric train_loss = 0.4121431469917297\n",
      "classification ---- 10610 metric train_loss = 0.36207175999879837\n",
      "classification ---- 10620 metric train_loss = 0.4410922318696976\n",
      "classification ---- 10630 metric train_loss = 0.3696294665336609\n",
      "classification ---- 10640 metric train_loss = 0.44613081216812134\n",
      "classification ---- 10650 metric train_loss = 0.42487886250019075\n",
      "classification ---- 10660 metric train_loss = 0.3985156506299973\n",
      "classification ---- 10670 metric train_loss = 0.3799378350377083\n",
      "classification ---- 10680 metric train_loss = 0.4216967910528183\n",
      "classification ---- 10690 metric train_loss = 0.36683503091335296\n",
      "classification ---- 10700 metric train_loss = 0.38497848212718966\n",
      "classification ---- 10710 metric train_loss = 0.5079221844673156\n",
      "classification ---- 10720 metric train_loss = 0.4198484241962433\n",
      "classification ---- 10730 metric train_loss = 0.41760792434215543\n",
      "classification ---- 10740 metric train_loss = 0.4162250518798828\n",
      "classification ---- 10750 metric train_loss = 0.41752171367406843\n",
      "classification ---- 10760 metric train_loss = 0.41395761370658873\n",
      "classification ---- 10770 metric train_loss = 0.37913128584623335\n",
      "classification ---- 10780 metric train_loss = 0.47978529781103135\n",
      "classification ---- 10790 metric train_loss = 0.4356034189462662\n",
      "classification ---- 10800 metric train_loss = 0.47716875970363615\n",
      "classification ---- 10810 metric train_loss = 0.45079244673252106\n",
      "classification ---- 10820 metric train_loss = 0.4039896547794342\n",
      "classification ---- 10830 metric train_loss = 0.45306666791439054\n",
      "classification ---- 10840 metric train_loss = 0.45654643774032594\n",
      "classification ---- 10850 metric train_loss = 0.39515931606292726\n",
      "classification ---- 10860 metric train_loss = 0.38731883466243744\n",
      "classification ---- 10870 metric train_loss = 0.416085048019886\n",
      "classification ---- 10880 metric train_loss = 0.3839173898100853\n",
      "classification ---- 10890 metric train_loss = 0.3831456959247589\n",
      "classification ---- 10900 metric train_loss = 0.4484460696578026\n",
      "classification ---- 10910 metric train_loss = 0.36528800129890443\n",
      "classification ---- 10920 metric train_loss = 0.3924534827470779\n",
      "classification ---- 10930 metric train_loss = 0.46171669363975526\n",
      "classification ---- 10940 metric train_loss = 0.34059617221355437\n",
      "classification ---- 10950 metric train_loss = 0.4205287039279938\n",
      "classification ---- 10960 metric train_loss = 0.4293856680393219\n",
      "classification ---- 10970 metric train_loss = 0.433169487118721\n",
      "classification ---- 10980 metric train_loss = 0.3423673868179321\n",
      "classification ---- 10990 metric train_loss = 0.4276886790990829\n",
      "classification ---- 11000 metric train_loss = 0.45275387167930603\n",
      "classification ---- 23 metric test_f1 = 0.9117731497453949\n",
      "classification ---- 23 metric test_accuracy = 0.9104545454545454\n",
      "classification ---- 12 metric train_accuracy = 0.8647112323783538\n",
      "classification ---- 12 metric train_f1 = 0.8667004595339305\n",
      "classification ---- 11010 metric train_loss = 0.36983822286129\n",
      "classification ---- 11020 metric train_loss = 0.43723514676094055\n",
      "classification ---- 11030 metric train_loss = 0.3979806363582611\n",
      "classification ---- 11040 metric train_loss = 0.3947895050048828\n",
      "classification ---- 11050 metric train_loss = 0.37339441776275634\n",
      "classification ---- 11060 metric train_loss = 0.4204878330230713\n",
      "classification ---- 11070 metric train_loss = 0.39621822237968446\n",
      "classification ---- 11080 metric train_loss = 0.37497907429933547\n",
      "classification ---- 11090 metric train_loss = 0.4680556684732437\n",
      "classification ---- 11100 metric train_loss = 0.4246175244450569\n",
      "classification ---- 11110 metric train_loss = 0.38195855617523194\n",
      "classification ---- 11120 metric train_loss = 0.44401839971542356\n",
      "classification ---- 11130 metric train_loss = 0.3670741006731987\n",
      "classification ---- 11140 metric train_loss = 0.44678540229797364\n",
      "classification ---- 11150 metric train_loss = 0.4217111557722092\n",
      "classification ---- 11160 metric train_loss = 0.389396196603775\n",
      "classification ---- 11170 metric train_loss = 0.40153816491365435\n",
      "classification ---- 11180 metric train_loss = 0.4825890094041824\n",
      "classification ---- 11190 metric train_loss = 0.3779177188873291\n",
      "classification ---- 11200 metric train_loss = 0.3985872745513916\n",
      "classification ---- 11210 metric train_loss = 0.46887713074684145\n",
      "classification ---- 11220 metric train_loss = 0.4333717077970505\n",
      "classification ---- 11230 metric train_loss = 0.4216324582695961\n",
      "classification ---- 11240 metric train_loss = 0.4246155709028244\n",
      "classification ---- 11250 metric train_loss = 0.358675579726696\n",
      "classification ---- 11260 metric train_loss = 0.39099727272987367\n",
      "classification ---- 11270 metric train_loss = 0.3750173360109329\n",
      "classification ---- 11280 metric train_loss = 0.43236650377511976\n",
      "classification ---- 11290 metric train_loss = 0.38607430160045625\n",
      "classification ---- 11300 metric train_loss = 0.39787493646144867\n",
      "classification ---- 11310 metric train_loss = 0.38385680615901946\n",
      "classification ---- 11320 metric train_loss = 0.43962787091732025\n",
      "classification ---- 11330 metric train_loss = 0.4512041687965393\n",
      "classification ---- 11340 metric train_loss = 0.4406779229640961\n",
      "classification ---- 11350 metric train_loss = 0.3931660085916519\n",
      "classification ---- 11360 metric train_loss = 0.3775231510400772\n",
      "classification ---- 11370 metric train_loss = 0.4264234334230423\n",
      "classification ---- 11380 metric train_loss = 0.43733786046504974\n",
      "classification ---- 11390 metric train_loss = 0.41383408159017565\n",
      "classification ---- 11400 metric train_loss = 0.362912979722023\n",
      "classification ---- 11410 metric train_loss = 0.3751374751329422\n",
      "classification ---- 11420 metric train_loss = 0.44228789806365965\n",
      "classification ---- 11430 metric train_loss = 0.4406290799379349\n",
      "classification ---- 11440 metric train_loss = 0.38216382563114165\n",
      "classification ---- 11450 metric train_loss = 0.41323575377464294\n",
      "classification ---- 11460 metric train_loss = 0.4527927994728088\n",
      "classification ---- 11470 metric train_loss = 0.34725886583328247\n",
      "classification ---- 11480 metric train_loss = 0.41176977157592776\n",
      "classification ---- 11490 metric train_loss = 0.32712513506412505\n",
      "classification ---- 11500 metric train_loss = 0.36396492570638656\n",
      "classification ---- 24 metric test_f1 = 0.9061616475490867\n",
      "classification ---- 24 metric test_accuracy = 0.9022727272727272\n",
      "classification ---- 11510 metric train_loss = 0.4436283141374588\n",
      "classification ---- 11520 metric train_loss = 0.3989182710647583\n",
      "classification ---- 11530 metric train_loss = 0.381659160554409\n",
      "classification ---- 11540 metric train_loss = 0.346832187473774\n",
      "classification ---- 11550 metric train_loss = 0.4104340702295303\n",
      "classification ---- 11560 metric train_loss = 0.3980442062020302\n",
      "classification ---- 11570 metric train_loss = 0.4035624474287033\n",
      "classification ---- 11580 metric train_loss = 0.4279192596673965\n",
      "classification ---- 11590 metric train_loss = 0.4170127332210541\n",
      "classification ---- 11600 metric train_loss = 0.3721997946500778\n",
      "classification ---- 11610 metric train_loss = 0.3998948305845261\n",
      "classification ---- 11620 metric train_loss = 0.40868256986141205\n",
      "classification ---- 11630 metric train_loss = 0.4384359121322632\n",
      "classification ---- 11640 metric train_loss = 0.37049448043107985\n",
      "classification ---- 11650 metric train_loss = 0.4400876730680466\n",
      "classification ---- 11660 metric train_loss = 0.3281823217868805\n",
      "classification ---- 11670 metric train_loss = 0.4098078355193138\n",
      "classification ---- 11680 metric train_loss = 0.39276047646999357\n",
      "classification ---- 11690 metric train_loss = 0.34978944808244705\n",
      "classification ---- 11700 metric train_loss = 0.4036374971270561\n",
      "classification ---- 11710 metric train_loss = 0.46603667438030244\n",
      "classification ---- 11720 metric train_loss = 0.3750941142439842\n",
      "classification ---- 11730 metric train_loss = 0.432092958688736\n",
      "classification ---- 11740 metric train_loss = 0.3887647807598114\n",
      "classification ---- 11750 metric train_loss = 0.45332358181476595\n",
      "classification ---- 11760 metric train_loss = 0.4117624431848526\n",
      "classification ---- 11770 metric train_loss = 0.34938154816627504\n",
      "classification ---- 11780 metric train_loss = 0.3880357503890991\n",
      "classification ---- 11790 metric train_loss = 0.38212682604789733\n",
      "classification ---- 11800 metric train_loss = 0.3810198366641998\n",
      "classification ---- 11810 metric train_loss = 0.40218482315540316\n",
      "classification ---- 11820 metric train_loss = 0.4401985168457031\n",
      "classification ---- 11830 metric train_loss = 0.3568555548787117\n",
      "classification ---- 11840 metric train_loss = 0.37714074105024337\n",
      "classification ---- 11850 metric train_loss = 0.3312462270259857\n",
      "classification ---- 11860 metric train_loss = 0.4967782348394394\n",
      "classification ---- 11870 metric train_loss = 0.3604929521679878\n",
      "classification ---- 11880 metric train_loss = 0.5022478014230728\n",
      "classification ---- 11890 metric train_loss = 0.3635997295379639\n",
      "classification ---- 11900 metric train_loss = 0.36382037699222564\n",
      "classification ---- 11910 metric train_loss = 0.3141644597053528\n",
      "classification ---- 11920 metric train_loss = 0.44699310660362246\n",
      "classification ---- 11930 metric train_loss = 0.32653034180402757\n",
      "classification ---- 11940 metric train_loss = 0.42661885917186737\n",
      "classification ---- 11950 metric train_loss = 0.396127986907959\n",
      "classification ---- 11960 metric train_loss = 0.38655007928609847\n",
      "classification ---- 11970 metric train_loss = 0.4106197014451027\n",
      "classification ---- 11980 metric train_loss = 0.42214718759059905\n",
      "classification ---- 11990 metric train_loss = 0.3775557100772858\n",
      "classification ---- 12000 metric train_loss = 0.33341696560382844\n",
      "classification ---- 25 metric test_f1 = 0.9087970582034629\n",
      "classification ---- 25 metric test_accuracy = 0.9027272727272727\n",
      "classification ---- 13 metric train_accuracy = 0.8681218735788995\n",
      "classification ---- 13 metric train_f1 = 0.8710827409263009\n",
      "classification ---- 12010 metric train_loss = 0.3996765375137329\n",
      "classification ---- 12020 metric train_loss = 0.37328108251094816\n",
      "classification ---- 12030 metric train_loss = 0.4461427241563797\n",
      "classification ---- 12040 metric train_loss = 0.37233335971832277\n",
      "classification ---- 12050 metric train_loss = 0.3703443631529808\n",
      "classification ---- 12060 metric train_loss = 0.43545827865600584\n",
      "classification ---- 12070 metric train_loss = 0.3634718060493469\n",
      "classification ---- 12080 metric train_loss = 0.43370712399482725\n",
      "classification ---- 12090 metric train_loss = 0.36524627506732943\n",
      "classification ---- 12100 metric train_loss = 0.37304321974515914\n",
      "classification ---- 12110 metric train_loss = 0.39703715443611143\n",
      "classification ---- 12120 metric train_loss = 0.3977867752313614\n",
      "classification ---- 12130 metric train_loss = 0.3846930354833603\n",
      "classification ---- 12140 metric train_loss = 0.40798862278461456\n",
      "classification ---- 12150 metric train_loss = 0.3922088578343391\n",
      "classification ---- 12160 metric train_loss = 0.43126015961170194\n",
      "classification ---- 12170 metric train_loss = 0.4262411132454872\n",
      "classification ---- 12180 metric train_loss = 0.38256716877222063\n",
      "classification ---- 12190 metric train_loss = 0.3641937017440796\n",
      "classification ---- 12200 metric train_loss = 0.36481987237930297\n",
      "classification ---- 12210 metric train_loss = 0.3721075713634491\n",
      "classification ---- 12220 metric train_loss = 0.3984712868928909\n",
      "classification ---- 12230 metric train_loss = 0.35267866104841233\n",
      "classification ---- 12240 metric train_loss = 0.39041038155555724\n",
      "classification ---- 12250 metric train_loss = 0.3426010191440582\n",
      "classification ---- 12260 metric train_loss = 0.39379712343215945\n",
      "classification ---- 12270 metric train_loss = 0.41544982641935346\n",
      "classification ---- 12280 metric train_loss = 0.35750904977321624\n",
      "classification ---- 12290 metric train_loss = 0.3716705560684204\n",
      "classification ---- 12300 metric train_loss = 0.40524314641952514\n",
      "classification ---- 12310 metric train_loss = 0.3859735906124115\n",
      "classification ---- 12320 metric train_loss = 0.38359109610319136\n",
      "classification ---- 12330 metric train_loss = 0.36084367632865905\n",
      "classification ---- 12340 metric train_loss = 0.40933718383312223\n",
      "classification ---- 12350 metric train_loss = 0.34159577190876006\n",
      "classification ---- 12360 metric train_loss = 0.3587425246834755\n",
      "classification ---- 12370 metric train_loss = 0.3155669793486595\n",
      "classification ---- 12380 metric train_loss = 0.33567616045475007\n",
      "classification ---- 12390 metric train_loss = 0.41463335752487185\n",
      "classification ---- 12400 metric train_loss = 0.4068025380373001\n",
      "classification ---- 12410 metric train_loss = 0.36273428052663803\n",
      "classification ---- 12420 metric train_loss = 0.4292879730463028\n",
      "classification ---- 12430 metric train_loss = 0.42680382132530215\n",
      "classification ---- 12440 metric train_loss = 0.42516788840293884\n",
      "classification ---- 12450 metric train_loss = 0.42625032365322113\n",
      "classification ---- 12460 metric train_loss = 0.3698340117931366\n",
      "classification ---- 12470 metric train_loss = 0.37191261649131774\n",
      "classification ---- 12480 metric train_loss = 0.4141252800822258\n",
      "classification ---- 12490 metric train_loss = 0.32446336299180983\n",
      "classification ---- 12500 metric train_loss = 0.3421237602829933\n",
      "classification ---- 26 metric test_f1 = 0.9112257280983116\n",
      "classification ---- 26 metric test_accuracy = 0.9081818181818182\n",
      "classification ---- 12510 metric train_loss = 0.36661744862794876\n",
      "classification ---- 12520 metric train_loss = 0.35113733559846877\n",
      "classification ---- 12530 metric train_loss = 0.3994926601648331\n",
      "classification ---- 12540 metric train_loss = 0.3824314475059509\n",
      "classification ---- 12550 metric train_loss = 0.39471071064472196\n",
      "classification ---- 12560 metric train_loss = 0.3528647854924202\n",
      "classification ---- 12570 metric train_loss = 0.33161322623491285\n",
      "classification ---- 12580 metric train_loss = 0.4027869775891304\n",
      "classification ---- 12590 metric train_loss = 0.41988442838191986\n",
      "classification ---- 12600 metric train_loss = 0.46656631529331205\n",
      "classification ---- 12610 metric train_loss = 0.4182939201593399\n",
      "classification ---- 12620 metric train_loss = 0.3332932323217392\n",
      "classification ---- 12630 metric train_loss = 0.4280316591262817\n",
      "classification ---- 12640 metric train_loss = 0.40194583535194395\n",
      "classification ---- 12650 metric train_loss = 0.3871294319629669\n",
      "classification ---- 12660 metric train_loss = 0.35473419576883314\n",
      "classification ---- 12670 metric train_loss = 0.39230097234249117\n",
      "classification ---- 12680 metric train_loss = 0.36705304533243177\n",
      "classification ---- 12690 metric train_loss = 0.3340449795126915\n",
      "classification ---- 12700 metric train_loss = 0.38788498342037203\n",
      "classification ---- 12710 metric train_loss = 0.3549001917243004\n",
      "classification ---- 12720 metric train_loss = 0.42916316241025926\n",
      "classification ---- 12730 metric train_loss = 0.34255316853523254\n",
      "classification ---- 12740 metric train_loss = 0.3808714643120766\n",
      "classification ---- 12750 metric train_loss = 0.4051771551370621\n",
      "classification ---- 12760 metric train_loss = 0.36338163912296295\n",
      "classification ---- 12770 metric train_loss = 0.3734484285116196\n",
      "classification ---- 12780 metric train_loss = 0.38858127743005755\n",
      "classification ---- 12790 metric train_loss = 0.39157710373401644\n",
      "classification ---- 12800 metric train_loss = 0.37511213421821593\n",
      "classification ---- 12810 metric train_loss = 0.34889219254255294\n",
      "classification ---- 12820 metric train_loss = 0.35043629705905915\n",
      "classification ---- 12830 metric train_loss = 0.38220212459564207\n",
      "classification ---- 12840 metric train_loss = 0.3801941379904747\n",
      "classification ---- 12850 metric train_loss = 0.3937265038490295\n",
      "classification ---- 12860 metric train_loss = 0.3689465194940567\n",
      "classification ---- 12870 metric train_loss = 0.4181761458516121\n",
      "classification ---- 12880 metric train_loss = 0.37932310104370115\n",
      "classification ---- 12890 metric train_loss = 0.3352886289358139\n",
      "classification ---- 12900 metric train_loss = 0.3957004934549332\n",
      "classification ---- 12910 metric train_loss = 0.43091253042221067\n",
      "classification ---- 12920 metric train_loss = 0.3447591230273247\n",
      "classification ---- 12930 metric train_loss = 0.3417975202202797\n",
      "classification ---- 12940 metric train_loss = 0.346014204621315\n",
      "classification ---- 12950 metric train_loss = 0.32707642316818236\n",
      "classification ---- 12960 metric train_loss = 0.4188046157360077\n",
      "classification ---- 12970 metric train_loss = 0.4351151645183563\n",
      "classification ---- 12980 metric train_loss = 0.4608318656682968\n",
      "classification ---- 12990 metric train_loss = 0.3946139797568321\n",
      "classification ---- 13000 metric train_loss = 0.3613545849919319\n",
      "classification ---- 27 metric test_f1 = 0.9054869556317102\n",
      "classification ---- 27 metric test_accuracy = 0.9009090909090909\n",
      "classification ---- 14 metric train_accuracy = 0.8786948613005912\n",
      "classification ---- 14 metric train_f1 = 0.8803802205177454\n",
      "classification ---- 13010 metric train_loss = 0.3974075436592102\n",
      "classification ---- 13020 metric train_loss = 0.32465607225894927\n",
      "classification ---- 13030 metric train_loss = 0.3300916016101837\n",
      "classification ---- 13040 metric train_loss = 0.4106867477297783\n",
      "classification ---- 13050 metric train_loss = 0.3788642093539238\n",
      "classification ---- 13060 metric train_loss = 0.31915283352136614\n",
      "classification ---- 13070 metric train_loss = 0.4039838135242462\n",
      "classification ---- 13080 metric train_loss = 0.3705159991979599\n",
      "classification ---- 13090 metric train_loss = 0.3613345682621002\n",
      "classification ---- 13100 metric train_loss = 0.36560321152210234\n",
      "classification ---- 13110 metric train_loss = 0.4136188477277756\n",
      "classification ---- 13120 metric train_loss = 0.33275585025548937\n",
      "classification ---- 13130 metric train_loss = 0.31963195502758024\n",
      "classification ---- 13140 metric train_loss = 0.38019085079431536\n",
      "classification ---- 13150 metric train_loss = 0.39079236835241316\n",
      "classification ---- 13160 metric train_loss = 0.39860205352306366\n",
      "classification ---- 13170 metric train_loss = 0.3428800255060196\n",
      "classification ---- 13180 metric train_loss = 0.3852759450674057\n",
      "classification ---- 13190 metric train_loss = 0.3307796910405159\n",
      "classification ---- 13200 metric train_loss = 0.39376469552516935\n",
      "classification ---- 13210 metric train_loss = 0.31892107874155046\n",
      "classification ---- 13220 metric train_loss = 0.4059439480304718\n",
      "classification ---- 13230 metric train_loss = 0.3763814091682434\n",
      "classification ---- 13240 metric train_loss = 0.33773285448551177\n",
      "classification ---- 13250 metric train_loss = 0.3660884499549866\n",
      "classification ---- 13260 metric train_loss = 0.40232210904359816\n",
      "classification ---- 13270 metric train_loss = 0.4267563819885254\n",
      "classification ---- 13280 metric train_loss = 0.3424901947379112\n",
      "classification ---- 13290 metric train_loss = 0.38981427550315856\n",
      "classification ---- 13300 metric train_loss = 0.42996578812599184\n",
      "classification ---- 13310 metric train_loss = 0.3943772777915001\n",
      "classification ---- 13320 metric train_loss = 0.29743838161230085\n",
      "classification ---- 13330 metric train_loss = 0.3738971710205078\n",
      "classification ---- 13340 metric train_loss = 0.3446314886212349\n",
      "classification ---- 13350 metric train_loss = 0.38722266256809235\n",
      "classification ---- 13360 metric train_loss = 0.30172954499721527\n",
      "classification ---- 13370 metric train_loss = 0.3838804721832275\n",
      "classification ---- 13380 metric train_loss = 0.37699162811040876\n",
      "classification ---- 13390 metric train_loss = 0.37435416877269745\n",
      "classification ---- 13400 metric train_loss = 0.32075442373752594\n",
      "classification ---- 13410 metric train_loss = 0.3963456779718399\n",
      "classification ---- 13420 metric train_loss = 0.33643650114536283\n",
      "classification ---- 13430 metric train_loss = 0.376415042579174\n",
      "classification ---- 13440 metric train_loss = 0.33722180873155594\n",
      "classification ---- 13450 metric train_loss = 0.32113488018512726\n",
      "classification ---- 13460 metric train_loss = 0.3463093489408493\n",
      "classification ---- 13470 metric train_loss = 0.3397846221923828\n",
      "classification ---- 13480 metric train_loss = 0.33283667266368866\n",
      "classification ---- 13490 metric train_loss = 0.39566505551338194\n",
      "classification ---- 13500 metric train_loss = 0.3813808798789978\n",
      "classification ---- 28 metric test_f1 = 0.9086600920239626\n",
      "classification ---- 28 metric test_accuracy = 0.9027272727272727\n",
      "classification ---- 13510 metric train_loss = 0.3805576890707016\n",
      "classification ---- 13520 metric train_loss = 0.35006932616233827\n",
      "classification ---- 13530 metric train_loss = 0.34300353527069094\n",
      "classification ---- 13540 metric train_loss = 0.4415421038866043\n",
      "classification ---- 13550 metric train_loss = 0.33208690136671065\n",
      "classification ---- 13560 metric train_loss = 0.3808324545621872\n",
      "classification ---- 13570 metric train_loss = 0.3551739796996117\n",
      "classification ---- 13580 metric train_loss = 0.44031100273132323\n",
      "classification ---- 13590 metric train_loss = 0.3590035825967789\n",
      "classification ---- 13600 metric train_loss = 0.38815116286277773\n",
      "classification ---- 13610 metric train_loss = 0.36820032000541686\n",
      "classification ---- 13620 metric train_loss = 0.38194447457790376\n",
      "classification ---- 13630 metric train_loss = 0.3531924024224281\n",
      "classification ---- 13640 metric train_loss = 0.37962511330842974\n",
      "classification ---- 13650 metric train_loss = 0.3343373090028763\n",
      "classification ---- 13660 metric train_loss = 0.34771249294281004\n",
      "classification ---- 13670 metric train_loss = 0.34672041833400724\n",
      "classification ---- 13680 metric train_loss = 0.34980170875787736\n",
      "classification ---- 13690 metric train_loss = 0.31755889654159547\n",
      "classification ---- 13700 metric train_loss = 0.30883961021900175\n",
      "classification ---- 13710 metric train_loss = 0.3683911323547363\n",
      "classification ---- 13720 metric train_loss = 0.3966751039028168\n",
      "classification ---- 13730 metric train_loss = 0.36662511974573136\n",
      "classification ---- 13740 metric train_loss = 0.3723086714744568\n",
      "classification ---- 13750 metric train_loss = 0.3745728462934494\n",
      "classification ---- 13760 metric train_loss = 0.36192854940891267\n",
      "classification ---- 13770 metric train_loss = 0.43287056386470796\n",
      "classification ---- 13780 metric train_loss = 0.3452389031648636\n",
      "classification ---- 13790 metric train_loss = 0.33304393738508226\n",
      "classification ---- 13800 metric train_loss = 0.3603548929095268\n",
      "classification ---- 13810 metric train_loss = 0.343506221473217\n",
      "classification ---- 13820 metric train_loss = 0.3401593238115311\n",
      "classification ---- 13830 metric train_loss = 0.40167015343904494\n",
      "classification ---- 13840 metric train_loss = 0.3516495853662491\n",
      "classification ---- 13850 metric train_loss = 0.3298040747642517\n",
      "classification ---- 13860 metric train_loss = 0.3538310512900352\n",
      "classification ---- 13870 metric train_loss = 0.33841304630041125\n",
      "classification ---- 13880 metric train_loss = 0.35992986112833025\n",
      "classification ---- 13890 metric train_loss = 0.3611420333385468\n",
      "classification ---- 13900 metric train_loss = 0.28150607496500013\n",
      "classification ---- 13910 metric train_loss = 0.33499807119369507\n",
      "classification ---- 13920 metric train_loss = 0.34965634942054746\n",
      "classification ---- 13930 metric train_loss = 0.38680849969387054\n",
      "classification ---- 13940 metric train_loss = 0.3670962482690811\n",
      "classification ---- 13950 metric train_loss = 0.37621353268623353\n",
      "classification ---- 13960 metric train_loss = 0.3361528813838959\n",
      "classification ---- 13970 metric train_loss = 0.35310557037591933\n",
      "classification ---- 13980 metric train_loss = 0.35660135447978974\n",
      "classification ---- 13990 metric train_loss = 0.35184630304574965\n",
      "classification ---- 14000 metric train_loss = 0.3606839805841446\n",
      "classification ---- 29 metric test_f1 = 0.9096753252144841\n",
      "classification ---- 29 metric test_accuracy = 0.9054545454545454\n",
      "classification ---- 15 metric train_accuracy = 0.8839245111414279\n",
      "classification ---- 15 metric train_f1 = 0.8867595034165083\n",
      "classification ---- 14010 metric train_loss = 0.31209726482629774\n",
      "classification ---- 14020 metric train_loss = 0.3879577130079269\n",
      "classification ---- 14030 metric train_loss = 0.34557436406612396\n",
      "classification ---- 14040 metric train_loss = 0.3107157588005066\n",
      "classification ---- 14050 metric train_loss = 0.3155897781252861\n",
      "classification ---- 14060 metric train_loss = 0.3893539264798164\n",
      "classification ---- 14070 metric train_loss = 0.3966672495007515\n",
      "classification ---- 14080 metric train_loss = 0.3609158143401146\n",
      "classification ---- 14090 metric train_loss = 0.3333911016583443\n",
      "classification ---- 14100 metric train_loss = 0.3339677765965462\n",
      "classification ---- 14110 metric train_loss = 0.41385785639286043\n",
      "classification ---- 14120 metric train_loss = 0.3915039300918579\n",
      "classification ---- 14130 metric train_loss = 0.3094450294971466\n",
      "classification ---- 14140 metric train_loss = 0.33479451537132265\n",
      "classification ---- 14150 metric train_loss = 0.3835282862186432\n",
      "classification ---- 14160 metric train_loss = 0.35701375603675845\n",
      "classification ---- 14170 metric train_loss = 0.3370681285858154\n",
      "classification ---- 14180 metric train_loss = 0.3488954335451126\n",
      "classification ---- 14190 metric train_loss = 0.4224574103951454\n",
      "classification ---- 14200 metric train_loss = 0.3647475078701973\n",
      "classification ---- 14210 metric train_loss = 0.35574625730514525\n",
      "classification ---- 14220 metric train_loss = 0.39564701318740847\n",
      "classification ---- 14230 metric train_loss = 0.396090929210186\n",
      "classification ---- 14240 metric train_loss = 0.3157260656356812\n",
      "classification ---- 14250 metric train_loss = 0.34644332379102705\n",
      "classification ---- 14260 metric train_loss = 0.3388244122266769\n",
      "classification ---- 14270 metric train_loss = 0.37508573681116103\n",
      "classification ---- 14280 metric train_loss = 0.3444306939840317\n",
      "classification ---- 14290 metric train_loss = 0.3534302219748497\n",
      "classification ---- 14300 metric train_loss = 0.3856404185295105\n",
      "classification ---- 14310 metric train_loss = 0.3488679513335228\n",
      "classification ---- 14320 metric train_loss = 0.3869226187467575\n",
      "classification ---- 14330 metric train_loss = 0.36997643709182737\n",
      "classification ---- 14340 metric train_loss = 0.30658112466335297\n",
      "classification ---- 14350 metric train_loss = 0.35628507733345033\n",
      "classification ---- 14360 metric train_loss = 0.3286982744932175\n",
      "classification ---- 14370 metric train_loss = 0.3539561241865158\n",
      "classification ---- 14380 metric train_loss = 0.3295099765062332\n",
      "classification ---- 14390 metric train_loss = 0.38002597689628603\n",
      "classification ---- 14400 metric train_loss = 0.3135162487626076\n",
      "classification ---- 14410 metric train_loss = 0.3832593262195587\n",
      "classification ---- 14420 metric train_loss = 0.33518741428852084\n",
      "classification ---- 14430 metric train_loss = 0.3282367423176765\n",
      "classification ---- 14440 metric train_loss = 0.3647041290998459\n",
      "classification ---- 14450 metric train_loss = 0.31440911144018174\n",
      "classification ---- 14460 metric train_loss = 0.34028656259179113\n",
      "classification ---- 14470 metric train_loss = 0.3460638731718063\n",
      "classification ---- 14480 metric train_loss = 0.376873180270195\n",
      "classification ---- 14490 metric train_loss = 0.3466670364141464\n",
      "classification ---- 14500 metric train_loss = 0.30029631704092025\n",
      "classification ---- 30 metric test_f1 = 0.9121514974769417\n",
      "classification ---- 30 metric test_accuracy = 0.9081818181818182\n",
      "classification ---- 14510 metric train_loss = 0.36254818439483644\n",
      "classification ---- 14520 metric train_loss = 0.29778060764074327\n",
      "classification ---- 14530 metric train_loss = 0.33456030189991\n",
      "classification ---- 14540 metric train_loss = 0.3721764624118805\n",
      "classification ---- 14550 metric train_loss = 0.30053054392337797\n",
      "classification ---- 14560 metric train_loss = 0.34916077852249144\n",
      "classification ---- 14570 metric train_loss = 0.35360618978738784\n",
      "classification ---- 14580 metric train_loss = 0.30859364867210387\n",
      "classification ---- 14590 metric train_loss = 0.3501780107617378\n",
      "classification ---- 14600 metric train_loss = 0.3684866279363632\n",
      "classification ---- 14610 metric train_loss = 0.38295856714248655\n",
      "classification ---- 14620 metric train_loss = 0.33840843439102175\n",
      "classification ---- 14630 metric train_loss = 0.3359756082296371\n",
      "classification ---- 14640 metric train_loss = 0.33262351155281067\n",
      "classification ---- 14650 metric train_loss = 0.36088028699159624\n",
      "classification ---- 14660 metric train_loss = 0.4024417981505394\n",
      "classification ---- 14670 metric train_loss = 0.36514005810022354\n",
      "classification ---- 14680 metric train_loss = 0.3731814235448837\n",
      "classification ---- 14690 metric train_loss = 0.355314177274704\n",
      "classification ---- 14700 metric train_loss = 0.34694313406944277\n",
      "classification ---- 14710 metric train_loss = 0.3413990274071693\n",
      "classification ---- 14720 metric train_loss = 0.3529667392373085\n",
      "classification ---- 14730 metric train_loss = 0.34479546546936035\n",
      "classification ---- 14740 metric train_loss = 0.34211951941251756\n",
      "classification ---- 14750 metric train_loss = 0.32004536837339403\n",
      "classification ---- 14760 metric train_loss = 0.3771258816123009\n",
      "classification ---- 14770 metric train_loss = 0.33648529797792437\n",
      "classification ---- 14780 metric train_loss = 0.3136985808610916\n",
      "classification ---- 14790 metric train_loss = 0.3720507755875587\n",
      "classification ---- 14800 metric train_loss = 0.38128441721200945\n",
      "classification ---- 14810 metric train_loss = 0.28671086579561234\n",
      "classification ---- 14820 metric train_loss = 0.295539553463459\n",
      "classification ---- 14830 metric train_loss = 0.3587512895464897\n",
      "classification ---- 14840 metric train_loss = 0.3710107013583183\n",
      "classification ---- 14850 metric train_loss = 0.33146233931183816\n",
      "classification ---- 14860 metric train_loss = 0.34471984654664994\n",
      "classification ---- 14870 metric train_loss = 0.37035317718982697\n",
      "classification ---- 14880 metric train_loss = 0.36391655057668687\n",
      "classification ---- 14890 metric train_loss = 0.3064990624785423\n",
      "classification ---- 14900 metric train_loss = 0.2900233119726181\n",
      "classification ---- 14910 metric train_loss = 0.30351465195417404\n",
      "classification ---- 14920 metric train_loss = 0.37816868126392367\n",
      "classification ---- 14930 metric train_loss = 0.34396073669195176\n",
      "classification ---- 14940 metric train_loss = 0.2972972795367241\n",
      "classification ---- 14950 metric train_loss = 0.2654888018965721\n",
      "classification ---- 14960 metric train_loss = 0.2730559706687927\n",
      "classification ---- 14970 metric train_loss = 0.31731702387332916\n",
      "classification ---- 14980 metric train_loss = 0.3591875463724136\n",
      "classification ---- 14990 metric train_loss = 0.32971773743629457\n",
      "classification ---- 15000 metric train_loss = 0.33492687046527864\n",
      "classification ---- 31 metric test_f1 = 0.9140590317362042\n",
      "classification ---- 31 metric test_accuracy = 0.915\n",
      "classification ---- 16 metric train_accuracy = 0.8902910413824465\n",
      "classification ---- 16 metric train_f1 = 0.8920522844600247\n",
      "classification ---- 15010 metric train_loss = 0.3817457318305969\n",
      "classification ---- 15020 metric train_loss = 0.44517009556293485\n",
      "classification ---- 15030 metric train_loss = 0.30867875963449476\n",
      "classification ---- 15040 metric train_loss = 0.3779167875647545\n",
      "classification ---- 15050 metric train_loss = 0.3233364179730415\n",
      "classification ---- 15060 metric train_loss = 0.3358606085181236\n",
      "classification ---- 15070 metric train_loss = 0.32160492390394213\n",
      "classification ---- 15080 metric train_loss = 0.35360306352376936\n",
      "classification ---- 15090 metric train_loss = 0.337735316157341\n",
      "classification ---- 15100 metric train_loss = 0.31125138252973555\n",
      "classification ---- 15110 metric train_loss = 0.32089538425207137\n",
      "classification ---- 15120 metric train_loss = 0.32955153584480285\n",
      "classification ---- 15130 metric train_loss = 0.2964017778635025\n",
      "classification ---- 15140 metric train_loss = 0.3419435307383537\n",
      "classification ---- 15150 metric train_loss = 0.3073934942483902\n",
      "classification ---- 15160 metric train_loss = 0.3576315566897392\n",
      "classification ---- 15170 metric train_loss = 0.37973280251026154\n",
      "classification ---- 15180 metric train_loss = 0.38123962879180906\n",
      "classification ---- 15190 metric train_loss = 0.2993022292852402\n",
      "classification ---- 15200 metric train_loss = 0.308293217420578\n",
      "classification ---- 15210 metric train_loss = 0.3614204257726669\n",
      "classification ---- 15220 metric train_loss = 0.34160298109054565\n",
      "classification ---- 15230 metric train_loss = 0.33474005609750745\n",
      "classification ---- 15240 metric train_loss = 0.3582874447107315\n",
      "classification ---- 15250 metric train_loss = 0.2964072063565254\n",
      "classification ---- 15260 metric train_loss = 0.30239117294549944\n",
      "classification ---- 15270 metric train_loss = 0.2911598563194275\n",
      "classification ---- 15280 metric train_loss = 0.3238611489534378\n",
      "classification ---- 15290 metric train_loss = 0.3768991380929947\n",
      "classification ---- 15300 metric train_loss = 0.3559124305844307\n",
      "classification ---- 15310 metric train_loss = 0.35454124212265015\n",
      "classification ---- 15320 metric train_loss = 0.29167159348726274\n",
      "classification ---- 15330 metric train_loss = 0.3160208374261856\n",
      "classification ---- 15340 metric train_loss = 0.30103152692317964\n",
      "classification ---- 15350 metric train_loss = 0.3445921391248703\n",
      "classification ---- 15360 metric train_loss = 0.3566578671336174\n",
      "classification ---- 15370 metric train_loss = 0.3350839376449585\n",
      "classification ---- 15380 metric train_loss = 0.3123218804597855\n",
      "classification ---- 15390 metric train_loss = 0.34506248533725736\n",
      "classification ---- 15400 metric train_loss = 0.30583065152168276\n",
      "classification ---- 15410 metric train_loss = 0.31510275453329084\n",
      "classification ---- 15420 metric train_loss = 0.3326559990644455\n",
      "classification ---- 15430 metric train_loss = 0.28960927575826645\n",
      "classification ---- 15440 metric train_loss = 0.2640791803598404\n",
      "classification ---- 15450 metric train_loss = 0.3288080349564552\n",
      "classification ---- 15460 metric train_loss = 0.3040373459458351\n",
      "classification ---- 15470 metric train_loss = 0.39739723652601244\n",
      "classification ---- 15480 metric train_loss = 0.2937686026096344\n",
      "classification ---- 15490 metric train_loss = 0.32344735562801363\n",
      "classification ---- 15500 metric train_loss = 0.3207686424255371\n",
      "classification ---- 32 metric test_f1 = 0.9088211438904972\n",
      "classification ---- 32 metric test_accuracy = 0.9063636363636364\n",
      "classification ---- 15510 metric train_loss = 0.33858362287282945\n",
      "classification ---- 15520 metric train_loss = 0.33832557797431945\n",
      "classification ---- 15530 metric train_loss = 0.375185689330101\n",
      "classification ---- 15540 metric train_loss = 0.3081842720508575\n",
      "classification ---- 15550 metric train_loss = 0.337597031891346\n",
      "classification ---- 15560 metric train_loss = 0.32238246202468873\n",
      "classification ---- 15570 metric train_loss = 0.36108655780553817\n",
      "classification ---- 15580 metric train_loss = 0.338998019695282\n",
      "classification ---- 15590 metric train_loss = 0.33303512036800387\n",
      "classification ---- 15600 metric train_loss = 0.3397179126739502\n",
      "classification ---- 15610 metric train_loss = 0.2980181038379669\n",
      "classification ---- 15620 metric train_loss = 0.34986802786588667\n",
      "classification ---- 15630 metric train_loss = 0.3007771477103233\n",
      "classification ---- 15640 metric train_loss = 0.312593886256218\n",
      "classification ---- 15650 metric train_loss = 0.35853670686483385\n",
      "classification ---- 15660 metric train_loss = 0.30134953558444977\n",
      "classification ---- 15670 metric train_loss = 0.357674740254879\n",
      "classification ---- 15680 metric train_loss = 0.29727359861135483\n",
      "classification ---- 15690 metric train_loss = 0.2694270297884941\n",
      "classification ---- 15700 metric train_loss = 0.3199379414319992\n",
      "classification ---- 15710 metric train_loss = 0.34509434551000595\n",
      "classification ---- 15720 metric train_loss = 0.33683652579784396\n",
      "classification ---- 15730 metric train_loss = 0.33959008753299713\n",
      "classification ---- 15740 metric train_loss = 0.36355880498886106\n",
      "classification ---- 15750 metric train_loss = 0.36391526609659197\n",
      "classification ---- 15760 metric train_loss = 0.3114543348550797\n",
      "classification ---- 15770 metric train_loss = 0.269549572467804\n",
      "classification ---- 15780 metric train_loss = 0.34129505306482316\n",
      "classification ---- 15790 metric train_loss = 0.2896765947341919\n",
      "classification ---- 15800 metric train_loss = 0.32134990245103834\n",
      "classification ---- 15810 metric train_loss = 0.3596297413110733\n",
      "classification ---- 15820 metric train_loss = 0.35858037769794465\n",
      "classification ---- 15830 metric train_loss = 0.3041410446166992\n",
      "classification ---- 15840 metric train_loss = 0.3330374971032143\n",
      "classification ---- 15850 metric train_loss = 0.35337854623794557\n",
      "classification ---- 15860 metric train_loss = 0.2695522591471672\n",
      "classification ---- 15870 metric train_loss = 0.3084702879190445\n",
      "classification ---- 15880 metric train_loss = 0.32475347965955736\n",
      "classification ---- 15890 metric train_loss = 0.35545559525489806\n",
      "classification ---- 15900 metric train_loss = 0.3077679917216301\n",
      "classification ---- 15910 metric train_loss = 0.30533420145511625\n",
      "classification ---- 15920 metric train_loss = 0.3117718145251274\n",
      "classification ---- 15930 metric train_loss = 0.28035159707069396\n",
      "classification ---- 15940 metric train_loss = 0.26973043084144593\n",
      "classification ---- 15950 metric train_loss = 0.3677427679300308\n",
      "classification ---- 15960 metric train_loss = 0.2855790004134178\n",
      "classification ---- 15970 metric train_loss = 0.2515149191021919\n",
      "classification ---- 15980 metric train_loss = 0.3607670679688454\n",
      "classification ---- 15990 metric train_loss = 0.3405529260635376\n",
      "classification ---- 16000 metric train_loss = 0.3652208372950554\n",
      "classification ---- 33 metric test_f1 = 0.9046420530709425\n",
      "classification ---- 33 metric test_accuracy = 0.9013636363636364\n",
      "classification ---- 17 metric train_accuracy = 0.882787630741246\n",
      "classification ---- 17 metric train_f1 = 0.8856150034991546\n",
      "classification ---- 16010 metric train_loss = 0.33802558183670045\n",
      "classification ---- 16020 metric train_loss = 0.3280409127473831\n",
      "classification ---- 16030 metric train_loss = 0.31772977858781815\n",
      "classification ---- 16040 metric train_loss = 0.31953609436750413\n",
      "classification ---- 16050 metric train_loss = 0.3171362653374672\n",
      "classification ---- 16060 metric train_loss = 0.31401596069335935\n",
      "classification ---- 16070 metric train_loss = 0.31927539259195326\n",
      "classification ---- 16080 metric train_loss = 0.3064377844333649\n",
      "classification ---- 16090 metric train_loss = 0.35377281010150907\n",
      "classification ---- 16100 metric train_loss = 0.2828551411628723\n",
      "classification ---- 16110 metric train_loss = 0.35745440870523454\n",
      "classification ---- 16120 metric train_loss = 0.3795552313327789\n",
      "classification ---- 16130 metric train_loss = 0.29625376164913175\n",
      "classification ---- 16140 metric train_loss = 0.33783884793519975\n",
      "classification ---- 16150 metric train_loss = 0.2792374834418297\n",
      "classification ---- 16160 metric train_loss = 0.35284324288368224\n",
      "classification ---- 16170 metric train_loss = 0.269126458466053\n",
      "classification ---- 16180 metric train_loss = 0.28810626864433286\n",
      "classification ---- 16190 metric train_loss = 0.34684886783361435\n",
      "classification ---- 16200 metric train_loss = 0.3097966641187668\n",
      "classification ---- 16210 metric train_loss = 0.37005643993616105\n",
      "classification ---- 16220 metric train_loss = 0.30941006243228913\n",
      "classification ---- 16230 metric train_loss = 0.33125599920749665\n",
      "classification ---- 16240 metric train_loss = 0.27916296273469926\n",
      "classification ---- 16250 metric train_loss = 0.3523528665304184\n",
      "classification ---- 16260 metric train_loss = 0.2863862946629524\n",
      "classification ---- 16270 metric train_loss = 0.31318639069795606\n",
      "classification ---- 16280 metric train_loss = 0.36832956671714784\n",
      "classification ---- 16290 metric train_loss = 0.2826540097594261\n",
      "classification ---- 16300 metric train_loss = 0.30607476383447646\n",
      "classification ---- 16310 metric train_loss = 0.26694899797439575\n",
      "classification ---- 16320 metric train_loss = 0.3539109915494919\n",
      "classification ---- 16330 metric train_loss = 0.33777761459350586\n",
      "classification ---- 16340 metric train_loss = 0.384145987033844\n",
      "classification ---- 16350 metric train_loss = 0.3528082564473152\n",
      "classification ---- 16360 metric train_loss = 0.31234760880470275\n",
      "classification ---- 16370 metric train_loss = 0.3079308032989502\n",
      "classification ---- 16380 metric train_loss = 0.3265753582119942\n",
      "classification ---- 16390 metric train_loss = 0.38782694935798645\n",
      "classification ---- 16400 metric train_loss = 0.27886188477277757\n",
      "classification ---- 16410 metric train_loss = 0.31155742704868317\n",
      "classification ---- 16420 metric train_loss = 0.33088079690933225\n",
      "classification ---- 16430 metric train_loss = 0.3482790529727936\n",
      "classification ---- 16440 metric train_loss = 0.25831536054611204\n",
      "classification ---- 16450 metric train_loss = 0.30329942256212233\n",
      "classification ---- 16460 metric train_loss = 0.3027133956551552\n",
      "classification ---- 16470 metric train_loss = 0.2707691118121147\n",
      "classification ---- 16480 metric train_loss = 0.3144771933555603\n",
      "classification ---- 16490 metric train_loss = 0.31503428518772125\n",
      "classification ---- 16500 metric train_loss = 0.32914216816425323\n",
      "classification ---- 34 metric test_f1 = 0.9172468764728343\n",
      "classification ---- 34 metric test_accuracy = 0.9136363636363637\n",
      "classification ---- 16510 metric train_loss = 0.29029033333063126\n",
      "classification ---- 16520 metric train_loss = 0.34885833114385606\n",
      "classification ---- 16530 metric train_loss = 0.2882895454764366\n",
      "classification ---- 16540 metric train_loss = 0.34632338881492614\n",
      "classification ---- 16550 metric train_loss = 0.30262538194656374\n",
      "classification ---- 16560 metric train_loss = 0.31870029866695404\n",
      "classification ---- 16570 metric train_loss = 0.2904412791132927\n",
      "classification ---- 16580 metric train_loss = 0.33651688545942304\n",
      "classification ---- 16590 metric train_loss = 0.33933803588151934\n",
      "classification ---- 16600 metric train_loss = 0.26652434319257734\n",
      "classification ---- 16610 metric train_loss = 0.28614233434200287\n",
      "classification ---- 16620 metric train_loss = 0.2999562308192253\n",
      "classification ---- 16630 metric train_loss = 0.3036427959799767\n",
      "classification ---- 16640 metric train_loss = 0.3727392449975014\n",
      "classification ---- 16650 metric train_loss = 0.34908461272716523\n",
      "classification ---- 16660 metric train_loss = 0.3456244558095932\n",
      "classification ---- 16670 metric train_loss = 0.3852871537208557\n",
      "classification ---- 16680 metric train_loss = 0.32590861022472384\n",
      "classification ---- 16690 metric train_loss = 0.31758888959884646\n",
      "classification ---- 16700 metric train_loss = 0.28108035326004027\n",
      "classification ---- 16710 metric train_loss = 0.3168739154934883\n",
      "classification ---- 16720 metric train_loss = 0.26140339076519015\n",
      "classification ---- 16730 metric train_loss = 0.3023734360933304\n",
      "classification ---- 16740 metric train_loss = 0.2941354736685753\n",
      "classification ---- 16750 metric train_loss = 0.30827747732400895\n",
      "classification ---- 16760 metric train_loss = 0.32374049425125123\n",
      "classification ---- 16770 metric train_loss = 0.35218214690685273\n",
      "classification ---- 16780 metric train_loss = 0.3064061880111694\n",
      "classification ---- 16790 metric train_loss = 0.3004414916038513\n",
      "classification ---- 16800 metric train_loss = 0.34098093807697294\n",
      "classification ---- 16810 metric train_loss = 0.3264390677213669\n",
      "classification ---- 16820 metric train_loss = 0.32225828766822817\n",
      "classification ---- 16830 metric train_loss = 0.26064592227339745\n",
      "classification ---- 16840 metric train_loss = 0.29942552745342255\n",
      "classification ---- 16850 metric train_loss = 0.3270431742072105\n",
      "classification ---- 16860 metric train_loss = 0.32153644114732743\n",
      "classification ---- 16870 metric train_loss = 0.31281302571296693\n",
      "classification ---- 16880 metric train_loss = 0.34259461164474486\n",
      "classification ---- 16890 metric train_loss = 0.2852786719799042\n",
      "classification ---- 16900 metric train_loss = 0.3212829977273941\n",
      "classification ---- 16910 metric train_loss = 0.3409860223531723\n",
      "classification ---- 16920 metric train_loss = 0.3280273601412773\n",
      "classification ---- 16930 metric train_loss = 0.34838607609272004\n",
      "classification ---- 16940 metric train_loss = 0.29770049899816514\n",
      "classification ---- 16950 metric train_loss = 0.2891868382692337\n",
      "classification ---- 16960 metric train_loss = 0.3117404133081436\n",
      "classification ---- 16970 metric train_loss = 0.3855603963136673\n",
      "classification ---- 16980 metric train_loss = 0.4077423185110092\n",
      "classification ---- 16990 metric train_loss = 0.29238669127225875\n",
      "classification ---- 17000 metric train_loss = 0.34505158811807635\n",
      "classification ---- 35 metric test_f1 = 0.9061433203622331\n",
      "classification ---- 35 metric test_accuracy = 0.9059090909090909\n",
      "classification ---- 18 metric train_accuracy = 0.8860845839017736\n",
      "classification ---- 18 metric train_f1 = 0.8880095124178531\n",
      "classification ---- 17010 metric train_loss = 0.2753946602344513\n",
      "classification ---- 17020 metric train_loss = 0.2793720193207264\n",
      "classification ---- 17030 metric train_loss = 0.3098717950284481\n",
      "classification ---- 17040 metric train_loss = 0.3728525325655937\n",
      "classification ---- 17050 metric train_loss = 0.3086682751774788\n",
      "classification ---- 17060 metric train_loss = 0.29902989864349366\n",
      "classification ---- 17070 metric train_loss = 0.3145304545760155\n",
      "classification ---- 17080 metric train_loss = 0.28155081123113634\n",
      "classification ---- 17090 metric train_loss = 0.26916097700595853\n",
      "classification ---- 17100 metric train_loss = 0.3319059729576111\n",
      "classification ---- 17110 metric train_loss = 0.30507308542728423\n",
      "classification ---- 17120 metric train_loss = 0.3357716202735901\n",
      "classification ---- 17130 metric train_loss = 0.2991281121969223\n",
      "classification ---- 17140 metric train_loss = 0.3375704362988472\n",
      "classification ---- 17150 metric train_loss = 0.2921353906393051\n",
      "classification ---- 17160 metric train_loss = 0.3075486943125725\n",
      "classification ---- 17170 metric train_loss = 0.3232897907495499\n",
      "classification ---- 17180 metric train_loss = 0.27966976910829544\n",
      "classification ---- 17190 metric train_loss = 0.348345248401165\n",
      "classification ---- 17200 metric train_loss = 0.2753069460391998\n",
      "classification ---- 17210 metric train_loss = 0.32698541432619094\n",
      "classification ---- 17220 metric train_loss = 0.3545878201723099\n",
      "classification ---- 17230 metric train_loss = 0.30143301635980607\n",
      "classification ---- 17240 metric train_loss = 0.30573421716690063\n",
      "classification ---- 17250 metric train_loss = 0.3162973776459694\n",
      "classification ---- 17260 metric train_loss = 0.3260801821947098\n",
      "classification ---- 17270 metric train_loss = 0.30328732430934907\n",
      "classification ---- 17280 metric train_loss = 0.3296396806836128\n",
      "classification ---- 17290 metric train_loss = 0.2666416004300117\n",
      "classification ---- 17300 metric train_loss = 0.2612870119512081\n",
      "classification ---- 17310 metric train_loss = 0.3147709399461746\n",
      "classification ---- 17320 metric train_loss = 0.336716091632843\n",
      "classification ---- 17330 metric train_loss = 0.29356671422719954\n",
      "classification ---- 17340 metric train_loss = 0.27241743355989456\n",
      "classification ---- 17350 metric train_loss = 0.28689145147800443\n",
      "classification ---- 17360 metric train_loss = 0.3318129822611809\n",
      "classification ---- 17370 metric train_loss = 0.2878681570291519\n",
      "classification ---- 17380 metric train_loss = 0.3076404228806496\n",
      "classification ---- 17390 metric train_loss = 0.2935357138514519\n",
      "classification ---- 17400 metric train_loss = 0.2755707442760468\n",
      "classification ---- 17410 metric train_loss = 0.2546438962221146\n",
      "classification ---- 17420 metric train_loss = 0.32879193872213364\n",
      "classification ---- 17430 metric train_loss = 0.24375470206141472\n",
      "classification ---- 17440 metric train_loss = 0.3584170684218407\n",
      "classification ---- 17450 metric train_loss = 0.2961625188589096\n",
      "classification ---- 17460 metric train_loss = 0.32993028312921524\n",
      "classification ---- 17470 metric train_loss = 0.30570369511842727\n",
      "classification ---- 17480 metric train_loss = 0.2476406693458557\n",
      "classification ---- 17490 metric train_loss = 0.28424483835697173\n",
      "classification ---- 17500 metric train_loss = 0.31975271701812746\n",
      "classification ---- 36 metric test_f1 = 0.9187957213538359\n",
      "classification ---- 36 metric test_accuracy = 0.9172727272727272\n",
      "classification ---- 17510 metric train_loss = 0.31415410339832306\n",
      "classification ---- 17520 metric train_loss = 0.3416744828224182\n",
      "classification ---- 17530 metric train_loss = 0.33184812813997266\n",
      "classification ---- 17540 metric train_loss = 0.29196488559246064\n",
      "classification ---- 17550 metric train_loss = 0.2917044386267662\n",
      "classification ---- 17560 metric train_loss = 0.2790292054414749\n",
      "classification ---- 17570 metric train_loss = 0.35196203291416167\n",
      "classification ---- 17580 metric train_loss = 0.3550985276699066\n",
      "classification ---- 17590 metric train_loss = 0.3114362835884094\n",
      "classification ---- 17600 metric train_loss = 0.33434265553951265\n",
      "classification ---- 17610 metric train_loss = 0.30423549115657805\n",
      "classification ---- 17620 metric train_loss = 0.27509964257478714\n",
      "classification ---- 17630 metric train_loss = 0.3467574827373028\n",
      "classification ---- 17640 metric train_loss = 0.3138708591461182\n",
      "classification ---- 17650 metric train_loss = 0.3214592322707176\n",
      "classification ---- 17660 metric train_loss = 0.33121901005506516\n",
      "classification ---- 17670 metric train_loss = 0.30322269797325135\n",
      "classification ---- 17680 metric train_loss = 0.29912295639514924\n",
      "classification ---- 17690 metric train_loss = 0.3303028792142868\n",
      "classification ---- 17700 metric train_loss = 0.3157129049301147\n",
      "classification ---- 17710 metric train_loss = 0.30722587257623674\n",
      "classification ---- 17720 metric train_loss = 0.2774251960217953\n",
      "classification ---- 17730 metric train_loss = 0.3026641935110092\n",
      "classification ---- 17740 metric train_loss = 0.28127339035272597\n",
      "classification ---- 17750 metric train_loss = 0.2998769745230675\n",
      "classification ---- 17760 metric train_loss = 0.29034377485513685\n",
      "classification ---- 17770 metric train_loss = 0.30274655669927597\n",
      "classification ---- 17780 metric train_loss = 0.3004886507987976\n",
      "classification ---- 17790 metric train_loss = 0.3225843086838722\n",
      "classification ---- 17800 metric train_loss = 0.33176072537899015\n",
      "classification ---- 17810 metric train_loss = 0.35106122940778733\n",
      "classification ---- 17820 metric train_loss = 0.35529265403747556\n",
      "classification ---- 17830 metric train_loss = 0.29449560344219206\n",
      "classification ---- 17840 metric train_loss = 0.24968002438545228\n",
      "classification ---- 17850 metric train_loss = 0.3192029893398285\n",
      "classification ---- 17860 metric train_loss = 0.28308654204010963\n",
      "classification ---- 17870 metric train_loss = 0.27700524032115936\n",
      "classification ---- 17880 metric train_loss = 0.27440246269106866\n",
      "classification ---- 17890 metric train_loss = 0.2963904023170471\n",
      "classification ---- 17900 metric train_loss = 0.3213926538825035\n",
      "classification ---- 17910 metric train_loss = 0.34815427362918855\n",
      "classification ---- 17920 metric train_loss = 0.31703530848026273\n",
      "classification ---- 17930 metric train_loss = 0.25782665610313416\n",
      "classification ---- 17940 metric train_loss = 0.3412811040878296\n",
      "classification ---- 17950 metric train_loss = 0.3286771610379219\n",
      "classification ---- 17960 metric train_loss = 0.30987175852060317\n",
      "classification ---- 17970 metric train_loss = 0.28739050924777987\n",
      "classification ---- 17980 metric train_loss = 0.2891269147396088\n",
      "classification ---- 17990 metric train_loss = 0.3125178307294846\n",
      "classification ---- 18000 metric train_loss = 0.2995064675807953\n",
      "classification ---- 37 metric test_f1 = 0.9178265080521266\n",
      "classification ---- 37 metric test_accuracy = 0.9154545454545454\n",
      "classification ---- 19 metric train_accuracy = 0.9009777171441564\n",
      "classification ---- 19 metric train_f1 = 0.9034418001604051\n",
      "classification ---- 18010 metric train_loss = 0.315406808257103\n",
      "classification ---- 18020 metric train_loss = 0.2965552777051926\n",
      "classification ---- 18030 metric train_loss = 0.33587490767240524\n",
      "classification ---- 18040 metric train_loss = 0.2658247694373131\n",
      "classification ---- 18050 metric train_loss = 0.2975029915571213\n",
      "classification ---- 18060 metric train_loss = 0.34272252172231676\n",
      "classification ---- 18070 metric train_loss = 0.30809466540813446\n",
      "classification ---- 18080 metric train_loss = 0.28113682717084887\n",
      "classification ---- 18090 metric train_loss = 0.27986189275979995\n",
      "classification ---- 18100 metric train_loss = 0.33499332517385483\n",
      "classification ---- 18110 metric train_loss = 0.27181523889303205\n",
      "classification ---- 18120 metric train_loss = 0.25137956961989405\n",
      "classification ---- 18130 metric train_loss = 0.32152394503355025\n",
      "classification ---- 18140 metric train_loss = 0.34292586594820024\n",
      "classification ---- 18150 metric train_loss = 0.2682996839284897\n",
      "classification ---- 18160 metric train_loss = 0.2872467711567879\n",
      "classification ---- 18170 metric train_loss = 0.3067323863506317\n",
      "classification ---- 18180 metric train_loss = 0.30233447104692457\n",
      "classification ---- 18190 metric train_loss = 0.3190503239631653\n",
      "classification ---- 18200 metric train_loss = 0.29471727907657624\n",
      "classification ---- 18210 metric train_loss = 0.2995434537529945\n",
      "classification ---- 18220 metric train_loss = 0.2961348593235016\n",
      "classification ---- 18230 metric train_loss = 0.3078299179673195\n",
      "classification ---- 18240 metric train_loss = 0.2498359724879265\n",
      "classification ---- 18250 metric train_loss = 0.2908589422702789\n",
      "classification ---- 18260 metric train_loss = 0.29167346060276034\n",
      "classification ---- 18270 metric train_loss = 0.3437653943896294\n",
      "classification ---- 18280 metric train_loss = 0.22829747796058655\n",
      "classification ---- 18290 metric train_loss = 0.31732495725154874\n",
      "classification ---- 18300 metric train_loss = 0.31513056457042693\n",
      "classification ---- 18310 metric train_loss = 0.2852791830897331\n",
      "classification ---- 18320 metric train_loss = 0.31010436415672304\n",
      "classification ---- 18330 metric train_loss = 0.29979301542043685\n",
      "classification ---- 18340 metric train_loss = 0.2750144347548485\n",
      "classification ---- 18350 metric train_loss = 0.2880652010440826\n",
      "classification ---- 18360 metric train_loss = 0.29486793279647827\n",
      "classification ---- 18370 metric train_loss = 0.28674464523792265\n",
      "classification ---- 18380 metric train_loss = 0.2997008293867111\n",
      "classification ---- 18390 metric train_loss = 0.2826676368713379\n",
      "classification ---- 18400 metric train_loss = 0.29555465579032897\n",
      "classification ---- 18410 metric train_loss = 0.311438300460577\n",
      "classification ---- 18420 metric train_loss = 0.2935720466077328\n",
      "classification ---- 18430 metric train_loss = 0.25587426126003265\n",
      "classification ---- 18440 metric train_loss = 0.3003602460026741\n",
      "classification ---- 18450 metric train_loss = 0.2552058018743992\n",
      "classification ---- 18460 metric train_loss = 0.3239787325263023\n",
      "classification ---- 18470 metric train_loss = 0.3078301228582859\n",
      "classification ---- 18480 metric train_loss = 0.30857640951871873\n",
      "classification ---- 18490 metric train_loss = 0.2944954738020897\n",
      "classification ---- 18500 metric train_loss = 0.2270730748772621\n",
      "classification ---- 38 metric test_f1 = 0.9163499471141113\n",
      "classification ---- 38 metric test_accuracy = 0.9154545454545454\n",
      "classification ---- 18510 metric train_loss = 0.2374580129981041\n",
      "classification ---- 18520 metric train_loss = 0.30458409488201144\n",
      "classification ---- 18530 metric train_loss = 0.28478039503097535\n",
      "classification ---- 18540 metric train_loss = 0.30113852173089983\n",
      "classification ---- 18550 metric train_loss = 0.3155021175742149\n",
      "classification ---- 18560 metric train_loss = 0.24631856232881547\n",
      "classification ---- 18570 metric train_loss = 0.29816854670643805\n",
      "classification ---- 18580 metric train_loss = 0.26052509993314743\n",
      "classification ---- 18590 metric train_loss = 0.3050442814826965\n",
      "classification ---- 18600 metric train_loss = 0.27812330275774\n",
      "classification ---- 18610 metric train_loss = 0.2919450134038925\n",
      "classification ---- 18620 metric train_loss = 0.31235269755125045\n",
      "classification ---- 18630 metric train_loss = 0.28119592666625975\n",
      "classification ---- 18640 metric train_loss = 0.31656564027071\n",
      "classification ---- 18650 metric train_loss = 0.28073434382677076\n",
      "classification ---- 18660 metric train_loss = 0.3192921057343483\n",
      "classification ---- 18670 metric train_loss = 0.2926454901695251\n",
      "classification ---- 18680 metric train_loss = 0.26315500140190123\n",
      "classification ---- 18690 metric train_loss = 0.31873010396957396\n",
      "classification ---- 18700 metric train_loss = 0.25936043113470075\n",
      "classification ---- 18710 metric train_loss = 0.3132557839155197\n",
      "classification ---- 18720 metric train_loss = 0.3102248288691044\n",
      "classification ---- 18730 metric train_loss = 0.3385414630174637\n",
      "classification ---- 18740 metric train_loss = 0.29142328202724455\n",
      "classification ---- 18750 metric train_loss = 0.31990373134613037\n",
      "classification ---- 18760 metric train_loss = 0.30232289880514146\n",
      "classification ---- 18770 metric train_loss = 0.2806015580892563\n",
      "classification ---- 18780 metric train_loss = 0.24888119399547576\n",
      "classification ---- 18790 metric train_loss = 0.3244169130921364\n",
      "classification ---- 18800 metric train_loss = 0.2799786850810051\n",
      "classification ---- 18810 metric train_loss = 0.2958614841103554\n",
      "classification ---- 18820 metric train_loss = 0.3197671741247177\n",
      "classification ---- 18830 metric train_loss = 0.27216643616557123\n",
      "classification ---- 18840 metric train_loss = 0.3015209972858429\n",
      "classification ---- 18850 metric train_loss = 0.24362848028540612\n",
      "classification ---- 18860 metric train_loss = 0.28865529149770736\n",
      "classification ---- 18870 metric train_loss = 0.31689296662807465\n",
      "classification ---- 18880 metric train_loss = 0.3408998966217041\n",
      "classification ---- 18890 metric train_loss = 0.3325978383421898\n",
      "classification ---- 18900 metric train_loss = 0.31780720204114915\n",
      "classification ---- 18910 metric train_loss = 0.328854638338089\n",
      "classification ---- 18920 metric train_loss = 0.3088584840297699\n",
      "classification ---- 18930 metric train_loss = 0.30039667189121244\n",
      "classification ---- 18940 metric train_loss = 0.2940860614180565\n",
      "classification ---- 18950 metric train_loss = 0.2374454751610756\n",
      "classification ---- 18960 metric train_loss = 0.2561397358775139\n",
      "classification ---- 18970 metric train_loss = 0.23173792958259581\n",
      "classification ---- 18980 metric train_loss = 0.2998399257659912\n",
      "classification ---- 18990 metric train_loss = 0.27257752418518066\n",
      "classification ---- 19000 metric train_loss = 0.3041595995426178\n",
      "classification ---- 39 metric test_f1 = 0.9199311184521678\n",
      "classification ---- 39 metric test_accuracy = 0.9186363636363636\n",
      "classification ---- 20 metric train_accuracy = 0.9098453842655753\n",
      "classification ---- 20 metric train_f1 = 0.9120102001003347\n",
      "classification ---- 19010 metric train_loss = 0.2637569412589073\n",
      "classification ---- 19020 metric train_loss = 0.2456166222691536\n",
      "classification ---- 19030 metric train_loss = 0.31167586594820024\n",
      "classification ---- 19040 metric train_loss = 0.30487295985221863\n",
      "classification ---- 19050 metric train_loss = 0.29601550549268724\n",
      "classification ---- 19060 metric train_loss = 0.29372016787528993\n",
      "classification ---- 19070 metric train_loss = 0.34813771545886996\n",
      "classification ---- 19080 metric train_loss = 0.3224303424358368\n",
      "classification ---- 19090 metric train_loss = 0.2869142100214958\n",
      "classification ---- 19100 metric train_loss = 0.27276085764169694\n",
      "classification ---- 19110 metric train_loss = 0.25756313651800156\n",
      "classification ---- 19120 metric train_loss = 0.332061630487442\n",
      "classification ---- 19130 metric train_loss = 0.25049872100353243\n",
      "classification ---- 19140 metric train_loss = 0.2641925446689129\n",
      "classification ---- 19150 metric train_loss = 0.32531589865684507\n",
      "classification ---- 19160 metric train_loss = 0.2899465441703796\n",
      "classification ---- 19170 metric train_loss = 0.2360525608062744\n",
      "classification ---- 19180 metric train_loss = 0.32101013958454133\n",
      "classification ---- 19190 metric train_loss = 0.2777230441570282\n",
      "classification ---- 19200 metric train_loss = 0.3491178244352341\n",
      "classification ---- 19210 metric train_loss = 0.2924922168254852\n",
      "classification ---- 19220 metric train_loss = 0.29186069443821905\n",
      "classification ---- 19230 metric train_loss = 0.2722262814640999\n",
      "classification ---- 19240 metric train_loss = 0.26596990078687666\n",
      "classification ---- 19250 metric train_loss = 0.29964505434036254\n",
      "classification ---- 19260 metric train_loss = 0.26856849119067194\n",
      "classification ---- 19270 metric train_loss = 0.31072404235601425\n",
      "classification ---- 19280 metric train_loss = 0.2778479874134064\n",
      "classification ---- 19290 metric train_loss = 0.2888441890478134\n",
      "classification ---- 19300 metric train_loss = 0.2756525933742523\n",
      "classification ---- 19310 metric train_loss = 0.2516453266143799\n",
      "classification ---- 19320 metric train_loss = 0.2593772254884243\n",
      "classification ---- 19330 metric train_loss = 0.2645249404013157\n",
      "classification ---- 19340 metric train_loss = 0.2988226696848869\n",
      "classification ---- 19350 metric train_loss = 0.2706762671470642\n",
      "classification ---- 19360 metric train_loss = 0.30625690072774886\n",
      "classification ---- 19370 metric train_loss = 0.30099766701459885\n",
      "classification ---- 19380 metric train_loss = 0.2736027240753174\n",
      "classification ---- 19390 metric train_loss = 0.25704833269119265\n",
      "classification ---- 19400 metric train_loss = 0.3058085381984711\n",
      "classification ---- 19410 metric train_loss = 0.29658819884061816\n",
      "classification ---- 19420 metric train_loss = 0.23519527018070222\n",
      "classification ---- 19430 metric train_loss = 0.2972192645072937\n",
      "classification ---- 19440 metric train_loss = 0.24921949952840805\n",
      "classification ---- 19450 metric train_loss = 0.28043818324804304\n",
      "classification ---- 19460 metric train_loss = 0.29224560111761094\n",
      "classification ---- 19470 metric train_loss = 0.25991190075874326\n",
      "classification ---- 19480 metric train_loss = 0.3183420494198799\n",
      "classification ---- 19490 metric train_loss = 0.2694163352251053\n",
      "classification ---- 19500 metric train_loss = 0.2368360161781311\n",
      "classification ---- 40 metric test_f1 = 0.9177326761886804\n",
      "classification ---- 40 metric test_accuracy = 0.9163636363636364\n",
      "classification ---- 19510 metric train_loss = 0.26774038299918174\n",
      "classification ---- 19520 metric train_loss = 0.3309350907802582\n",
      "classification ---- 19530 metric train_loss = 0.29428026676177976\n",
      "classification ---- 19540 metric train_loss = 0.304784020781517\n",
      "classification ---- 19550 metric train_loss = 0.2991233229637146\n",
      "classification ---- 19560 metric train_loss = 0.31770193129777907\n",
      "classification ---- 19570 metric train_loss = 0.2918271943926811\n",
      "classification ---- 19580 metric train_loss = 0.2973125517368317\n",
      "classification ---- 19590 metric train_loss = 0.33065808564424515\n",
      "classification ---- 19600 metric train_loss = 0.3010416775941849\n",
      "classification ---- 19610 metric train_loss = 0.2587968215346336\n",
      "classification ---- 19620 metric train_loss = 0.2627093233168125\n",
      "classification ---- 19630 metric train_loss = 0.27459208220243453\n",
      "classification ---- 19640 metric train_loss = 0.2629486620426178\n",
      "classification ---- 19650 metric train_loss = 0.30333678871393205\n",
      "classification ---- 19660 metric train_loss = 0.32140291184186937\n",
      "classification ---- 19670 metric train_loss = 0.36618596464395525\n",
      "classification ---- 19680 metric train_loss = 0.27023929357528687\n",
      "classification ---- 19690 metric train_loss = 0.3384291842579842\n",
      "classification ---- 19700 metric train_loss = 0.2802917629480362\n",
      "classification ---- 19710 metric train_loss = 0.289014133810997\n",
      "classification ---- 19720 metric train_loss = 0.2346885621547699\n",
      "classification ---- 19730 metric train_loss = 0.23913857340812683\n",
      "classification ---- 19740 metric train_loss = 0.3056393340229988\n",
      "classification ---- 19750 metric train_loss = 0.27150227278470995\n",
      "classification ---- 19760 metric train_loss = 0.28303202241659164\n",
      "classification ---- 19770 metric train_loss = 0.32814708799123765\n",
      "classification ---- 19780 metric train_loss = 0.2964654088020325\n",
      "classification ---- 19790 metric train_loss = 0.33472906798124313\n",
      "classification ---- 19800 metric train_loss = 0.3009611889719963\n",
      "classification ---- 19810 metric train_loss = 0.27787009030580523\n",
      "classification ---- 19820 metric train_loss = 0.29773478507995604\n",
      "classification ---- 19830 metric train_loss = 0.26549179702997205\n",
      "classification ---- 19840 metric train_loss = 0.25636120438575744\n",
      "classification ---- 19850 metric train_loss = 0.3049465388059616\n",
      "classification ---- 19860 metric train_loss = 0.24163500368595123\n",
      "classification ---- 19870 metric train_loss = 0.27519517987966535\n",
      "classification ---- 19880 metric train_loss = 0.2684174656867981\n",
      "classification ---- 19890 metric train_loss = 0.3067774698138237\n",
      "classification ---- 19900 metric train_loss = 0.2744388237595558\n",
      "classification ---- 19910 metric train_loss = 0.2684346318244934\n",
      "classification ---- 19920 metric train_loss = 0.31406316459178923\n",
      "classification ---- 19930 metric train_loss = 0.31338978707790377\n",
      "classification ---- 19940 metric train_loss = 0.26346173882484436\n",
      "classification ---- 19950 metric train_loss = 0.3124515533447266\n",
      "classification ---- 19960 metric train_loss = 0.25364387333393096\n",
      "classification ---- 19970 metric train_loss = 0.2677912935614586\n",
      "classification ---- 19980 metric train_loss = 0.2996432438492775\n",
      "classification ---- 19990 metric train_loss = 0.2714827060699463\n",
      "classification ---- 20000 metric train_loss = 0.2357805296778679\n",
      "classification ---- 41 metric test_f1 = 0.9218822602297452\n",
      "classification ---- 41 metric test_accuracy = 0.9204545454545454\n",
      "classification ---- 21 metric train_accuracy = 0.9067758071850841\n",
      "classification ---- 21 metric train_f1 = 0.9099125090388144\n",
      "classification ---- 20010 metric train_loss = 0.2960606500506401\n",
      "classification ---- 20020 metric train_loss = 0.21235930919647217\n",
      "classification ---- 20030 metric train_loss = 0.24695974886417388\n",
      "classification ---- 20040 metric train_loss = 0.2558452636003494\n",
      "classification ---- 20050 metric train_loss = 0.2469559758901596\n",
      "classification ---- 20060 metric train_loss = 0.2305426999926567\n",
      "classification ---- 20070 metric train_loss = 0.3033752664923668\n",
      "classification ---- 20080 metric train_loss = 0.33002170324325564\n",
      "classification ---- 20090 metric train_loss = 0.26475314050912857\n",
      "classification ---- 20100 metric train_loss = 0.2911521106958389\n",
      "classification ---- 20110 metric train_loss = 0.26562546491622924\n",
      "classification ---- 20120 metric train_loss = 0.28952123075723646\n",
      "classification ---- 20130 metric train_loss = 0.2987892836332321\n",
      "classification ---- 20140 metric train_loss = 0.2895922362804413\n",
      "classification ---- 20150 metric train_loss = 0.305207385122776\n",
      "classification ---- 20160 metric train_loss = 0.27585730999708175\n",
      "classification ---- 20170 metric train_loss = 0.2265978679060936\n",
      "classification ---- 20180 metric train_loss = 0.31397278010845187\n",
      "classification ---- 20190 metric train_loss = 0.3200512006878853\n",
      "classification ---- 20200 metric train_loss = 0.2942862182855606\n",
      "classification ---- 20210 metric train_loss = 0.3190601199865341\n",
      "classification ---- 20220 metric train_loss = 0.26961317509412763\n",
      "classification ---- 20230 metric train_loss = 0.3070153295993805\n",
      "classification ---- 20240 metric train_loss = 0.27226741462945936\n",
      "classification ---- 20250 metric train_loss = 0.26001911163330077\n",
      "classification ---- 20260 metric train_loss = 0.2554649278521538\n",
      "classification ---- 20270 metric train_loss = 0.2684888198971748\n",
      "classification ---- 20280 metric train_loss = 0.2559686921536922\n",
      "classification ---- 20290 metric train_loss = 0.3171908393502235\n",
      "classification ---- 20300 metric train_loss = 0.26634241342544557\n",
      "classification ---- 20310 metric train_loss = 0.2410801388323307\n",
      "classification ---- 20320 metric train_loss = 0.27750752568244935\n",
      "classification ---- 20330 metric train_loss = 0.2799102395772934\n",
      "classification ---- 20340 metric train_loss = 0.29216610416769984\n",
      "classification ---- 20350 metric train_loss = 0.3034281745553017\n",
      "classification ---- 20360 metric train_loss = 0.2883947119116783\n",
      "classification ---- 20370 metric train_loss = 0.272660318762064\n",
      "classification ---- 20380 metric train_loss = 0.2558134764432907\n",
      "classification ---- 20390 metric train_loss = 0.32802460342645645\n",
      "classification ---- 20400 metric train_loss = 0.2717358872294426\n",
      "classification ---- 20410 metric train_loss = 0.30206249803304674\n",
      "classification ---- 20420 metric train_loss = 0.2366595521569252\n",
      "classification ---- 20430 metric train_loss = 0.26274420469999316\n",
      "classification ---- 20440 metric train_loss = 0.25848973393440244\n",
      "classification ---- 20450 metric train_loss = 0.22797518819570542\n",
      "classification ---- 20460 metric train_loss = 0.2706914432346821\n",
      "classification ---- 20470 metric train_loss = 0.2952957347035408\n",
      "classification ---- 20480 metric train_loss = 0.3195093095302582\n",
      "classification ---- 20490 metric train_loss = 0.2691678687930107\n",
      "classification ---- 20500 metric train_loss = 0.28521821945905684\n",
      "classification ---- 42 metric test_f1 = 0.9235363290571174\n",
      "classification ---- 42 metric test_accuracy = 0.9218181818181819\n",
      "classification ---- 20510 metric train_loss = 0.2466398999094963\n",
      "classification ---- 20520 metric train_loss = 0.2759569823741913\n",
      "classification ---- 20530 metric train_loss = 0.2928152963519096\n",
      "classification ---- 20540 metric train_loss = 0.2908581458032131\n",
      "classification ---- 20550 metric train_loss = 0.29958598166704176\n",
      "classification ---- 20560 metric train_loss = 0.2980942964553833\n",
      "classification ---- 20570 metric train_loss = 0.2278162084519863\n",
      "classification ---- 20580 metric train_loss = 0.24846355319023133\n",
      "classification ---- 20590 metric train_loss = 0.28848819583654406\n",
      "classification ---- 20600 metric train_loss = 0.2869634240865707\n",
      "classification ---- 20610 metric train_loss = 0.2554335482418537\n",
      "classification ---- 20620 metric train_loss = 0.2786452293395996\n",
      "classification ---- 20630 metric train_loss = 0.25463430359959605\n",
      "classification ---- 20640 metric train_loss = 0.2504644401371479\n",
      "classification ---- 20650 metric train_loss = 0.25717017203569414\n",
      "classification ---- 20660 metric train_loss = 0.29198387563228606\n",
      "classification ---- 20670 metric train_loss = 0.29362220615148543\n",
      "classification ---- 20680 metric train_loss = 0.29381917119026185\n",
      "classification ---- 20690 metric train_loss = 0.28054195940494536\n",
      "classification ---- 20700 metric train_loss = 0.277860876172781\n",
      "classification ---- 20710 metric train_loss = 0.25502281039953234\n",
      "classification ---- 20720 metric train_loss = 0.2521393418312073\n",
      "classification ---- 20730 metric train_loss = 0.20428702980279922\n",
      "classification ---- 20740 metric train_loss = 0.2761408522725105\n",
      "classification ---- 20750 metric train_loss = 0.31262769252061845\n",
      "classification ---- 20760 metric train_loss = 0.266890624165535\n",
      "classification ---- 20770 metric train_loss = 0.2622546121478081\n",
      "classification ---- 20780 metric train_loss = 0.32025072276592254\n",
      "classification ---- 20790 metric train_loss = 0.3133974775671959\n",
      "classification ---- 20800 metric train_loss = 0.30581453889608384\n",
      "classification ---- 20810 metric train_loss = 0.28589471727609633\n",
      "classification ---- 20820 metric train_loss = 0.2771192714571953\n",
      "classification ---- 20830 metric train_loss = 0.2583582252264023\n",
      "classification ---- 20840 metric train_loss = 0.2907984539866447\n",
      "classification ---- 20850 metric train_loss = 0.29503625333309175\n",
      "classification ---- 20860 metric train_loss = 0.2939931184053421\n",
      "classification ---- 20870 metric train_loss = 0.2505692645907402\n",
      "classification ---- 20880 metric train_loss = 0.282929627597332\n",
      "classification ---- 20890 metric train_loss = 0.276688888669014\n",
      "classification ---- 20900 metric train_loss = 0.2503304958343506\n",
      "classification ---- 20910 metric train_loss = 0.26872851252555846\n",
      "classification ---- 20920 metric train_loss = 0.2513877123594284\n",
      "classification ---- 20930 metric train_loss = 0.29294670671224593\n",
      "classification ---- 20940 metric train_loss = 0.2587859630584717\n",
      "classification ---- 20950 metric train_loss = 0.2689239948987961\n",
      "classification ---- 20960 metric train_loss = 0.30666110664606094\n",
      "classification ---- 20970 metric train_loss = 0.2567932315170765\n",
      "classification ---- 20980 metric train_loss = 0.2567708417773247\n",
      "classification ---- 20990 metric train_loss = 0.2733278967440128\n",
      "classification ---- 21000 metric train_loss = 0.260397993773222\n",
      "classification ---- 43 metric test_f1 = 0.9192268267575561\n",
      "classification ---- 43 metric test_accuracy = 0.9186363636363636\n",
      "classification ---- 22 metric train_accuracy = 0.9125738972260118\n",
      "classification ---- 22 metric train_f1 = 0.9153650592993389\n",
      "classification ---- 21010 metric train_loss = 0.24915773123502732\n",
      "classification ---- 21020 metric train_loss = 0.27573165446519854\n",
      "classification ---- 21030 metric train_loss = 0.28817721307277677\n",
      "classification ---- 21040 metric train_loss = 0.2382079169154167\n",
      "classification ---- 21050 metric train_loss = 0.2831029504537582\n",
      "classification ---- 21060 metric train_loss = 0.22893657460808753\n",
      "classification ---- 21070 metric train_loss = 0.30444700717926027\n",
      "classification ---- 21080 metric train_loss = 0.2968493767082691\n",
      "classification ---- 21090 metric train_loss = 0.3244274064898491\n",
      "classification ---- 21100 metric train_loss = 0.2625418588519096\n",
      "classification ---- 21110 metric train_loss = 0.2699426054954529\n",
      "classification ---- 21120 metric train_loss = 0.26480095982551577\n",
      "classification ---- 21130 metric train_loss = 0.3062773823738098\n",
      "classification ---- 21140 metric train_loss = 0.3060685247182846\n",
      "classification ---- 21150 metric train_loss = 0.2656896486878395\n",
      "classification ---- 21160 metric train_loss = 0.25688785314559937\n",
      "classification ---- 21170 metric train_loss = 0.2832914777100086\n",
      "classification ---- 21180 metric train_loss = 0.29094951748847964\n",
      "classification ---- 21190 metric train_loss = 0.3050069913268089\n",
      "classification ---- 21200 metric train_loss = 0.29254167675971987\n",
      "classification ---- 21210 metric train_loss = 0.31230216920375825\n",
      "classification ---- 21220 metric train_loss = 0.28655334040522573\n",
      "classification ---- 21230 metric train_loss = 0.2831562116742134\n",
      "classification ---- 21240 metric train_loss = 0.30440151393413545\n",
      "classification ---- 21250 metric train_loss = 0.2325999081134796\n",
      "classification ---- 21260 metric train_loss = 0.2824692025780678\n",
      "classification ---- 21270 metric train_loss = 0.2968606874346733\n",
      "classification ---- 21280 metric train_loss = 0.28888689130544665\n",
      "classification ---- 21290 metric train_loss = 0.2558781772851944\n",
      "classification ---- 21300 metric train_loss = 0.25300351679325106\n",
      "classification ---- 21310 metric train_loss = 0.23803574293851854\n",
      "classification ---- 21320 metric train_loss = 0.3045676425099373\n",
      "classification ---- 21330 metric train_loss = 0.27727461904287337\n",
      "classification ---- 21340 metric train_loss = 0.21148832216858865\n",
      "classification ---- 21350 metric train_loss = 0.2791964814066887\n",
      "classification ---- 21360 metric train_loss = 0.28498650789260865\n",
      "classification ---- 21370 metric train_loss = 0.2229117453098297\n",
      "classification ---- 21380 metric train_loss = 0.26424926668405535\n",
      "classification ---- 21390 metric train_loss = 0.26330028772354125\n",
      "classification ---- 21400 metric train_loss = 0.23969853669404984\n",
      "classification ---- 21410 metric train_loss = 0.2367528572678566\n",
      "classification ---- 21420 metric train_loss = 0.26490747183561325\n",
      "classification ---- 21430 metric train_loss = 0.2755882039666176\n",
      "classification ---- 21440 metric train_loss = 0.251009564101696\n",
      "classification ---- 21450 metric train_loss = 0.2591079190373421\n",
      "classification ---- 21460 metric train_loss = 0.26334511339664457\n",
      "classification ---- 21470 metric train_loss = 0.3040894612669945\n",
      "classification ---- 21480 metric train_loss = 0.28906336426734924\n",
      "classification ---- 21490 metric train_loss = 0.2429664172232151\n",
      "classification ---- 21500 metric train_loss = 0.30972964465618136\n",
      "classification ---- 44 metric test_f1 = 0.914592808407076\n",
      "classification ---- 44 metric test_accuracy = 0.9104545454545454\n",
      "classification ---- 21510 metric train_loss = 0.31319971531629565\n",
      "classification ---- 21520 metric train_loss = 0.24946337938308716\n",
      "classification ---- 21530 metric train_loss = 0.2538930714130402\n",
      "classification ---- 21540 metric train_loss = 0.24614959061145783\n",
      "classification ---- 21550 metric train_loss = 0.22769594714045524\n",
      "classification ---- 21560 metric train_loss = 0.24490415453910827\n",
      "classification ---- 21570 metric train_loss = 0.24776040464639665\n",
      "classification ---- 21580 metric train_loss = 0.2610169745981693\n",
      "classification ---- 21590 metric train_loss = 0.24025575295090676\n",
      "classification ---- 21600 metric train_loss = 0.3051261559128761\n",
      "classification ---- 21610 metric train_loss = 0.2702730104327202\n",
      "classification ---- 21620 metric train_loss = 0.2579718753695488\n",
      "classification ---- 21630 metric train_loss = 0.31681765615940094\n",
      "classification ---- 21640 metric train_loss = 0.25762726813554765\n",
      "classification ---- 21650 metric train_loss = 0.3100473627448082\n",
      "classification ---- 21660 metric train_loss = 0.2862750723958015\n",
      "classification ---- 21670 metric train_loss = 0.2466478168964386\n",
      "classification ---- 21680 metric train_loss = 0.2319011650979519\n",
      "classification ---- 21690 metric train_loss = 0.23367775976657867\n",
      "classification ---- 21700 metric train_loss = 0.23094820529222487\n",
      "classification ---- 21710 metric train_loss = 0.2340568333864212\n",
      "classification ---- 21720 metric train_loss = 0.2654924526810646\n",
      "classification ---- 21730 metric train_loss = 0.2472669415175915\n",
      "classification ---- 21740 metric train_loss = 0.28323315009474753\n",
      "classification ---- 21750 metric train_loss = 0.2646370708942413\n",
      "classification ---- 21760 metric train_loss = 0.21455505937337876\n",
      "classification ---- 21770 metric train_loss = 0.2781922876834869\n",
      "classification ---- 21780 metric train_loss = 0.23821471333503724\n",
      "classification ---- 21790 metric train_loss = 0.29594341963529586\n",
      "classification ---- 21800 metric train_loss = 0.256026953458786\n",
      "classification ---- 21810 metric train_loss = 0.244645556807518\n",
      "classification ---- 21820 metric train_loss = 0.30206154137849806\n",
      "classification ---- 21830 metric train_loss = 0.2725602358579636\n",
      "classification ---- 21840 metric train_loss = 0.2428390860557556\n",
      "classification ---- 21850 metric train_loss = 0.2657108634710312\n",
      "classification ---- 21860 metric train_loss = 0.26299586445093154\n",
      "classification ---- 21870 metric train_loss = 0.22178131118416786\n",
      "classification ---- 21880 metric train_loss = 0.26538555771112443\n",
      "classification ---- 21890 metric train_loss = 0.3139093667268753\n",
      "classification ---- 21900 metric train_loss = 0.254213373363018\n",
      "classification ---- 21910 metric train_loss = 0.24767159670591354\n",
      "classification ---- 21920 metric train_loss = 0.27838717922568323\n",
      "classification ---- 21930 metric train_loss = 0.23177186399698257\n",
      "classification ---- 21940 metric train_loss = 0.2512610763311386\n",
      "classification ---- 21950 metric train_loss = 0.27739482522010805\n",
      "classification ---- 21960 metric train_loss = 0.286199551820755\n",
      "classification ---- 21970 metric train_loss = 0.2623457834124565\n",
      "classification ---- 21980 metric train_loss = 0.2886695206165314\n",
      "classification ---- 21990 metric train_loss = 0.22020190805196763\n",
      "classification ---- 22000 metric train_loss = 0.2746972180902958\n",
      "classification ---- 45 metric test_f1 = 0.9200739054033615\n",
      "classification ---- 45 metric test_accuracy = 0.92\n",
      "classification ---- 23 metric train_accuracy = 0.9170077307867213\n",
      "classification ---- 23 metric train_f1 = 0.9206195153655179\n",
      "classification ---- 22010 metric train_loss = 0.21664404422044753\n",
      "classification ---- 22020 metric train_loss = 0.27552334517240523\n",
      "classification ---- 22030 metric train_loss = 0.2499575525522232\n",
      "classification ---- 22040 metric train_loss = 0.2543331176042557\n",
      "classification ---- 22050 metric train_loss = 0.3231485038995743\n",
      "classification ---- 22060 metric train_loss = 0.2863353967666626\n",
      "classification ---- 22070 metric train_loss = 0.2574858047068119\n",
      "classification ---- 22080 metric train_loss = 0.30441234856843946\n",
      "classification ---- 22090 metric train_loss = 0.19575496539473533\n",
      "classification ---- 22100 metric train_loss = 0.29469560384750365\n",
      "classification ---- 22110 metric train_loss = 0.25524635836482046\n",
      "classification ---- 22120 metric train_loss = 0.2390845835208893\n",
      "classification ---- 22130 metric train_loss = 0.27039607167243956\n",
      "classification ---- 22140 metric train_loss = 0.294757267832756\n",
      "classification ---- 22150 metric train_loss = 0.26087808758020403\n",
      "classification ---- 22160 metric train_loss = 0.23003825843334197\n",
      "classification ---- 22170 metric train_loss = 0.21287019178271294\n",
      "classification ---- 22180 metric train_loss = 0.2836602970957756\n",
      "classification ---- 22190 metric train_loss = 0.28678239732980726\n",
      "classification ---- 22200 metric train_loss = 0.2530781224370003\n",
      "classification ---- 22210 metric train_loss = 0.2238879233598709\n",
      "classification ---- 22220 metric train_loss = 0.24464435055851935\n",
      "classification ---- 22230 metric train_loss = 0.2667461812496185\n",
      "classification ---- 22240 metric train_loss = 0.22557885944843292\n",
      "classification ---- 22250 metric train_loss = 0.28832757025957106\n",
      "classification ---- 22260 metric train_loss = 0.2837799623608589\n",
      "classification ---- 22270 metric train_loss = 0.29190642684698104\n",
      "classification ---- 22280 metric train_loss = 0.3301614344120026\n",
      "classification ---- 22290 metric train_loss = 0.2563799560070038\n",
      "classification ---- 22300 metric train_loss = 0.2531129613518715\n",
      "classification ---- 22310 metric train_loss = 0.2613445192575455\n",
      "classification ---- 22320 metric train_loss = 0.3013266533613205\n",
      "classification ---- 22330 metric train_loss = 0.22567977085709573\n",
      "classification ---- 22340 metric train_loss = 0.3073342442512512\n",
      "classification ---- 22350 metric train_loss = 0.23589202761650085\n",
      "classification ---- 22360 metric train_loss = 0.26161384135484694\n",
      "classification ---- 22370 metric train_loss = 0.2486818850040436\n",
      "classification ---- 22380 metric train_loss = 0.27399071902036665\n",
      "classification ---- 22390 metric train_loss = 0.24404793828725815\n",
      "classification ---- 22400 metric train_loss = 0.250167989730835\n",
      "classification ---- 22410 metric train_loss = 0.23200056999921798\n",
      "classification ---- 22420 metric train_loss = 0.2749237880110741\n",
      "classification ---- 22430 metric train_loss = 0.2798371180891991\n",
      "classification ---- 22440 metric train_loss = 0.3021079652011395\n",
      "classification ---- 22450 metric train_loss = 0.24066944271326066\n",
      "classification ---- 22460 metric train_loss = 0.2724660292267799\n",
      "classification ---- 22470 metric train_loss = 0.263637076318264\n",
      "classification ---- 22480 metric train_loss = 0.25707016736268995\n",
      "classification ---- 22490 metric train_loss = 0.27959970384836197\n",
      "classification ---- 22500 metric train_loss = 0.262088930606842\n",
      "classification ---- 46 metric test_f1 = 0.917836934368807\n",
      "classification ---- 46 metric test_accuracy = 0.9186363636363636\n",
      "classification ---- 22510 metric train_loss = 0.24607662856578827\n",
      "classification ---- 22520 metric train_loss = 0.2543099083006382\n",
      "classification ---- 22530 metric train_loss = 0.2516741707921028\n",
      "classification ---- 22540 metric train_loss = 0.27845440432429314\n",
      "classification ---- 22550 metric train_loss = 0.25529116466641427\n",
      "classification ---- 22560 metric train_loss = 0.24257025867700577\n",
      "classification ---- 22570 metric train_loss = 0.2971891850233078\n",
      "classification ---- 22580 metric train_loss = 0.28228087797760965\n",
      "classification ---- 22590 metric train_loss = 0.19987517446279526\n",
      "classification ---- 22600 metric train_loss = 0.2743263810873032\n",
      "classification ---- 22610 metric train_loss = 0.2646517314016819\n",
      "classification ---- 22620 metric train_loss = 0.2367882803082466\n",
      "classification ---- 22630 metric train_loss = 0.22594208344817163\n",
      "classification ---- 22640 metric train_loss = 0.2396399475634098\n",
      "classification ---- 22650 metric train_loss = 0.2358998864889145\n",
      "classification ---- 22660 metric train_loss = 0.27576692700386046\n",
      "classification ---- 22670 metric train_loss = 0.271163634955883\n",
      "classification ---- 22680 metric train_loss = 0.259613972902298\n",
      "classification ---- 22690 metric train_loss = 0.2898043654859066\n",
      "classification ---- 22700 metric train_loss = 0.23016966879367828\n",
      "classification ---- 22710 metric train_loss = 0.2585725739598274\n",
      "classification ---- 22720 metric train_loss = 0.28078474625945093\n",
      "classification ---- 22730 metric train_loss = 0.2563473626971245\n",
      "classification ---- 22740 metric train_loss = 0.22162956595420838\n",
      "classification ---- 22750 metric train_loss = 0.24256124794483186\n",
      "classification ---- 22760 metric train_loss = 0.3237625151872635\n",
      "classification ---- 22770 metric train_loss = 0.22270758002996444\n",
      "classification ---- 22780 metric train_loss = 0.2776992477476597\n",
      "classification ---- 22790 metric train_loss = 0.23155777007341385\n",
      "classification ---- 22800 metric train_loss = 0.2833229437470436\n",
      "classification ---- 22810 metric train_loss = 0.21906975284218788\n",
      "classification ---- 22820 metric train_loss = 0.220222869515419\n",
      "classification ---- 22830 metric train_loss = 0.27320643812417983\n",
      "classification ---- 22840 metric train_loss = 0.21347831562161446\n",
      "classification ---- 22850 metric train_loss = 0.32024082392454145\n",
      "classification ---- 22860 metric train_loss = 0.2762217476963997\n",
      "classification ---- 22870 metric train_loss = 0.26823209375143053\n",
      "classification ---- 22880 metric train_loss = 0.2537592425942421\n",
      "classification ---- 22890 metric train_loss = 0.3079856351017952\n",
      "classification ---- 22900 metric train_loss = 0.2843142956495285\n",
      "classification ---- 22910 metric train_loss = 0.2451007291674614\n",
      "classification ---- 22920 metric train_loss = 0.26098441183567045\n",
      "classification ---- 22930 metric train_loss = 0.21448813527822494\n",
      "classification ---- 22940 metric train_loss = 0.24681255221366882\n",
      "classification ---- 22950 metric train_loss = 0.2521927922964096\n",
      "classification ---- 22960 metric train_loss = 0.26412743180990217\n",
      "classification ---- 22970 metric train_loss = 0.22144178301095963\n",
      "classification ---- 22980 metric train_loss = 0.24381230622529984\n",
      "classification ---- 22990 metric train_loss = 0.24576639011502266\n",
      "classification ---- 23000 metric train_loss = 0.22424690052866936\n",
      "classification ---- 47 metric test_f1 = 0.918393873424006\n",
      "classification ---- 47 metric test_accuracy = 0.9172727272727272\n",
      "classification ---- 24 metric train_accuracy = 0.9109822646657572\n",
      "classification ---- 24 metric train_f1 = 0.9131780362474252\n",
      "classification ---- 23010 metric train_loss = 0.25685684084892274\n",
      "classification ---- 23020 metric train_loss = 0.2544499307870865\n",
      "classification ---- 23030 metric train_loss = 0.2687128260731697\n",
      "classification ---- 23040 metric train_loss = 0.23473944440484046\n",
      "classification ---- 23050 metric train_loss = 0.2622383937239647\n",
      "classification ---- 23060 metric train_loss = 0.22466704696416856\n",
      "classification ---- 23070 metric train_loss = 0.24204509556293488\n",
      "classification ---- 23080 metric train_loss = 0.27754229456186297\n",
      "classification ---- 23090 metric train_loss = 0.2675584897398949\n",
      "classification ---- 23100 metric train_loss = 0.2299715369939804\n",
      "classification ---- 23110 metric train_loss = 0.2527731090784073\n",
      "classification ---- 23120 metric train_loss = 0.24205179363489152\n",
      "classification ---- 23130 metric train_loss = 0.2956479012966156\n",
      "classification ---- 23140 metric train_loss = 0.2664294898509979\n",
      "classification ---- 23150 metric train_loss = 0.23463454246520996\n",
      "classification ---- 23160 metric train_loss = 0.2614703565835953\n",
      "classification ---- 23170 metric train_loss = 0.23651693090796472\n",
      "classification ---- 23180 metric train_loss = 0.22842234671115874\n",
      "classification ---- 23190 metric train_loss = 0.26221226155757904\n",
      "classification ---- 23200 metric train_loss = 0.2699663907289505\n",
      "classification ---- 23210 metric train_loss = 0.23877991884946823\n",
      "classification ---- 23220 metric train_loss = 0.28979416340589526\n",
      "classification ---- 23230 metric train_loss = 0.2928194165229797\n",
      "classification ---- 23240 metric train_loss = 0.2598657801747322\n",
      "classification ---- 23250 metric train_loss = 0.2626970961689949\n",
      "classification ---- 23260 metric train_loss = 0.24090224802494048\n",
      "classification ---- 23270 metric train_loss = 0.28076115548610686\n",
      "classification ---- 23280 metric train_loss = 0.24608602598309517\n",
      "classification ---- 23290 metric train_loss = 0.27178150713443755\n",
      "classification ---- 23300 metric train_loss = 0.21465354785323143\n",
      "classification ---- 23310 metric train_loss = 0.219132636487484\n",
      "classification ---- 23320 metric train_loss = 0.31189102977514266\n",
      "classification ---- 23330 metric train_loss = 0.2784049712121487\n",
      "classification ---- 23340 metric train_loss = 0.23668326437473297\n",
      "classification ---- 23350 metric train_loss = 0.21966056078672408\n",
      "classification ---- 23360 metric train_loss = 0.2993027985095978\n",
      "classification ---- 23370 metric train_loss = 0.2375887304544449\n",
      "classification ---- 23380 metric train_loss = 0.2723129436373711\n",
      "classification ---- 23390 metric train_loss = 0.23975413516163827\n",
      "classification ---- 23400 metric train_loss = 0.27237866818904877\n",
      "classification ---- 23410 metric train_loss = 0.25624471008777616\n",
      "classification ---- 23420 metric train_loss = 0.24391281753778457\n",
      "classification ---- 23430 metric train_loss = 0.27704904079437254\n",
      "classification ---- 23440 metric train_loss = 0.2597107753157616\n",
      "classification ---- 23450 metric train_loss = 0.23053509443998338\n",
      "classification ---- 23460 metric train_loss = 0.2419536218047142\n",
      "classification ---- 23470 metric train_loss = 0.2464159309864044\n",
      "classification ---- 23480 metric train_loss = 0.2180427260696888\n",
      "classification ---- 23490 metric train_loss = 0.2444632351398468\n",
      "classification ---- 23500 metric train_loss = 0.23657746836543084\n",
      "classification ---- 48 metric test_f1 = 0.9267673565051963\n",
      "classification ---- 48 metric test_accuracy = 0.925\n",
      "classification ---- 23510 metric train_loss = 0.23380065262317656\n",
      "classification ---- 23520 metric train_loss = 0.23742718026041984\n",
      "classification ---- 23530 metric train_loss = 0.2694776639342308\n",
      "classification ---- 23540 metric train_loss = 0.2848470762372017\n",
      "classification ---- 23550 metric train_loss = 0.2852558195590973\n",
      "classification ---- 23560 metric train_loss = 0.26614137440919877\n",
      "classification ---- 23570 metric train_loss = 0.2059060476720333\n",
      "classification ---- 23580 metric train_loss = 0.20676006972789765\n",
      "classification ---- 23590 metric train_loss = 0.3074444055557251\n",
      "classification ---- 23600 metric train_loss = 0.20172353088855743\n",
      "classification ---- 23610 metric train_loss = 0.2655194491147995\n",
      "classification ---- 23620 metric train_loss = 0.2067939169704914\n",
      "classification ---- 23630 metric train_loss = 0.23384482264518738\n",
      "classification ---- 23640 metric train_loss = 0.25678423792123795\n",
      "classification ---- 23650 metric train_loss = 0.23664896339178085\n",
      "classification ---- 23660 metric train_loss = 0.306741338968277\n",
      "classification ---- 23670 metric train_loss = 0.2715951457619667\n",
      "classification ---- 23680 metric train_loss = 0.24072161614894866\n",
      "classification ---- 23690 metric train_loss = 0.2384577825665474\n",
      "classification ---- 23700 metric train_loss = 0.29920576959848405\n",
      "classification ---- 23710 metric train_loss = 0.20290575325489044\n",
      "classification ---- 23720 metric train_loss = 0.2290332742035389\n",
      "classification ---- 23730 metric train_loss = 0.22467610538005828\n",
      "classification ---- 23740 metric train_loss = 0.3023823365569115\n",
      "classification ---- 23750 metric train_loss = 0.22765125036239625\n",
      "classification ---- 23760 metric train_loss = 0.23246860057115554\n",
      "classification ---- 23770 metric train_loss = 0.2731323570013046\n",
      "classification ---- 23780 metric train_loss = 0.24964796602725983\n",
      "classification ---- 23790 metric train_loss = 0.26810325384140016\n",
      "classification ---- 23800 metric train_loss = 0.21304487437009811\n",
      "classification ---- 23810 metric train_loss = 0.27850720286369324\n",
      "classification ---- 23820 metric train_loss = 0.23568978905677795\n",
      "classification ---- 23830 metric train_loss = 0.2504312425851822\n",
      "classification ---- 23840 metric train_loss = 0.2508639097213745\n",
      "classification ---- 23850 metric train_loss = 0.2683748498558998\n",
      "classification ---- 23860 metric train_loss = 0.28625118136405947\n",
      "classification ---- 23870 metric train_loss = 0.25588881596922874\n",
      "classification ---- 23880 metric train_loss = 0.24657153934240342\n",
      "classification ---- 23890 metric train_loss = 0.2727616935968399\n",
      "classification ---- 23900 metric train_loss = 0.23101586550474168\n",
      "classification ---- 23910 metric train_loss = 0.21910635828971864\n",
      "classification ---- 23920 metric train_loss = 0.2184924751520157\n",
      "classification ---- 23930 metric train_loss = 0.23407007455825807\n",
      "classification ---- 23940 metric train_loss = 0.24338296204805374\n",
      "classification ---- 23950 metric train_loss = 0.22799623757600784\n",
      "classification ---- 23960 metric train_loss = 0.2762510284781456\n",
      "classification ---- 23970 metric train_loss = 0.28977632969617845\n",
      "classification ---- 23980 metric train_loss = 0.26475134789943694\n",
      "classification ---- 23990 metric train_loss = 0.24671713784337043\n",
      "classification ---- 24000 metric train_loss = 0.2638939216732979\n",
      "classification ---- 49 metric test_f1 = 0.91562814460514\n",
      "classification ---- 49 metric test_accuracy = 0.9145454545454546\n",
      "classification ---- 25 metric train_accuracy = 0.9124602091859937\n",
      "classification ---- 25 metric train_f1 = 0.9154137425357977\n",
      "classification ---- 24010 metric train_loss = 0.22268070429563522\n",
      "classification ---- 24020 metric train_loss = 0.27657814472913744\n",
      "classification ---- 24030 metric train_loss = 0.23836073130369187\n",
      "classification ---- 24040 metric train_loss = 0.2696544110774994\n",
      "classification ---- 24050 metric train_loss = 0.29216659963130953\n",
      "classification ---- 24060 metric train_loss = 0.2518347159028053\n",
      "classification ---- 24070 metric train_loss = 0.26754131615161897\n",
      "classification ---- 24080 metric train_loss = 0.28168344795703887\n",
      "classification ---- 24090 metric train_loss = 0.3068476811051369\n",
      "classification ---- 24100 metric train_loss = 0.3265602394938469\n",
      "classification ---- 24110 metric train_loss = 0.2184645041823387\n",
      "classification ---- 24120 metric train_loss = 0.2569075547158718\n",
      "classification ---- 24130 metric train_loss = 0.18742226138710977\n",
      "classification ---- 24140 metric train_loss = 0.24089639782905578\n",
      "classification ---- 24150 metric train_loss = 0.2828198060393333\n",
      "classification ---- 24160 metric train_loss = 0.2791151896119118\n",
      "classification ---- 24170 metric train_loss = 0.2812707722187042\n",
      "classification ---- 24180 metric train_loss = 0.28306101858615873\n",
      "classification ---- 24190 metric train_loss = 0.2796916589140892\n",
      "classification ---- 24200 metric train_loss = 0.21380142644047737\n",
      "classification ---- 24210 metric train_loss = 0.21936706379055976\n",
      "classification ---- 24220 metric train_loss = 0.24059537053108215\n",
      "classification ---- 24230 metric train_loss = 0.27388463243842126\n",
      "classification ---- 24240 metric train_loss = 0.21318446546792985\n",
      "classification ---- 24250 metric train_loss = 0.2738163836300373\n",
      "classification ---- 24260 metric train_loss = 0.23973261415958405\n",
      "classification ---- 24270 metric train_loss = 0.22346301227808\n",
      "classification ---- 24280 metric train_loss = 0.25036494582891466\n",
      "classification ---- 24290 metric train_loss = 0.23318790420889854\n",
      "classification ---- 24300 metric train_loss = 0.23625147044658662\n",
      "classification ---- 24310 metric train_loss = 0.2309316836297512\n",
      "classification ---- 24320 metric train_loss = 0.2765146687626839\n",
      "classification ---- 24330 metric train_loss = 0.28253870755434035\n",
      "classification ---- 24340 metric train_loss = 0.2552949652075768\n",
      "classification ---- 24350 metric train_loss = 0.2435702919960022\n",
      "classification ---- 24360 metric train_loss = 0.27626364678144455\n",
      "classification ---- 24370 metric train_loss = 0.3368526205420494\n",
      "classification ---- 24380 metric train_loss = 0.2456013560295105\n",
      "classification ---- 24390 metric train_loss = 0.23547001034021378\n",
      "classification ---- 24400 metric train_loss = 0.23288778960704803\n",
      "classification ---- 24410 metric train_loss = 0.24742517620325089\n",
      "classification ---- 24420 metric train_loss = 0.24217431694269181\n",
      "classification ---- 24430 metric train_loss = 0.2519386649131775\n",
      "classification ---- 24440 metric train_loss = 0.23494151830673218\n",
      "classification ---- 24450 metric train_loss = 0.2259908750653267\n",
      "classification ---- 24460 metric train_loss = 0.21052123233675957\n",
      "classification ---- 24470 metric train_loss = 0.2618859753012657\n",
      "classification ---- 24480 metric train_loss = 0.29432550221681597\n",
      "classification ---- 24490 metric train_loss = 0.21744479835033417\n",
      "classification ---- 24500 metric train_loss = 0.2234427288174629\n",
      "classification ---- 50 metric test_f1 = 0.9194911348875847\n",
      "classification ---- 50 metric test_accuracy = 0.92\n",
      "classification ---- 24510 metric train_loss = 0.23097820878028869\n",
      "classification ---- 24520 metric train_loss = 0.23730756491422653\n",
      "classification ---- 24530 metric train_loss = 0.279533688724041\n",
      "classification ---- 24540 metric train_loss = 0.21699923574924468\n",
      "classification ---- 24550 metric train_loss = 0.19281551092863083\n",
      "classification ---- 24560 metric train_loss = 0.20038923993706703\n",
      "classification ---- 24570 metric train_loss = 0.23032572567462922\n",
      "classification ---- 24580 metric train_loss = 0.18884044587612153\n",
      "classification ---- 24590 metric train_loss = 0.2368221953511238\n",
      "classification ---- 24600 metric train_loss = 0.23686472028493882\n",
      "classification ---- 24610 metric train_loss = 0.2672718048095703\n",
      "classification ---- 24620 metric train_loss = 0.21239120736718178\n",
      "classification ---- 24630 metric train_loss = 0.19705479964613914\n",
      "classification ---- 24640 metric train_loss = 0.2720236048102379\n",
      "classification ---- 24650 metric train_loss = 0.24532103911042213\n",
      "classification ---- 24660 metric train_loss = 0.2832687355577946\n",
      "classification ---- 24670 metric train_loss = 0.23895130008459092\n",
      "classification ---- 24680 metric train_loss = 0.28475054949522016\n",
      "classification ---- 24690 metric train_loss = 0.2209476113319397\n",
      "classification ---- 24700 metric train_loss = 0.23125073164701462\n",
      "classification ---- 24710 metric train_loss = 0.28208497613668443\n",
      "classification ---- 24720 metric train_loss = 0.21370192766189575\n",
      "classification ---- 24730 metric train_loss = 0.2159781575202942\n",
      "classification ---- 24740 metric train_loss = 0.23873682767152787\n",
      "classification ---- 24750 metric train_loss = 0.23777832835912704\n",
      "classification ---- 24760 metric train_loss = 0.2567500278353691\n",
      "classification ---- 24770 metric train_loss = 0.2676979497075081\n",
      "classification ---- 24780 metric train_loss = 0.2687672823667526\n",
      "classification ---- 24790 metric train_loss = 0.23795417100191116\n",
      "classification ---- 24800 metric train_loss = 0.2114439621567726\n",
      "classification ---- 24810 metric train_loss = 0.2173202469944954\n",
      "classification ---- 24820 metric train_loss = 0.20869198441505432\n",
      "classification ---- 24830 metric train_loss = 0.28209746181964873\n",
      "classification ---- 24840 metric train_loss = 0.23215607702732086\n",
      "classification ---- 24850 metric train_loss = 0.2553598880767822\n",
      "classification ---- 24860 metric train_loss = 0.23545305281877518\n",
      "classification ---- 24870 metric train_loss = 0.18778139278292655\n",
      "classification ---- 24880 metric train_loss = 0.24850633442401887\n",
      "classification ---- 24890 metric train_loss = 0.2595414012670517\n",
      "classification ---- 24900 metric train_loss = 0.2734210565686226\n",
      "classification ---- 24910 metric train_loss = 0.2597189895808697\n",
      "classification ---- 24920 metric train_loss = 0.2539996452629566\n",
      "classification ---- 24930 metric train_loss = 0.2629894629120827\n",
      "classification ---- 24940 metric train_loss = 0.1938456892967224\n",
      "classification ---- 24950 metric train_loss = 0.2887321889400482\n",
      "classification ---- 24960 metric train_loss = 0.22389728873968123\n",
      "classification ---- 24970 metric train_loss = 0.24147464334964752\n",
      "classification ---- 24980 metric train_loss = 0.24270426481962204\n",
      "classification ---- 24990 metric train_loss = 0.27884525060653687\n",
      "classification ---- 25000 metric train_loss = 0.23802395164966583\n",
      "classification ---- 51 metric test_f1 = 0.918718299793308\n",
      "classification ---- 51 metric test_accuracy = 0.9218181818181819\n",
      "classification ---- 26 metric train_accuracy = 0.9176898590268304\n",
      "classification ---- 26 metric train_f1 = 0.9205397133959634\n",
      "classification ---- 25010 metric train_loss = 0.21350278332829475\n",
      "classification ---- 25020 metric train_loss = 0.2573023810982704\n",
      "classification ---- 25030 metric train_loss = 0.2704786017537117\n",
      "classification ---- 25040 metric train_loss = 0.271797663718462\n",
      "classification ---- 25050 metric train_loss = 0.20887887328863144\n",
      "classification ---- 25060 metric train_loss = 0.1995847776532173\n",
      "classification ---- 25070 metric train_loss = 0.20538859739899634\n",
      "classification ---- 25080 metric train_loss = 0.2663044914603233\n",
      "classification ---- 25090 metric train_loss = 0.2429158091545105\n",
      "classification ---- 25100 metric train_loss = 0.21979160979390144\n",
      "classification ---- 25110 metric train_loss = 0.2360805258154869\n",
      "classification ---- 25120 metric train_loss = 0.23258880376815796\n",
      "classification ---- 25130 metric train_loss = 0.22378454804420472\n",
      "classification ---- 25140 metric train_loss = 0.20265229493379594\n",
      "classification ---- 25150 metric train_loss = 0.23810856342315673\n",
      "classification ---- 25160 metric train_loss = 0.22277373522520066\n",
      "classification ---- 25170 metric train_loss = 0.2655292548239231\n",
      "classification ---- 25180 metric train_loss = 0.27526697516441345\n",
      "classification ---- 25190 metric train_loss = 0.23716189861297607\n",
      "classification ---- 25200 metric train_loss = 0.26718267500400544\n",
      "classification ---- 25210 metric train_loss = 0.24727521538734437\n",
      "classification ---- 25220 metric train_loss = 0.22562023997306824\n",
      "classification ---- 25230 metric train_loss = 0.23148205652832984\n",
      "classification ---- 25240 metric train_loss = 0.2686218902468681\n",
      "classification ---- 25250 metric train_loss = 0.2393445134162903\n",
      "classification ---- 25260 metric train_loss = 0.23196094185113908\n",
      "classification ---- 25270 metric train_loss = 0.23833144083619118\n",
      "classification ---- 25280 metric train_loss = 0.2588577553629875\n",
      "classification ---- 25290 metric train_loss = 0.2772566244006157\n",
      "classification ---- 25300 metric train_loss = 0.2354647159576416\n",
      "classification ---- 25310 metric train_loss = 0.214766875654459\n",
      "classification ---- 25320 metric train_loss = 0.20610906258225442\n",
      "classification ---- 25330 metric train_loss = 0.20722915679216386\n",
      "classification ---- 25340 metric train_loss = 0.22744813375175\n",
      "classification ---- 25350 metric train_loss = 0.2798344314098358\n",
      "classification ---- 25360 metric train_loss = 0.21518402844667434\n",
      "classification ---- 25370 metric train_loss = 0.2257076121866703\n",
      "classification ---- 25380 metric train_loss = 0.2539976269006729\n",
      "classification ---- 25390 metric train_loss = 0.2687621235847473\n",
      "classification ---- 25400 metric train_loss = 0.23061035722494125\n",
      "classification ---- 25410 metric train_loss = 0.23488108813762665\n",
      "classification ---- 25420 metric train_loss = 0.24174749702215195\n",
      "classification ---- 25430 metric train_loss = 0.2261610969901085\n",
      "classification ---- 25440 metric train_loss = 0.27284167557954786\n",
      "classification ---- 25450 metric train_loss = 0.2011297270655632\n",
      "classification ---- 25460 metric train_loss = 0.25688097923994063\n",
      "classification ---- 25470 metric train_loss = 0.20936598330736161\n",
      "classification ---- 25480 metric train_loss = 0.2844475328922272\n",
      "classification ---- 25490 metric train_loss = 0.2530013665556908\n",
      "classification ---- 25500 metric train_loss = 0.21738286092877387\n",
      "classification ---- 52 metric test_f1 = 0.9163278301605313\n",
      "classification ---- 52 metric test_accuracy = 0.9168181818181819\n",
      "classification ---- 25510 metric train_loss = 0.20710949823260308\n",
      "classification ---- 25520 metric train_loss = 0.22497151270508767\n",
      "classification ---- 25530 metric train_loss = 0.23922095447778702\n",
      "classification ---- 25540 metric train_loss = 0.22454327046871186\n",
      "classification ---- 25550 metric train_loss = 0.24275696128606797\n",
      "classification ---- 25560 metric train_loss = 0.21535793989896773\n",
      "classification ---- 25570 metric train_loss = 0.2731268733739853\n",
      "classification ---- 25580 metric train_loss = 0.24581980854272842\n",
      "classification ---- 25590 metric train_loss = 0.293833389878273\n",
      "classification ---- 25600 metric train_loss = 0.25573028177022933\n",
      "classification ---- 25610 metric train_loss = 0.2679086297750473\n",
      "classification ---- 25620 metric train_loss = 0.2614750325679779\n",
      "classification ---- 25630 metric train_loss = 0.20544151291251184\n",
      "classification ---- 25640 metric train_loss = 0.22258605509996415\n",
      "classification ---- 25650 metric train_loss = 0.25499954372644423\n",
      "classification ---- 25660 metric train_loss = 0.21697021871805192\n",
      "classification ---- 25670 metric train_loss = 0.22576764822006226\n",
      "classification ---- 25680 metric train_loss = 0.22847601696848868\n",
      "classification ---- 25690 metric train_loss = 0.2374571830034256\n",
      "classification ---- 25700 metric train_loss = 0.26760384663939474\n",
      "classification ---- 25710 metric train_loss = 0.26845117658376694\n",
      "classification ---- 25720 metric train_loss = 0.24237048402428626\n",
      "classification ---- 25730 metric train_loss = 0.23255899399518967\n",
      "classification ---- 25740 metric train_loss = 0.2686827898025513\n",
      "classification ---- 25750 metric train_loss = 0.22739251106977462\n",
      "classification ---- 25760 metric train_loss = 0.20691420882940292\n",
      "classification ---- 25770 metric train_loss = 0.2310067296028137\n",
      "classification ---- 25780 metric train_loss = 0.20926730036735536\n",
      "classification ---- 25790 metric train_loss = 0.2603429213166237\n",
      "classification ---- 25800 metric train_loss = 0.23015728145837783\n",
      "classification ---- 25810 metric train_loss = 0.24858410134911538\n",
      "classification ---- 25820 metric train_loss = 0.25917657017707824\n",
      "classification ---- 25830 metric train_loss = 0.2538807958364487\n",
      "classification ---- 25840 metric train_loss = 0.2126550555229187\n",
      "classification ---- 25850 metric train_loss = 0.24745360761880875\n",
      "classification ---- 25860 metric train_loss = 0.27208729833364487\n",
      "classification ---- 25870 metric train_loss = 0.22679175212979316\n",
      "classification ---- 25880 metric train_loss = 0.22540048509836197\n",
      "classification ---- 25890 metric train_loss = 0.22895971387624742\n",
      "classification ---- 25900 metric train_loss = 0.22564260065555572\n",
      "classification ---- 25910 metric train_loss = 0.22087194100022317\n",
      "classification ---- 25920 metric train_loss = 0.28047210797667504\n",
      "classification ---- 25930 metric train_loss = 0.24910484850406647\n",
      "classification ---- 25940 metric train_loss = 0.25558598153293133\n",
      "classification ---- 25950 metric train_loss = 0.2446427136659622\n",
      "classification ---- 25960 metric train_loss = 0.188102538138628\n",
      "classification ---- 25970 metric train_loss = 0.1939355507493019\n",
      "classification ---- 25980 metric train_loss = 0.25490008741617204\n",
      "classification ---- 25990 metric train_loss = 0.2552554279565811\n",
      "classification ---- 26000 metric train_loss = 0.2076816275715828\n",
      "classification ---- 53 metric test_f1 = 0.9242602307808244\n",
      "classification ---- 53 metric test_accuracy = 0.9245454545454546\n",
      "classification ---- 27 metric train_accuracy = 0.916894042746703\n",
      "classification ---- 27 metric train_f1 = 0.9198832113786862\n",
      "classification ---- 26010 metric train_loss = 0.19792341738939284\n",
      "classification ---- 26020 metric train_loss = 0.3243814378976822\n",
      "classification ---- 26030 metric train_loss = 0.23148780912160874\n",
      "classification ---- 26040 metric train_loss = 0.2594719812273979\n",
      "classification ---- 26050 metric train_loss = 0.2357748731970787\n",
      "classification ---- 26060 metric train_loss = 0.2542124718427658\n",
      "classification ---- 26070 metric train_loss = 0.2220461994409561\n",
      "classification ---- 26080 metric train_loss = 0.26416987031698225\n",
      "classification ---- 26090 metric train_loss = 0.20532945692539215\n",
      "classification ---- 26100 metric train_loss = 0.2361558496952057\n",
      "classification ---- 26110 metric train_loss = 0.22597577422857285\n",
      "classification ---- 26120 metric train_loss = 0.24620779007673263\n",
      "classification ---- 26130 metric train_loss = 0.19924461171031\n",
      "classification ---- 26140 metric train_loss = 0.24868418276309967\n",
      "classification ---- 26150 metric train_loss = 0.24542755782604217\n",
      "classification ---- 26160 metric train_loss = 0.20825444161891937\n",
      "classification ---- 26170 metric train_loss = 0.2532438591122627\n",
      "classification ---- 26180 metric train_loss = 0.22865976840257646\n",
      "classification ---- 26190 metric train_loss = 0.2826815605163574\n",
      "classification ---- 26200 metric train_loss = 0.24840930551290513\n",
      "classification ---- 26210 metric train_loss = 0.290435629338026\n",
      "classification ---- 26220 metric train_loss = 0.22064579501748086\n",
      "classification ---- 26230 metric train_loss = 0.21153470426797866\n",
      "classification ---- 26240 metric train_loss = 0.2535923182964325\n",
      "classification ---- 26250 metric train_loss = 0.23937851712107658\n",
      "classification ---- 26260 metric train_loss = 0.24409071132540702\n",
      "classification ---- 26270 metric train_loss = 0.25254088938236235\n",
      "classification ---- 26280 metric train_loss = 0.2017328418791294\n",
      "classification ---- 26290 metric train_loss = 0.2152012124657631\n",
      "classification ---- 26300 metric train_loss = 0.20323033183813094\n",
      "classification ---- 26310 metric train_loss = 0.20737497955560685\n",
      "classification ---- 26320 metric train_loss = 0.2701846405863762\n",
      "classification ---- 26330 metric train_loss = 0.21475501507520675\n",
      "classification ---- 26340 metric train_loss = 0.2020465187728405\n",
      "classification ---- 26350 metric train_loss = 0.29499111473560335\n",
      "classification ---- 26360 metric train_loss = 0.19247580617666243\n",
      "classification ---- 26370 metric train_loss = 0.21598929092288016\n",
      "classification ---- 26380 metric train_loss = 0.23099780231714248\n",
      "classification ---- 26390 metric train_loss = 0.22257583290338517\n",
      "classification ---- 26400 metric train_loss = 0.2342018276453018\n",
      "classification ---- 26410 metric train_loss = 0.24506343454122542\n",
      "classification ---- 26420 metric train_loss = 0.322216671705246\n",
      "classification ---- 26430 metric train_loss = 0.23445179164409638\n",
      "classification ---- 26440 metric train_loss = 0.2557128340005875\n",
      "classification ---- 26450 metric train_loss = 0.19473869800567628\n",
      "classification ---- 26460 metric train_loss = 0.2474147744476795\n",
      "classification ---- 26470 metric train_loss = 0.2547003500163555\n",
      "classification ---- 26480 metric train_loss = 0.27820468991994857\n",
      "classification ---- 26490 metric train_loss = 0.24944658651947976\n",
      "classification ---- 26500 metric train_loss = 0.24347687661647796\n",
      "classification ---- 54 metric test_f1 = 0.9227177937757466\n",
      "classification ---- 54 metric test_accuracy = 0.9222727272727272\n",
      "classification ---- 26510 metric train_loss = 0.22040130645036698\n",
      "classification ---- 26520 metric train_loss = 0.21906746178865433\n",
      "classification ---- 26530 metric train_loss = 0.20110730826854706\n",
      "classification ---- 26540 metric train_loss = 0.19527653157711028\n",
      "classification ---- 26550 metric train_loss = 0.29458241909742355\n",
      "classification ---- 26560 metric train_loss = 0.2821797043085098\n",
      "classification ---- 26570 metric train_loss = 0.2532002002000809\n",
      "classification ---- 26580 metric train_loss = 0.21370504871010781\n",
      "classification ---- 26590 metric train_loss = 0.25549772307276725\n",
      "classification ---- 26600 metric train_loss = 0.23504738062620162\n",
      "classification ---- 26610 metric train_loss = 0.18984550535678862\n",
      "classification ---- 26620 metric train_loss = 0.2516613878309727\n",
      "classification ---- 26630 metric train_loss = 0.259342934936285\n",
      "classification ---- 26640 metric train_loss = 0.2750672370195389\n",
      "classification ---- 26650 metric train_loss = 0.2382811948657036\n",
      "classification ---- 26660 metric train_loss = 0.2845736563205719\n",
      "classification ---- 26670 metric train_loss = 0.2832477711141109\n",
      "classification ---- 26680 metric train_loss = 0.2189057946205139\n",
      "classification ---- 26690 metric train_loss = 0.2992345102131367\n",
      "classification ---- 26700 metric train_loss = 0.28620578348636627\n",
      "classification ---- 26710 metric train_loss = 0.23091236427426337\n",
      "classification ---- 26720 metric train_loss = 0.19872556924819945\n",
      "classification ---- 26730 metric train_loss = 0.21218105107545854\n",
      "classification ---- 26740 metric train_loss = 0.18410965725779532\n",
      "classification ---- 26750 metric train_loss = 0.22207212820649147\n",
      "classification ---- 26760 metric train_loss = 0.24453167617321014\n",
      "classification ---- 26770 metric train_loss = 0.21954497694969177\n",
      "classification ---- 26780 metric train_loss = 0.22654428333044052\n",
      "classification ---- 26790 metric train_loss = 0.28732400089502336\n",
      "classification ---- 26800 metric train_loss = 0.250989006459713\n",
      "classification ---- 26810 metric train_loss = 0.23424326106905938\n",
      "classification ---- 26820 metric train_loss = 0.23727671951055526\n",
      "classification ---- 26830 metric train_loss = 0.22585504353046418\n",
      "classification ---- 26840 metric train_loss = 0.2571986585855484\n",
      "classification ---- 26850 metric train_loss = 0.2028108298778534\n",
      "classification ---- 26860 metric train_loss = 0.2254582680761814\n",
      "classification ---- 26870 metric train_loss = 0.2135976128280163\n",
      "classification ---- 26880 metric train_loss = 0.19482297152280809\n",
      "classification ---- 26890 metric train_loss = 0.2259977474808693\n",
      "classification ---- 26900 metric train_loss = 0.23302116319537164\n",
      "classification ---- 26910 metric train_loss = 0.28704890608787537\n",
      "classification ---- 26920 metric train_loss = 0.2802823558449745\n",
      "classification ---- 26930 metric train_loss = 0.24207107722759247\n",
      "classification ---- 26940 metric train_loss = 0.20805127322673797\n",
      "classification ---- 26950 metric train_loss = 0.27849476635456083\n",
      "classification ---- 26960 metric train_loss = 0.19923968464136124\n",
      "classification ---- 26970 metric train_loss = 0.22564830332994462\n",
      "classification ---- 26980 metric train_loss = 0.19274085760116577\n",
      "classification ---- 26990 metric train_loss = 0.21280741393566133\n",
      "classification ---- 27000 metric train_loss = 0.2008289471268654\n",
      "classification ---- 55 metric test_f1 = 0.9227931810905371\n",
      "classification ---- 55 metric test_accuracy = 0.9245454545454546\n",
      "classification ---- 28 metric train_accuracy = 0.9221236925875398\n",
      "classification ---- 28 metric train_f1 = 0.9256562393023942\n",
      "classification ---- 27010 metric train_loss = 0.288301508128643\n",
      "classification ---- 27020 metric train_loss = 0.22482041493058205\n",
      "classification ---- 27030 metric train_loss = 0.22303288877010347\n",
      "classification ---- 27040 metric train_loss = 0.23331620544195175\n",
      "classification ---- 27050 metric train_loss = 0.19881174042820932\n",
      "classification ---- 27060 metric train_loss = 0.18539311811327935\n",
      "classification ---- 27070 metric train_loss = 0.19952266588807105\n",
      "classification ---- 27080 metric train_loss = 0.19766016378998758\n",
      "classification ---- 27090 metric train_loss = 0.22438675165176392\n",
      "classification ---- 27100 metric train_loss = 0.26158174574375154\n",
      "classification ---- 27110 metric train_loss = 0.2823726266622543\n",
      "classification ---- 27120 metric train_loss = 0.22732222080230713\n",
      "classification ---- 27130 metric train_loss = 0.21377939209342003\n",
      "classification ---- 27140 metric train_loss = 0.2374508872628212\n",
      "classification ---- 27150 metric train_loss = 0.2164236567914486\n",
      "classification ---- 27160 metric train_loss = 0.2637096635997295\n",
      "classification ---- 27170 metric train_loss = 0.2285461813211441\n",
      "classification ---- 27180 metric train_loss = 0.2568886555731297\n",
      "classification ---- 27190 metric train_loss = 0.21738315969705582\n",
      "classification ---- 27200 metric train_loss = 0.2458508148789406\n",
      "classification ---- 27210 metric train_loss = 0.22264138609170914\n",
      "classification ---- 27220 metric train_loss = 0.23745075687766076\n",
      "classification ---- 27230 metric train_loss = 0.20724138468503953\n",
      "classification ---- 27240 metric train_loss = 0.19116722866892816\n",
      "classification ---- 27250 metric train_loss = 0.27122262865304947\n",
      "classification ---- 27260 metric train_loss = 0.25895892530679704\n",
      "classification ---- 27270 metric train_loss = 0.2197220206260681\n",
      "classification ---- 27280 metric train_loss = 0.1962670423090458\n",
      "classification ---- 27290 metric train_loss = 0.2400854356586933\n",
      "classification ---- 27300 metric train_loss = 0.19098106473684312\n",
      "classification ---- 27310 metric train_loss = 0.24303824305534363\n",
      "classification ---- 27320 metric train_loss = 0.21904662549495696\n",
      "classification ---- 27330 metric train_loss = 0.20979414284229278\n",
      "classification ---- 27340 metric train_loss = 0.26176937520503996\n",
      "classification ---- 27350 metric train_loss = 0.218279467523098\n",
      "classification ---- 27360 metric train_loss = 0.2261678010225296\n",
      "classification ---- 27370 metric train_loss = 0.23254515826702118\n",
      "classification ---- 27380 metric train_loss = 0.30900904834270476\n",
      "classification ---- 27390 metric train_loss = 0.23093494176864623\n",
      "classification ---- 27400 metric train_loss = 0.23951005935668945\n"
     ]
    }
   ],
   "source": [
    "#classifier_ = CNNNetwork1D( **configs[\"full_model_kwargs\"])#LSTMNetwork(lstm_hidden_size= 64,lstm_input_size=6,output_dim = len(all_train_dataset.label_to_index))\n",
    "classifier_ = LSTMNetwork(**configs[\"full_model_kwargs\"])\n",
    "logger= Logger(name= \"classification\",verbose= True)\n",
    "logger.default_step_size = 500\n",
    "classification_trainer = NNClassificationTrainer(classifier = classifier_,device= device,logger= logger)\n",
    "classification_trainer.train(train_dataset= train_dataset,test_dataset= test_dataset,epochs=200,batch_size= 64,lr= .0003,use_balanced_sampler= configs[\"full_trainer_config\"][\"use_sampler\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9267673565051963"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_trainer.best[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'facebook': 0, 'pinterest': 1, 'hangout': 2, 'netflix': 3, 'google-drive': 4, 'gmail': 5, 'instagram': 6, 'spotify': 7, 'reddit': 8, 'twitter': 9}\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset.label_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'micro_f1': 0.92,\n",
       " 'macro_f1': 0.9217255738658713,\n",
       " 'accuracy': 0.92,\n",
       " 'cm': array([[246,   0,   0,   1,   0,   0,   2,   0,   6,   0],\n",
       "        [  6, 211,   0,   0,   1,   0,   1,   0,  37,   3],\n",
       "        [  0,   0,  72,   1,   0,   0,   0,   3,   0,   1],\n",
       "        [  3,   4,   0, 401,   2,   0,   5,   0,   4,   1],\n",
       "        [  2,   1,   0,   0, 163,   1,   1,   0,   0,   1],\n",
       "        [  5,   1,   0,   0,   1,  94,   1,   0,   1,   4],\n",
       "        [ 11,   0,   1,   1,   1,   1, 193,   1,   6,   1],\n",
       "        [  1,   0,   1,   0,   1,   0,   3, 158,  11,   2],\n",
       "        [  9,  10,   0,   0,   1,   0,   2,   0, 327,   2],\n",
       "        [  2,   1,   3,   1,   1,   0,   0,   0,   2, 159]]),\n",
       " 'incorrect_ood': 0.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evaluator(model= classification_trainer.best[\"model\"], device=device).getMetrices(dataset= test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rewarder:\n",
    "    def __init__(self,max_length,l,num_labels : int):\n",
    "        self.max_length = max_length\n",
    "        self.l = l # l is smaller than 1\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "    def reward(self,state : State,action : int):\n",
    "        if state.label == action:\n",
    "            # reward 1 on a correct prediction\n",
    "            return 1, True\n",
    "        else:\n",
    "            # either incorrect or wait\n",
    "            # wait \n",
    "            # treat the wait action with a negative reward\n",
    "            if action == self.num_labels:\n",
    "                if state.length == self.max_length:\n",
    "                    # it is the last timestamp\n",
    "                    if state.label == -1:\n",
    "                        return -self.l/self.max_length, True#-self.l*(state.length/self.max_length),True\n",
    "                    else:\n",
    "                        return -1, True\n",
    "                else:\n",
    "                    return  -self.l/self.max_length, False#-self.l*(state.length/self.max_length), False\n",
    "            else:\n",
    "                # incorrect\n",
    "                return -1,True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewarder = Rewarder(**configs[\"rewarder_config\"])\n",
    "memory_filler = MemoryFiller(dataset= train_dataset,rewarder= rewarder, min_length= configs[\"memory_fillter_config\"][\"min_length\"],\n",
    "                              max_length= rewarder.max_length,ood_config= configs[\"memory_fillter_config\"][\"ood_config\"], use_balancer= configs[\"memory_fillter_config\"][\"use_balancer\"]\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2128632\n"
     ]
    }
   ],
   "source": [
    "memory = memory_filler.processDataset()\n",
    "print(len(memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_dataset = MemoryDataset(memories= memory,num_classes= len(train_dataset.label_to_index),\n",
    "                               min_length= memory_filler.min_length,max_length= memory_filler.max_length)\n",
    "predictor = LSTMNetwork(**configs[\"early_model_kwargs\"])\n",
    "logger = Logger(verbose= True)\n",
    "logger.default_step_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1    360701\n",
      " 4    279147\n",
      " 5    224818\n",
      "-1    215501\n",
      " 0    211387\n",
      " 6    209814\n",
      " 9    153912\n",
      " 3    152581\n",
      " 2    147983\n",
      " 8     94501\n",
      " 7     78287\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "\n",
    "for m in memory_dataset:\n",
    "    labels.append(m[\"label\"])\n",
    "\n",
    "print(pd.Series(labels).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddq_model = EarlyClassificationtrainer(predictor= predictor,train_dataset = train_dataset,test_dataset= test_dataset,memory_dataset= memory_dataset,hint_loss_gap= .05,\n",
    "                                       ood_dataset= ood_dataset,hint_loss_alpha= .5,q_loss_alpha= 1,use_sampler= configs[\"early_trainer_config\"][\"use_sampler\"],\n",
    "                                       logger= logger,device=device,model_replacement_steps= 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ---- 1000 metric q_loss = 0.31719836155325176\n",
      " ---- 1000 metric hint_loss = 0.001989176519215107\n",
      " ---- 1 metric test_eval_f1 = 0.0\n",
      " ---- 1 metric test_eval_time = 15.0\n",
      " ---- 1 metric incorrect_ood_test = 1.0\n",
      " ---- 1 metric ood_eval = 1.0\n",
      " ---- 1 metric ood_eval_time = 15.0\n",
      " ---- 2000 metric q_loss = 0.30982620334625244\n",
      " ---- 2000 metric hint_loss = 0.02853160620853305\n",
      " ---- 2 metric test_eval_f1 = 0.0\n",
      " ---- 2 metric test_eval_time = 15.0\n",
      " ---- 2 metric incorrect_ood_test = 1.0\n",
      " ---- 2 metric ood_eval = 1.0\n",
      " ---- 2 metric ood_eval_time = 15.0\n",
      " ---- 1 metric train_eval_f1 = 0.0\n",
      " ---- 1 metric train_eval_time = 15.0\n",
      " ---- 1 metric incorrect_ood_train = 1.0\n",
      " ---- 3000 metric q_loss = 0.3177563038319349\n",
      " ---- 3000 metric hint_loss = 0.057243482571095225\n",
      " ---- 3 metric test_eval_f1 = 0.1635776544466814\n",
      " ---- 3 metric test_eval_time = 13.99\n",
      " ---- 3 metric incorrect_ood_test = 0.2863636363636364\n",
      " ---- 3 metric ood_eval = 0.9985926819461198\n",
      " ---- 3 metric ood_eval_time = 15.0\n",
      " ---- 4000 metric q_loss = 0.3249181607961655\n",
      " ---- 4000 metric hint_loss = 0.06411908627673983\n",
      " ---- 4 metric test_eval_f1 = 0.1912721539352944\n",
      " ---- 4 metric test_eval_time = 13.709545454545454\n",
      " ---- 4 metric incorrect_ood_test = 0.73\n",
      " ---- 4 metric ood_eval = 0.9847205468435867\n",
      " ---- 4 metric ood_eval_time = 14.986127864897467\n",
      " ---- 2 metric train_eval_f1 = 0.1403093706654082\n",
      " ---- 2 metric train_eval_time = 14.181105047748977\n",
      " ---- 2 metric incorrect_ood_train = 0.8040018190086403\n",
      " ---- 5000 metric q_loss = 0.3244031126350164\n",
      " ---- 5000 metric hint_loss = 0.0658111491985619\n",
      " ---- 5 metric test_eval_f1 = 0.07986274641322857\n",
      " ---- 5 metric test_eval_time = 13.655\n",
      " ---- 5 metric incorrect_ood_test = 0.79\n",
      " ---- 5 metric ood_eval = 0.9686369119420989\n",
      " ---- 5 metric ood_eval_time = 14.965219139525534\n",
      " ---- 6000 metric q_loss = 0.3231696470528841\n",
      " ---- 6000 metric hint_loss = 0.06467389342561364\n",
      " ---- 6 metric test_eval_f1 = 0.07376625904345055\n",
      " ---- 6 metric test_eval_time = 6.190454545454545\n",
      " ---- 6 metric incorrect_ood_test = 0.01681818181818182\n",
      " ---- 6 metric ood_eval = 0.6105749899477282\n",
      " ---- 6 metric ood_eval_time = 13.937474869320466\n",
      " ---- 3 metric train_eval_f1 = 0.08254783140085767\n",
      " ---- 3 metric train_eval_time = 7.787630741246021\n",
      " ---- 3 metric incorrect_ood_train = 0.09902228285584357\n",
      " ---- 7000 metric q_loss = 0.31849027828127147\n",
      " ---- 7000 metric hint_loss = 0.06326185850799083\n",
      " ---- 7 metric test_eval_f1 = 0.11677026778936606\n",
      " ---- 7 metric test_eval_time = 6.038636363636364\n",
      " ---- 7 metric incorrect_ood_test = 0.0022727272727272726\n",
      " ---- 7 metric ood_eval = 0.2064736630478488\n",
      " ---- 7 metric ood_eval_time = 10.419380780056292\n",
      " ---- 8000 metric q_loss = 0.3185800487548113\n",
      " ---- 8000 metric hint_loss = 0.062315105117857456\n",
      " ---- 8 metric test_eval_f1 = 0.15149339091455685\n",
      " ---- 8 metric test_eval_time = 12.49090909090909\n",
      " ---- 8 metric incorrect_ood_test = 0.36272727272727273\n",
      " ---- 8 metric ood_eval = 0.6779252110977081\n",
      " ---- 8 metric ood_eval_time = 14.258745476477683\n",
      " ---- 4 metric train_eval_f1 = 0.14476248555172133\n",
      " ---- 4 metric train_eval_time = 13.177580718508413\n",
      " ---- 4 metric incorrect_ood_train = 0.5284220100045475\n",
      " ---- 9000 metric q_loss = 0.3202179121375084\n",
      " ---- 9000 metric hint_loss = 0.0609717962294817\n",
      " ---- 9 metric test_eval_f1 = 0.15934329109940204\n",
      " ---- 9 metric test_eval_time = 8.653636363636364\n",
      " ---- 9 metric incorrect_ood_test = 0.018636363636363635\n",
      " ---- 9 metric ood_eval = 0.5802171290711701\n",
      " ---- 9 metric ood_eval_time = 13.480297547245678\n",
      " ---- 10000 metric q_loss = 0.316638839006424\n",
      " ---- 10000 metric hint_loss = 0.05977439283952117\n",
      " ---- 10 metric test_eval_f1 = 0.12556117009121606\n",
      " ---- 10 metric test_eval_time = 7.398181818181818\n",
      " ---- 10 metric incorrect_ood_test = 0.019090909090909092\n",
      " ---- 10 metric ood_eval = 0.5241254523522316\n",
      " ---- 10 metric ood_eval_time = 11.733815842380379\n",
      " ---- 5 metric train_eval_f1 = 0.16184258223001227\n",
      " ---- 5 metric train_eval_time = 9.332764893133243\n",
      " ---- 5 metric incorrect_ood_train = 0.11164165529786267\n",
      " ---- 11000 metric q_loss = 0.31607372798025607\n",
      " ---- 11000 metric hint_loss = 0.06070602695643902\n",
      " ---- 11 metric test_eval_f1 = 0.14997818443020436\n",
      " ---- 11 metric test_eval_time = 7.4\n",
      " ---- 11 metric incorrect_ood_test = 0.028181818181818183\n",
      " ---- 11 metric ood_eval = 0.5377965420184961\n",
      " ---- 11 metric ood_eval_time = 11.554885404101327\n",
      " ---- 12000 metric q_loss = 0.32000881059467795\n",
      " ---- 12000 metric hint_loss = 0.0598499648347497\n",
      " ---- 12 metric test_eval_f1 = 0.2139826310395203\n",
      " ---- 12 metric test_eval_time = 12.083181818181819\n",
      " ---- 12 metric incorrect_ood_test = 0.29863636363636364\n",
      " ---- 12 metric ood_eval = 0.9467229593888219\n",
      " ---- 12 metric ood_eval_time = 14.866907921190188\n",
      " ---- 6 metric train_eval_f1 = 0.17777864110612143\n",
      " ---- 6 metric train_eval_time = 12.637221464301955\n",
      " ---- 6 metric incorrect_ood_train = 0.47669395179627105\n",
      " ---- 13000 metric q_loss = 0.3162858016937971\n",
      " ---- 13000 metric hint_loss = 0.059594912748783826\n",
      " ---- 13 metric test_eval_f1 = 0.1298050864790379\n",
      " ---- 13 metric test_eval_time = 6.166363636363636\n",
      " ---- 13 metric incorrect_ood_test = 0.017727272727272727\n",
      " ---- 13 metric ood_eval = 0.3837957378367511\n",
      " ---- 13 metric ood_eval_time = 12.627663852030558\n",
      " ---- 14000 metric q_loss = 0.3188659848198295\n",
      " ---- 14000 metric hint_loss = 0.05954162149876356\n",
      " ---- 14 metric test_eval_f1 = 0.11617878870350973\n",
      " ---- 14 metric test_eval_time = 7.372727272727273\n",
      " ---- 14 metric incorrect_ood_test = 0.022727272727272728\n",
      " ---- 14 metric ood_eval = 0.8811821471652593\n",
      " ---- 14 metric ood_eval_time = 14.44270205066345\n",
      " ---- 7 metric train_eval_f1 = 0.13947383499002172\n",
      " ---- 7 metric train_eval_time = 9.412119145065938\n",
      " ---- 7 metric incorrect_ood_train = 0.15870850386539337\n",
      " ---- 15000 metric q_loss = 0.3202903653308749\n",
      " ---- 15000 metric hint_loss = 0.06045955910906196\n",
      " ---- 15 metric test_eval_f1 = 0.1990793833872268\n",
      " ---- 15 metric test_eval_time = 6.540909090909091\n",
      " ---- 15 metric incorrect_ood_test = 0.020454545454545454\n",
      " ---- 15 metric ood_eval = 0.7141133896260555\n",
      " ---- 15 metric ood_eval_time = 13.565138721351026\n",
      " ---- 16000 metric q_loss = 0.314372339181602\n",
      " ---- 16000 metric hint_loss = 0.05886859599873424\n",
      " ---- 16 metric test_eval_f1 = 0.15290325233501256\n",
      " ---- 16 metric test_eval_time = 6.316363636363636\n",
      " ---- 16 metric incorrect_ood_test = 0.020454545454545454\n",
      " ---- 16 metric ood_eval = 0.5327704061117813\n",
      " ---- 16 metric ood_eval_time = 12.10172899075191\n",
      " ---- 8 metric train_eval_f1 = 0.16556618841782988\n",
      " ---- 8 metric train_eval_time = 8.959981809913597\n",
      " ---- 8 metric incorrect_ood_train = 0.19508867667121418\n",
      " ---- 17000 metric q_loss = 0.3203132232949138\n",
      " ---- 17000 metric hint_loss = 0.05978582949191332\n",
      " ---- 17 metric test_eval_f1 = 0.20391123476216363\n",
      " ---- 17 metric test_eval_time = 6.1886363636363635\n",
      " ---- 17 metric incorrect_ood_test = 0.02\n",
      " ---- 17 metric ood_eval = 0.5860474467229594\n",
      " ---- 17 metric ood_eval_time = 11.512665862484921\n",
      " ---- 18000 metric q_loss = 0.3177287742123008\n",
      " ---- 18000 metric hint_loss = 0.05968667759001255\n",
      " ---- 18 metric test_eval_f1 = 0.16886300771903104\n",
      " ---- 18 metric test_eval_time = 6.291818181818182\n",
      " ---- 18 metric incorrect_ood_test = 0.02\n",
      " ---- 18 metric ood_eval = 0.5681544028950543\n",
      " ---- 18 metric ood_eval_time = 11.467430639324487\n",
      " ---- 9 metric train_eval_f1 = 0.195688215135766\n",
      " ---- 9 metric train_eval_time = 8.512846748522055\n",
      " ---- 9 metric incorrect_ood_train = 0.15302410186448387\n",
      " ---- 19000 metric q_loss = 0.31769153632968666\n",
      " ---- 19000 metric hint_loss = 0.05945775291323662\n",
      " ---- 19 metric test_eval_f1 = 0.20293480291808896\n",
      " ---- 19 metric test_eval_time = 6.746818181818182\n",
      " ---- 19 metric incorrect_ood_test = 0.018636363636363635\n",
      " ---- 19 metric ood_eval = 0.0973059911540008\n",
      " ---- 19 metric ood_eval_time = 8.302975472456776\n",
      " ---- 20000 metric q_loss = 0.32006767237186434\n",
      " ---- 20000 metric hint_loss = 0.06107733172550797\n",
      " ---- 20 metric test_eval_f1 = 0.26404503897982945\n",
      " ---- 20 metric test_eval_time = 10.690454545454546\n",
      " ---- 20 metric incorrect_ood_test = 0.02\n",
      " ---- 20 metric ood_eval = 0.8578608765581022\n",
      " ---- 20 metric ood_eval_time = 14.604744672295938\n",
      " ---- 10 metric train_eval_f1 = 0.27945206492535973\n",
      " ---- 10 metric train_eval_time = 11.912005457025922\n",
      " ---- 10 metric incorrect_ood_train = 0.16564347430650295\n",
      " ---- 21000 metric q_loss = 0.3095326392501593\n",
      " ---- 21000 metric hint_loss = 0.06027002462744713\n",
      " ---- 21 metric test_eval_f1 = 0.2728896530907633\n",
      " ---- 21 metric test_eval_time = 6.067727272727272\n",
      " ---- 21 metric incorrect_ood_test = 0.0018181818181818182\n",
      " ---- 21 metric ood_eval = 0.25894652191395257\n",
      " ---- 21 metric ood_eval_time = 9.121029352633695\n",
      " ---- 22000 metric q_loss = 0.32109494061768057\n",
      " ---- 22000 metric hint_loss = 0.060078257482498884\n",
      " ---- 22 metric test_eval_f1 = 0.13885529634200713\n",
      " ---- 22 metric test_eval_time = 6.101818181818182\n",
      " ---- 22 metric incorrect_ood_test = 0.004545454545454545\n",
      " ---- 22 metric ood_eval = 0.316043425814234\n",
      " ---- 22 metric ood_eval_time = 10.97004422999598\n",
      " ---- 11 metric train_eval_f1 = 0.15940415339022465\n",
      " ---- 11 metric train_eval_time = 6.610050022737608\n",
      " ---- 11 metric incorrect_ood_train = 0.015347885402455661\n",
      " ---- 23000 metric q_loss = 0.31547233060747387\n",
      " ---- 23000 metric hint_loss = 0.059182960093021396\n",
      " ---- 23 metric test_eval_f1 = 0.2511841735298895\n",
      " ---- 23 metric test_eval_time = 6.179545454545455\n",
      " ---- 23 metric incorrect_ood_test = 0.009545454545454546\n",
      " ---- 23 metric ood_eval = 0.6284680337756333\n",
      " ---- 23 metric ood_eval_time = 12.270004020908726\n",
      " ---- 24000 metric q_loss = 0.31559598878771067\n",
      " ---- 24000 metric hint_loss = 0.06075037552043796\n",
      " ---- 24 metric test_eval_f1 = 0.1843233400255001\n",
      " ---- 24 metric test_eval_time = 6.128181818181818\n",
      " ---- 24 metric incorrect_ood_test = 0.006363636363636364\n",
      " ---- 24 metric ood_eval = 0.3856051467631685\n",
      " ---- 24 metric ood_eval_time = 13.07579412947326\n",
      " ---- 12 metric train_eval_f1 = 0.1829510827982334\n",
      " ---- 12 metric train_eval_time = 6.7124829467939975\n",
      " ---- 12 metric incorrect_ood_train = 0.016712141882673944\n",
      " ---- 25000 metric q_loss = 0.31486191718280315\n",
      " ---- 25000 metric hint_loss = 0.05993616760894656\n",
      " ---- 25 metric test_eval_f1 = 0.19354743155758775\n",
      " ---- 25 metric test_eval_time = 6.2\n",
      " ---- 25 metric incorrect_ood_test = 0.013636363636363636\n",
      " ---- 25 metric ood_eval = 0.5480498592681946\n",
      " ---- 25 metric ood_eval_time = 11.975874547647768\n",
      " ---- 26000 metric q_loss = 0.3147073015868664\n",
      " ---- 26000 metric hint_loss = 0.060408542227\n",
      " ---- 26 metric test_eval_f1 = 0.21524067232824137\n",
      " ---- 26 metric test_eval_time = 6.173181818181818\n",
      " ---- 26 metric incorrect_ood_test = 0.013636363636363636\n",
      " ---- 26 metric ood_eval = 0.5086449537595497\n",
      " ---- 26 metric ood_eval_time = 11.494772818657017\n",
      " ---- 13 metric train_eval_f1 = 0.2227810017356216\n",
      " ---- 13 metric train_eval_time = 7.014097316962255\n",
      " ---- 13 metric incorrect_ood_train = 0.03342428376534789\n",
      " ---- 27000 metric q_loss = 0.315414232686162\n",
      " ---- 27000 metric hint_loss = 0.06139920600876212\n",
      " ---- 27 metric test_eval_f1 = 0.2954837144812718\n",
      " ---- 27 metric test_eval_time = 7.192272727272727\n",
      " ---- 27 metric incorrect_ood_test = 0.01681818181818182\n",
      " ---- 27 metric ood_eval = 0.5388017691998391\n",
      " ---- 27 metric ood_eval_time = 13.237233614796944\n",
      " ---- 28000 metric q_loss = 0.3164795671254396\n",
      " ---- 28000 metric hint_loss = 0.0624196306951344\n",
      " ---- 28 metric test_eval_f1 = 0.23025950587449245\n",
      " ---- 28 metric test_eval_time = 9.674545454545454\n",
      " ---- 28 metric incorrect_ood_test = 0.017272727272727273\n",
      " ---- 28 metric ood_eval = 0.5958986731001207\n",
      " ---- 28 metric ood_eval_time = 13.449135504624046\n",
      " ---- 14 metric train_eval_f1 = 0.2810941394581498\n",
      " ---- 14 metric train_eval_time = 11.102887676216461\n",
      " ---- 14 metric incorrect_ood_train = 0.07162346521145975\n",
      " ---- 29000 metric q_loss = 0.31182652893662455\n",
      " ---- 29000 metric hint_loss = 0.0614130446203053\n",
      " ---- 29 metric test_eval_f1 = 0.2185893284511815\n",
      " ---- 29 metric test_eval_time = 6.618636363636363\n",
      " ---- 29 metric incorrect_ood_test = 0.015909090909090907\n",
      " ---- 29 metric ood_eval = 0.5920788098110172\n",
      " ---- 29 metric ood_eval_time = 12.236630478488138\n",
      " ---- 30000 metric q_loss = 0.31261453975737097\n",
      " ---- 30000 metric hint_loss = 0.061152562968432904\n",
      " ---- 30 metric test_eval_f1 = 0.20653029955603977\n",
      " ---- 30 metric test_eval_time = 8.56\n",
      " ---- 30 metric incorrect_ood_test = 0.02\n",
      " ---- 30 metric ood_eval = 0.5532770406111781\n",
      " ---- 30 metric ood_eval_time = 12.531162042621633\n",
      " ---- 15 metric train_eval_f1 = 0.2526181495255589\n",
      " ---- 15 metric train_eval_time = 10.482605729877218\n",
      " ---- 15 metric incorrect_ood_train = 0.11198271941791724\n",
      " ---- 31000 metric q_loss = 0.31237517394125464\n",
      " ---- 31000 metric hint_loss = 0.062033371094614265\n",
      " ---- 31 metric test_eval_f1 = 0.2991119726778341\n",
      " ---- 31 metric test_eval_time = 7.36\n",
      " ---- 31 metric incorrect_ood_test = 0.01818181818181818\n",
      " ---- 31 metric ood_eval = 0.7511057498994773\n",
      " ---- 31 metric ood_eval_time = 14.222557297949336\n",
      " ---- 32000 metric q_loss = 0.31083658638596534\n",
      " ---- 32000 metric hint_loss = 0.06295277735218406\n",
      " ---- 32 metric test_eval_f1 = 0.28608841493567244\n",
      " ---- 32 metric test_eval_time = 6.402272727272727\n",
      " ---- 32 metric incorrect_ood_test = 0.012272727272727272\n",
      " ---- 32 metric ood_eval = 0.5983112183353438\n",
      " ---- 32 metric ood_eval_time = 13.194209891435465\n",
      " ---- 16 metric train_eval_f1 = 0.2971781530950479\n",
      " ---- 16 metric train_eval_time = 7.80593451568895\n",
      " ---- 16 metric incorrect_ood_train = 0.04536152796725784\n",
      " ---- 33000 metric q_loss = 0.31154337706416846\n",
      " ---- 33000 metric hint_loss = 0.06255854106321931\n",
      " ---- 33 metric test_eval_f1 = 0.31729037915711744\n",
      " ---- 33 metric test_eval_time = 7.041363636363636\n",
      " ---- 33 metric incorrect_ood_test = 0.011363636363636364\n",
      " ---- 33 metric ood_eval = 0.7541214314435062\n",
      " ---- 33 metric ood_eval_time = 14.634901487736228\n",
      " ---- 34000 metric q_loss = 0.3045423957258463\n",
      " ---- 34000 metric hint_loss = 0.0616641335748136\n",
      " ---- 34 metric test_eval_f1 = 0.24798548867213296\n",
      " ---- 34 metric test_eval_time = 7.718636363636364\n",
      " ---- 34 metric incorrect_ood_test = 0.011818181818181818\n",
      " ---- 34 metric ood_eval = 0.6811419380780056\n",
      " ---- 34 metric ood_eval_time = 13.056091676718939\n",
      " ---- 17 metric train_eval_f1 = 0.29572635521391283\n",
      " ---- 17 metric train_eval_time = 8.61493860845839\n",
      " ---- 17 metric incorrect_ood_train = 0.03524329240563893\n",
      " ---- 35000 metric q_loss = 0.3120067075788975\n",
      " ---- 35000 metric hint_loss = 0.062465039737522605\n",
      " ---- 35 metric test_eval_f1 = 0.31478426903215473\n",
      " ---- 35 metric test_eval_time = 6.548181818181818\n",
      " ---- 35 metric incorrect_ood_test = 0.01090909090909091\n",
      " ---- 35 metric ood_eval = 0.4746682750301568\n",
      " ---- 35 metric ood_eval_time = 11.321069561720948\n",
      " ---- 36000 metric q_loss = 0.30915467561781407\n",
      " ---- 36000 metric hint_loss = 0.06349754878133536\n",
      " ---- 36 metric test_eval_f1 = 0.2500437079393558\n",
      " ---- 36 metric test_eval_time = 6.917727272727273\n",
      " ---- 36 metric incorrect_ood_test = 0.029545454545454545\n",
      " ---- 36 metric ood_eval = 0.6592279855247286\n",
      " ---- 36 metric ood_eval_time = 13.329714515480498\n",
      " ---- 18 metric train_eval_f1 = 0.28248844081630237\n",
      " ---- 18 metric train_eval_time = 9.381195998180992\n",
      " ---- 18 metric incorrect_ood_train = 0.1009549795361528\n",
      " ---- 37000 metric q_loss = 0.31140605226159096\n",
      " ---- 37000 metric hint_loss = 0.06287480561062693\n",
      " ---- 37 metric test_eval_f1 = 0.24429924069826647\n",
      " ---- 37 metric test_eval_time = 6.493181818181818\n",
      " ---- 37 metric incorrect_ood_test = 0.01681818181818182\n",
      " ---- 37 metric ood_eval = 0.6322878970647366\n",
      " ---- 37 metric ood_eval_time = 12.466827503015681\n",
      " ---- 38000 metric q_loss = 0.3072646834105253\n",
      " ---- 38000 metric hint_loss = 0.06304978992044925\n",
      " ---- 38 metric test_eval_f1 = 0.31171498123891117\n",
      " ---- 38 metric test_eval_time = 6.699545454545454\n",
      " ---- 38 metric incorrect_ood_test = 0.017727272727272727\n",
      " ---- 38 metric ood_eval = 0.4804985926819461\n",
      " ---- 38 metric ood_eval_time = 12.572778447929233\n",
      " ---- 19 metric train_eval_f1 = 0.3053270175953305\n",
      " ---- 19 metric train_eval_time = 8.427467030468394\n",
      " ---- 19 metric incorrect_ood_train = 0.06718963165075034\n",
      " ---- 39000 metric q_loss = 0.3101271250322461\n",
      " ---- 39000 metric hint_loss = 0.06312102755904198\n",
      " ---- 39 metric test_eval_f1 = 0.2665171644662568\n",
      " ---- 39 metric test_eval_time = 6.272272727272727\n",
      " ---- 39 metric incorrect_ood_test = 0.013181818181818182\n",
      " ---- 39 metric ood_eval = 0.6833534378769602\n",
      " ---- 39 metric ood_eval_time = 13.023321270607157\n",
      " ---- 40000 metric q_loss = 0.3069318681359291\n",
      " ---- 40000 metric hint_loss = 0.062383142240345475\n",
      " ---- 40 metric test_eval_f1 = 0.30391430416054177\n",
      " ---- 40 metric test_eval_time = 6.600909090909091\n",
      " ---- 40 metric incorrect_ood_test = 0.00909090909090909\n",
      " ---- 40 metric ood_eval = 0.40952955367913146\n",
      " ---- 40 metric ood_eval_time = 11.125653397667874\n",
      " ---- 20 metric train_eval_f1 = 0.3297337393197087\n",
      " ---- 20 metric train_eval_time = 7.745566166439291\n",
      " ---- 20 metric incorrect_ood_train = 0.02307867212369259\n",
      " ---- 41000 metric q_loss = 0.3061352088749409\n",
      " ---- 41000 metric hint_loss = 0.0629077875353396\n",
      " ---- 41 metric test_eval_f1 = 0.32148241147955897\n",
      " ---- 41 metric test_eval_time = 7.370454545454545\n",
      " ---- 41 metric incorrect_ood_test = 0.015909090909090907\n",
      " ---- 41 metric ood_eval = 0.6174105347808605\n",
      " ---- 41 metric ood_eval_time = 12.147366304784882\n",
      " ---- 42000 metric q_loss = 0.30425111298263074\n",
      " ---- 42000 metric hint_loss = 0.06459680213034152\n",
      " ---- 42 metric test_eval_f1 = 0.32641911490057196\n",
      " ---- 42 metric test_eval_time = 6.454545454545454\n",
      " ---- 42 metric incorrect_ood_test = 0.015454545454545455\n",
      " ---- 42 metric ood_eval = 0.6588258946521914\n",
      " ---- 42 metric ood_eval_time = 12.61600321672698\n",
      " ---- 21 metric train_eval_f1 = 0.34307640401129597\n",
      " ---- 21 metric train_eval_time = 7.78012733060482\n",
      " ---- 21 metric incorrect_ood_train = 0.06377899045020465\n",
      " ---- 43000 metric q_loss = 0.30045311300456523\n",
      " ---- 43000 metric hint_loss = 0.06284038080647587\n",
      " ---- 43 metric test_eval_f1 = 0.4052959404050988\n",
      " ---- 43 metric test_eval_time = 7.17\n",
      " ---- 43 metric incorrect_ood_test = 0.015\n",
      " ---- 43 metric ood_eval = 0.4682348210695617\n",
      " ---- 43 metric ood_eval_time = 11.617008443908324\n",
      " ---- 44000 metric q_loss = 0.3035202616304159\n",
      " ---- 44000 metric hint_loss = 0.06474239289015532\n",
      " ---- 44 metric test_eval_f1 = 0.3367621091246313\n",
      " ---- 44 metric test_eval_time = 6.9372727272727275\n",
      " ---- 44 metric incorrect_ood_test = 0.014090909090909091\n",
      " ---- 44 metric ood_eval = 0.6648572577402493\n",
      " ---- 44 metric ood_eval_time = 12.845999195818255\n",
      " ---- 22 metric train_eval_f1 = 0.37147001638983446\n",
      " ---- 22 metric train_eval_time = 7.871077762619373\n",
      " ---- 22 metric incorrect_ood_train = 0.029445202364711234\n",
      " ---- 45000 metric q_loss = 0.2987250580713153\n",
      " ---- 45000 metric hint_loss = 0.06429037307947874\n",
      " ---- 45 metric test_eval_f1 = 0.47223818726794203\n",
      " ---- 45 metric test_eval_time = 6.996363636363636\n",
      " ---- 45 metric incorrect_ood_test = 0.011818181818181818\n",
      " ---- 45 metric ood_eval = 0.725774024929634\n",
      " ---- 45 metric ood_eval_time = 13.216726980297548\n",
      " ---- 46000 metric q_loss = 0.2987986767962575\n",
      " ---- 46000 metric hint_loss = 0.06320190892741084\n",
      " ---- 46 metric test_eval_f1 = 0.4679499821397496\n",
      " ---- 46 metric test_eval_time = 6.759545454545455\n",
      " ---- 46 metric incorrect_ood_test = 0.009545454545454546\n",
      " ---- 46 metric ood_eval = 0.6304784881383193\n",
      " ---- 46 metric ood_eval_time = 13.413550462404503\n",
      " ---- 23 metric train_eval_f1 = 0.38622850212706\n",
      " ---- 23 metric train_eval_time = 7.494770350159163\n",
      " ---- 23 metric incorrect_ood_train = 0.024897680763983628\n",
      " ---- 47000 metric q_loss = 0.29268353248387574\n",
      " ---- 47000 metric hint_loss = 0.06364636368677021\n",
      " ---- 47 metric test_eval_f1 = 0.40328703034483554\n",
      " ---- 47 metric test_eval_time = 7.266818181818182\n",
      " ---- 47 metric incorrect_ood_test = 0.007272727272727273\n",
      " ---- 47 metric ood_eval = 0.46783273019702454\n",
      " ---- 47 metric ood_eval_time = 11.450140731805387\n",
      " ---- 48000 metric q_loss = 0.29932083033770324\n",
      " ---- 48000 metric hint_loss = 0.0633041155450046\n",
      " ---- 48 metric test_eval_f1 = 0.4558540868939383\n",
      " ---- 48 metric test_eval_time = 8.333181818181819\n",
      " ---- 48 metric incorrect_ood_test = 0.01\n",
      " ---- 48 metric ood_eval = 0.7092882991556092\n",
      " ---- 48 metric ood_eval_time = 13.74065138721351\n",
      " ---- 24 metric train_eval_f1 = 0.4541405877311939\n",
      " ---- 24 metric train_eval_time = 9.48738062755798\n",
      " ---- 24 metric incorrect_ood_train = 0.020009095043201454\n",
      " ---- 49000 metric q_loss = 0.2989218918159604\n",
      " ---- 49000 metric hint_loss = 0.06408430562540889\n",
      " ---- 49 metric test_eval_f1 = 0.4473061907363613\n",
      " ---- 49 metric test_eval_time = 7.713636363636364\n",
      " ---- 49 metric incorrect_ood_test = 0.014090909090909091\n",
      " ---- 49 metric ood_eval = 0.6548049859268195\n",
      " ---- 49 metric ood_eval_time = 13.121230398069963\n",
      " ---- 50000 metric q_loss = 0.295659554079175\n",
      " ---- 50000 metric hint_loss = 0.06355109223350883\n",
      " ---- 50 metric test_eval_f1 = 0.45343864432723197\n",
      " ---- 50 metric test_eval_time = 8.007272727272728\n",
      " ---- 50 metric incorrect_ood_test = 0.014545454545454545\n",
      " ---- 50 metric ood_eval = 0.7314032971451548\n",
      " ---- 50 metric ood_eval_time = 13.764776839565743\n",
      " ---- 25 metric train_eval_f1 = 0.4328984166863663\n",
      " ---- 25 metric train_eval_time = 10.243406093678946\n",
      " ---- 25 metric incorrect_ood_train = 0.05343337880854934\n",
      " ---- 51000 metric q_loss = 0.2972719351947308\n",
      " ---- 51000 metric hint_loss = 0.06485270594805478\n",
      " ---- 51 metric test_eval_f1 = 0.48320162264706706\n",
      " ---- 51 metric test_eval_time = 7.45\n",
      " ---- 51 metric incorrect_ood_test = 0.010454545454545454\n",
      " ---- 51 metric ood_eval = 0.76075593084037\n",
      " ---- 51 metric ood_eval_time = 13.656011258544432\n",
      " ---- 52000 metric q_loss = 0.295577649012208\n",
      " ---- 52000 metric hint_loss = 0.06402184322848917\n",
      " ---- 52 metric test_eval_f1 = 0.49301940109001535\n",
      " ---- 52 metric test_eval_time = 7.315454545454545\n",
      " ---- 52 metric incorrect_ood_test = 0.006818181818181818\n",
      " ---- 52 metric ood_eval = 0.7967430639324488\n",
      " ---- 52 metric ood_eval_time = 13.526940088459991\n",
      " ---- 26 metric train_eval_f1 = 0.4362673296911762\n",
      " ---- 26 metric train_eval_time = 8.311277853569804\n",
      " ---- 26 metric incorrect_ood_train = 0.02671668940427467\n",
      " ---- 53000 metric q_loss = 0.2965652691870928\n",
      " ---- 53000 metric hint_loss = 0.0646622362099588\n",
      " ---- 53 metric test_eval_f1 = 0.37384122794001146\n",
      " ---- 53 metric test_eval_time = 7.071818181818182\n",
      " ---- 53 metric incorrect_ood_test = 0.00909090909090909\n",
      " ---- 53 metric ood_eval = 0.6375150784077201\n",
      " ---- 53 metric ood_eval_time = 12.951347004422999\n",
      " ---- 54000 metric q_loss = 0.29442700592428445\n",
      " ---- 54000 metric hint_loss = 0.0637778186649084\n",
      " ---- 54 metric test_eval_f1 = 0.5333898141674177\n",
      " ---- 54 metric test_eval_time = 7.504545454545455\n",
      " ---- 54 metric incorrect_ood_test = 0.008636363636363636\n",
      " ---- 54 metric ood_eval = 0.6646562123039808\n",
      " ---- 54 metric ood_eval_time = 12.732408524326498\n",
      " ---- 27 metric train_eval_f1 = 0.48045143480997987\n",
      " ---- 27 metric train_eval_time = 8.590268303774442\n",
      " ---- 27 metric incorrect_ood_train = 0.021259663483401546\n",
      " ---- 55000 metric q_loss = 0.2918984712511301\n",
      " ---- 55000 metric hint_loss = 0.06545531592145562\n",
      " ---- 55 metric test_eval_f1 = 0.5598422380292395\n",
      " ---- 55 metric test_eval_time = 8.114090909090908\n",
      " ---- 55 metric incorrect_ood_test = 0.007272727272727273\n",
      " ---- 55 metric ood_eval = 0.6399276236429433\n",
      " ---- 55 metric ood_eval_time = 12.2880981101729\n",
      " ---- 56000 metric q_loss = 0.2914096076488495\n",
      " ---- 56000 metric hint_loss = 0.06424653478339315\n",
      " ---- 56 metric test_eval_f1 = 0.512640822404663\n",
      " ---- 56 metric test_eval_time = 7.309545454545455\n",
      " ---- 56 metric incorrect_ood_test = 0.005909090909090909\n",
      " ---- 56 metric ood_eval = 0.5914756735022115\n",
      " ---- 56 metric ood_eval_time = 12.719340570969038\n",
      " ---- 28 metric train_eval_f1 = 0.48214424791472044\n",
      " ---- 28 metric train_eval_time = 8.021828103683493\n",
      " ---- 28 metric incorrect_ood_train = 0.01296043656207367\n",
      " ---- 57000 metric q_loss = 0.2972780821621418\n",
      " ---- 57000 metric hint_loss = 0.06531345232948661\n",
      " ---- 57 metric test_eval_f1 = 0.4285882503654764\n",
      " ---- 57 metric test_eval_time = 7.054090909090909\n",
      " ---- 57 metric incorrect_ood_test = 0.005454545454545455\n",
      " ---- 57 metric ood_eval = 0.5741857659831122\n",
      " ---- 57 metric ood_eval_time = 13.270607157217531\n",
      " ---- 58000 metric q_loss = 0.29366789797693493\n",
      " ---- 58000 metric hint_loss = 0.06437072847783566\n",
      " ---- 58 metric test_eval_f1 = 0.5180845557853843\n",
      " ---- 58 metric test_eval_time = 7.257727272727273\n",
      " ---- 58 metric incorrect_ood_test = 0.004545454545454545\n",
      " ---- 58 metric ood_eval = 0.7042621632488942\n",
      " ---- 58 metric ood_eval_time = 13.604744672295938\n",
      " ---- 29 metric train_eval_f1 = 0.4612185036744847\n",
      " ---- 29 metric train_eval_time = 7.804797635288768\n",
      " ---- 29 metric incorrect_ood_train = 0.009322419281491587\n",
      " ---- 59000 metric q_loss = 0.2870948563888669\n",
      " ---- 59000 metric hint_loss = 0.06453090634942055\n",
      " ---- 59 metric test_eval_f1 = 0.48066560804807607\n",
      " ---- 59 metric test_eval_time = 8.467727272727272\n",
      " ---- 59 metric incorrect_ood_test = 0.01\n",
      " ---- 59 metric ood_eval = 0.7468837957378367\n",
      " ---- 59 metric ood_eval_time = 13.929232006433454\n",
      " ---- 60000 metric q_loss = 0.29079936412721874\n",
      " ---- 60000 metric hint_loss = 0.0660155338048935\n",
      " ---- 60 metric test_eval_f1 = 0.5168108995557484\n",
      " ---- 60 metric test_eval_time = 7.382272727272727\n",
      " ---- 60 metric incorrect_ood_test = 0.006363636363636364\n",
      " ---- 60 metric ood_eval = 0.5954965822275834\n",
      " ---- 60 metric ood_eval_time = 12.066344993968636\n",
      " ---- 30 metric train_eval_f1 = 0.4650105392388223\n",
      " ---- 30 metric train_eval_time = 8.123578899499773\n",
      " ---- 30 metric incorrect_ood_train = 0.014893133242382901\n",
      " ---- 61000 metric q_loss = 0.29274871037900446\n",
      " ---- 61000 metric hint_loss = 0.06583692173287273\n",
      " ---- 61 metric test_eval_f1 = 0.438373220078061\n",
      " ---- 61 metric test_eval_time = 7.577272727272727\n",
      " ---- 61 metric incorrect_ood_test = 0.006818181818181818\n",
      " ---- 61 metric ood_eval = 0.5948934459187777\n",
      " ---- 61 metric ood_eval_time = 13.736630478488138\n",
      " ---- 62000 metric q_loss = 0.29449422362446787\n",
      " ---- 62000 metric hint_loss = 0.06476946746557952\n",
      " ---- 62 metric test_eval_f1 = 0.4569261621855068\n",
      " ---- 62 metric test_eval_time = 7.578636363636364\n",
      " ---- 62 metric incorrect_ood_test = 0.007727272727272728\n",
      " ---- 62 metric ood_eval = 0.6606353035786088\n",
      " ---- 62 metric ood_eval_time = 12.734016887816647\n",
      " ---- 31 metric train_eval_f1 = 0.44754717152681833\n",
      " ---- 31 metric train_eval_time = 8.7449977262392\n",
      " ---- 31 metric incorrect_ood_train = 0.020122783083219645\n",
      " ---- 63000 metric q_loss = 0.28918612606078387\n",
      " ---- 63000 metric hint_loss = 0.06690219985693693\n",
      " ---- 63 metric test_eval_f1 = 0.4777447602489009\n",
      " ---- 63 metric test_eval_time = 7.330909090909091\n",
      " ---- 63 metric incorrect_ood_test = 0.00909090909090909\n",
      " ---- 63 metric ood_eval = 0.6819461198230801\n",
      " ---- 63 metric ood_eval_time = 12.62324085243265\n",
      " ---- 64000 metric q_loss = 0.287223481439054\n",
      " ---- 64000 metric hint_loss = 0.06734771214798092\n",
      " ---- 64 metric test_eval_f1 = 0.5566227160981879\n",
      " ---- 64 metric test_eval_time = 7.14\n",
      " ---- 64 metric incorrect_ood_test = 0.004545454545454545\n",
      " ---- 64 metric ood_eval = 0.5388017691998391\n",
      " ---- 64 metric ood_eval_time = 11.881785283474064\n",
      " ---- 32 metric train_eval_f1 = 0.4940190064404007\n",
      " ---- 32 metric train_eval_time = 7.658594815825375\n",
      " ---- 32 metric incorrect_ood_train = 0.01227830832196453\n",
      " ---- 65000 metric q_loss = 0.2866986172348261\n",
      " ---- 65000 metric hint_loss = 0.06665767363086343\n",
      " ---- 65 metric test_eval_f1 = 0.5058551725597168\n",
      " ---- 65 metric test_eval_time = 7.67\n",
      " ---- 65 metric incorrect_ood_test = 0.005\n",
      " ---- 65 metric ood_eval = 0.612183353437877\n",
      " ---- 65 metric ood_eval_time = 14.01286690792119\n",
      " ---- 66000 metric q_loss = 0.2888131762966514\n",
      " ---- 66000 metric hint_loss = 0.06673762595281005\n",
      " ---- 66 metric test_eval_f1 = 0.5114312356248228\n",
      " ---- 66 metric test_eval_time = 6.885454545454546\n",
      " ---- 66 metric incorrect_ood_test = 0.005909090909090909\n",
      " ---- 66 metric ood_eval = 0.6375150784077201\n",
      " ---- 66 metric ood_eval_time = 12.753116204262163\n",
      " ---- 33 metric train_eval_f1 = 0.4649255156670675\n",
      " ---- 33 metric train_eval_time = 7.406548431105048\n",
      " ---- 33 metric incorrect_ood_train = 0.011709868121873579\n",
      " ---- 67000 metric q_loss = 0.2876927393674851\n",
      " ---- 67000 metric hint_loss = 0.06760156569257379\n",
      " ---- 67 metric test_eval_f1 = 0.4850029117031349\n",
      " ---- 67 metric test_eval_time = 7.03\n",
      " ---- 67 metric incorrect_ood_test = 0.006363636363636364\n",
      " ---- 67 metric ood_eval = 0.5321672698029755\n",
      " ---- 67 metric ood_eval_time = 11.832931242460797\n",
      " ---- 68000 metric q_loss = 0.28431093503534793\n",
      " ---- 68000 metric hint_loss = 0.06555364758893847\n",
      " ---- 68 metric test_eval_f1 = 0.5820231178931837\n",
      " ---- 68 metric test_eval_time = 7.275909090909091\n",
      " ---- 68 metric incorrect_ood_test = 0.007272727272727273\n",
      " ---- 68 metric ood_eval = 0.5780056292722155\n",
      " ---- 68 metric ood_eval_time = 12.417571371129876\n",
      " ---- 34 metric train_eval_f1 = 0.527831370386885\n",
      " ---- 34 metric train_eval_time = 7.926557526148249\n",
      " ---- 34 metric incorrect_ood_train = 0.017849022282855842\n",
      " ---- 69000 metric q_loss = 0.2876677880436182\n",
      " ---- 69000 metric hint_loss = 0.06895211715251208\n",
      " ---- 69 metric test_eval_f1 = 0.4811383893927625\n",
      " ---- 69 metric test_eval_time = 7.381818181818182\n",
      " ---- 69 metric incorrect_ood_test = 0.006363636363636364\n",
      " ---- 69 metric ood_eval = 0.5954965822275834\n",
      " ---- 69 metric ood_eval_time = 13.65319662243667\n",
      " ---- 70000 metric q_loss = 0.28401369718462227\n",
      " ---- 70000 metric hint_loss = 0.0688396849744022\n",
      " ---- 70 metric test_eval_f1 = 0.5611903489255643\n",
      " ---- 70 metric test_eval_time = 7.000909090909091\n",
      " ---- 70 metric incorrect_ood_test = 0.006363636363636364\n",
      " ---- 70 metric ood_eval = 0.5152794531564133\n",
      " ---- 70 metric ood_eval_time = 12.530960997185364\n",
      " ---- 35 metric train_eval_f1 = 0.505401476131568\n",
      " ---- 35 metric train_eval_time = 7.835379718053661\n",
      " ---- 35 metric incorrect_ood_train = 0.008867667121418827\n",
      " ---- 71000 metric q_loss = 0.2824997972100973\n",
      " ---- 71000 metric hint_loss = 0.06782326612994075\n",
      " ---- 71 metric test_eval_f1 = 0.5196088720670955\n",
      " ---- 71 metric test_eval_time = 7.543181818181818\n",
      " ---- 71 metric incorrect_ood_test = 0.006363636363636364\n",
      " ---- 71 metric ood_eval = 0.5788098110172899\n",
      " ---- 71 metric ood_eval_time = 12.766988339364696\n",
      " ---- 72000 metric q_loss = 0.28742978256195784\n",
      " ---- 72000 metric hint_loss = 0.06811882340535522\n",
      " ---- 72 metric test_eval_f1 = 0.5979984759413398\n",
      " ---- 72 metric test_eval_time = 7.6459090909090905\n",
      " ---- 72 metric incorrect_ood_test = 0.007272727272727273\n",
      " ---- 72 metric ood_eval = 0.4489344591877764\n",
      " ---- 72 metric ood_eval_time = 12.164656212303981\n",
      " ---- 36 metric train_eval_f1 = 0.5337317695327412\n",
      " ---- 36 metric train_eval_time = 8.721691678035471\n",
      " ---- 36 metric incorrect_ood_train = 0.015347885402455661\n",
      " ---- 73000 metric q_loss = 0.28451033306866885\n",
      " ---- 73000 metric hint_loss = 0.06978209371119738\n",
      " ---- 73 metric test_eval_f1 = 0.4780132436604092\n",
      " ---- 73 metric test_eval_time = 7.005\n",
      " ---- 73 metric incorrect_ood_test = 0.005909090909090909\n",
      " ---- 73 metric ood_eval = 0.4694410936871733\n",
      " ---- 73 metric ood_eval_time = 12.18898271009248\n",
      " ---- 74000 metric q_loss = 0.28866920986026523\n",
      " ---- 74000 metric hint_loss = 0.0716593759842217\n",
      " ---- 74 metric test_eval_f1 = 0.5395115365415477\n",
      " ---- 74 metric test_eval_time = 7.533636363636363\n",
      " ---- 74 metric incorrect_ood_test = 0.006818181818181818\n",
      " ---- 74 metric ood_eval = 0.630076397265782\n",
      " ---- 74 metric ood_eval_time = 12.475874547647768\n",
      " ---- 37 metric train_eval_f1 = 0.5116478767906931\n",
      " ---- 37 metric train_eval_time = 8.856412005457026\n",
      " ---- 37 metric incorrect_ood_train = 0.023419736243747158\n",
      " ---- 75000 metric q_loss = 0.2855551333129406\n",
      " ---- 75000 metric hint_loss = 0.06958889807015657\n",
      " ---- 75 metric test_eval_f1 = 0.5283004399445331\n",
      " ---- 75 metric test_eval_time = 7.626363636363636\n",
      " ---- 75 metric incorrect_ood_test = 0.007272727272727273\n",
      " ---- 75 metric ood_eval = 0.656011258544431\n",
      " ---- 75 metric ood_eval_time = 12.768596702854845\n",
      " ---- 76000 metric q_loss = 0.2854895811825991\n",
      " ---- 76000 metric hint_loss = 0.07207753168791532\n",
      " ---- 76 metric test_eval_f1 = 0.4918756457191323\n",
      " ---- 76 metric test_eval_time = 7.155\n",
      " ---- 76 metric incorrect_ood_test = 0.006818181818181818\n",
      " ---- 76 metric ood_eval = 0.6264575794129473\n",
      " ---- 76 metric ood_eval_time = 13.924809006835545\n",
      " ---- 38 metric train_eval_f1 = 0.48459797596041077\n",
      " ---- 38 metric train_eval_time = 8.085948158253752\n",
      " ---- 38 metric incorrect_ood_train = 0.01637107776261937\n",
      " ---- 77000 metric q_loss = 0.28527552691102026\n",
      " ---- 77000 metric hint_loss = 0.06976876705512404\n",
      " ---- 77 metric test_eval_f1 = 0.5774792309193905\n",
      " ---- 77 metric test_eval_time = 6.995454545454545\n",
      " ---- 77 metric incorrect_ood_test = 0.006818181818181818\n",
      " ---- 77 metric ood_eval = 0.617611580217129\n",
      " ---- 77 metric ood_eval_time = 13.123843988741456\n",
      " ---- 78000 metric q_loss = 0.2832630345672369\n",
      " ---- 78000 metric hint_loss = 0.06887030404806137\n",
      " ---- 78 metric test_eval_f1 = 0.5805987573368528\n",
      " ---- 78 metric test_eval_time = 7.647272727272727\n",
      " ---- 78 metric incorrect_ood_test = 0.005454545454545455\n",
      " ---- 78 metric ood_eval = 0.39947728186570164\n",
      " ---- 78 metric ood_eval_time = 12.122637716123844\n",
      " ---- 39 metric train_eval_f1 = 0.5548896065942411\n",
      " ---- 39 metric train_eval_time = 8.770463847203274\n",
      " ---- 39 metric incorrect_ood_train = 0.010118235561618918\n",
      " ---- 79000 metric q_loss = 0.280160695925355\n",
      " ---- 79000 metric hint_loss = 0.07127390537038446\n",
      " ---- 79 metric test_eval_f1 = 0.5955382205248005\n",
      " ---- 79 metric test_eval_time = 8.22409090909091\n",
      " ---- 79 metric incorrect_ood_test = 0.00909090909090909\n",
      " ---- 79 metric ood_eval = 0.6258544431041415\n",
      " ---- 79 metric ood_eval_time = 12.666465621230397\n",
      " ---- 80000 metric q_loss = 0.28215913704782725\n",
      " ---- 80000 metric hint_loss = 0.07082259389385581\n",
      " ---- 80 metric test_eval_f1 = 0.6221336017879566\n",
      " ---- 80 metric test_eval_time = 11.071363636363637\n",
      " ---- 80 metric incorrect_ood_test = 0.01\n",
      " ---- 80 metric ood_eval = 0.5683554483313229\n",
      " ---- 80 metric ood_eval_time = 13.896059509449136\n",
      " ---- 40 metric train_eval_f1 = 0.556152580865677\n",
      " ---- 40 metric train_eval_time = 11.421896316507503\n",
      " ---- 40 metric incorrect_ood_train = 0.0241018644838563\n",
      " ---- 81000 metric q_loss = 0.2860854914411902\n",
      " ---- 81000 metric hint_loss = 0.07273242705315351\n",
      " ---- 81 metric test_eval_f1 = 0.6844870379602708\n",
      " ---- 81 metric test_eval_time = 10.976818181818182\n",
      " ---- 81 metric incorrect_ood_test = 0.010454545454545454\n",
      " ---- 81 metric ood_eval = 0.6873743466023321\n",
      " ---- 81 metric ood_eval_time = 13.97406513872135\n",
      " ---- 82000 metric q_loss = 0.28169703301787374\n",
      " ---- 82000 metric hint_loss = 0.07128130138292908\n",
      " ---- 82 metric test_eval_f1 = 0.6566244472934236\n",
      " ---- 82 metric test_eval_time = 7.965\n",
      " ---- 82 metric incorrect_ood_test = 0.005909090909090909\n",
      " ---- 82 metric ood_eval = 0.5810213108162444\n",
      " ---- 82 metric ood_eval_time = 12.285484519501408\n",
      " ---- 41 metric train_eval_f1 = 0.5914890046239681\n",
      " ---- 41 metric train_eval_time = 9.141086857662573\n",
      " ---- 41 metric incorrect_ood_train = 0.01205093224192815\n",
      " ---- 83000 metric q_loss = 0.28405852122604847\n",
      " ---- 83000 metric hint_loss = 0.07557029469311237\n",
      " ---- 83 metric test_eval_f1 = 0.7026219285194477\n",
      " ---- 83 metric test_eval_time = 8.64\n",
      " ---- 83 metric incorrect_ood_test = 0.008636363636363636\n",
      " ---- 83 metric ood_eval = 0.7187374346602332\n",
      " ---- 83 metric ood_eval_time = 14.202854845195015\n",
      " ---- 84000 metric q_loss = 0.28406213464587926\n",
      " ---- 84000 metric hint_loss = 0.07593032195791602\n",
      " ---- 84 metric test_eval_f1 = 0.7551027902536392\n",
      " ---- 84 metric test_eval_time = 11.539090909090909\n",
      " ---- 84 metric incorrect_ood_test = 0.011818181818181818\n",
      " ---- 84 metric ood_eval = 0.8029754724567753\n",
      " ---- 84 metric ood_eval_time = 14.72657820667471\n",
      " ---- 42 metric train_eval_f1 = 0.6350976097786677\n",
      " ---- 42 metric train_eval_time = 12.197930877671668\n",
      " ---- 42 metric incorrect_ood_train = 0.018076398362892224\n",
      " ---- 85000 metric q_loss = 0.2843472660034895\n",
      " ---- 85000 metric hint_loss = 0.07930430092290044\n",
      " ---- 85 metric test_eval_f1 = 0.6146772662815546\n",
      " ---- 85 metric test_eval_time = 10.632272727272728\n",
      " ---- 85 metric incorrect_ood_test = 0.013636363636363636\n",
      " ---- 85 metric ood_eval = 0.7726176115802171\n",
      " ---- 85 metric ood_eval_time = 14.502010454362686\n",
      " ---- 86000 metric q_loss = 0.283874914675951\n",
      " ---- 86000 metric hint_loss = 0.07748985751345754\n",
      " ---- 86 metric test_eval_f1 = 0.7300098407499559\n",
      " ---- 86 metric test_eval_time = 12.999545454545455\n",
      " ---- 86 metric incorrect_ood_test = 0.018636363636363635\n",
      " ---- 86 metric ood_eval = 0.984519501407318\n",
      " ---- 86 metric ood_eval_time = 14.980699638118216\n",
      " ---- 43 metric train_eval_f1 = 0.6341872724976192\n",
      " ---- 43 metric train_eval_time = 13.430991359708958\n",
      " ---- 43 metric incorrect_ood_train = 0.059458844929513414\n",
      " ---- 87000 metric q_loss = 0.2828235050663352\n",
      " ---- 87000 metric hint_loss = 0.07858135858178139\n",
      " ---- 87 metric test_eval_f1 = 0.6595568222446181\n",
      " ---- 87 metric test_eval_time = 11.558636363636364\n",
      " ---- 87 metric incorrect_ood_test = 0.012272727272727272\n",
      " ---- 87 metric ood_eval = 0.6877764374748693\n",
      " ---- 87 metric ood_eval_time = 14.665259348612787\n",
      " ---- 88000 metric q_loss = 0.2820399780422449\n",
      " ---- 88000 metric hint_loss = 0.07724345309659839\n",
      " ---- 88 metric test_eval_f1 = 0.7550729318770585\n",
      " ---- 88 metric test_eval_time = 11.80409090909091\n",
      " ---- 88 metric incorrect_ood_test = 0.00909090909090909\n",
      " ---- 88 metric ood_eval = 0.9585846401286691\n",
      " ---- 88 metric ood_eval_time = 14.809006835544833\n",
      " ---- 44 metric train_eval_f1 = 0.6590127547103414\n",
      " ---- 44 metric train_eval_time = 12.297862664847658\n",
      " ---- 44 metric incorrect_ood_train = 0.024783992723965437\n",
      " ---- 89000 metric q_loss = 0.27611912859231236\n",
      " ---- 89000 metric hint_loss = 0.0743274608105421\n",
      " ---- 89 metric test_eval_f1 = 0.6720918889229032\n",
      " ---- 89 metric test_eval_time = 10.457272727272727\n",
      " ---- 89 metric incorrect_ood_test = 0.01090909090909091\n",
      " ---- 89 metric ood_eval = 0.6726980297547246\n",
      " ---- 89 metric ood_eval_time = 14.093285082428629\n",
      " ---- 90000 metric q_loss = 0.28237692441046236\n",
      " ---- 90000 metric hint_loss = 0.07896560560539365\n",
      " ---- 90 metric test_eval_f1 = 0.7123131157116268\n",
      " ---- 90 metric test_eval_time = 12.177272727272728\n",
      " ---- 90 metric incorrect_ood_test = 0.013636363636363636\n",
      " ---- 90 metric ood_eval = 0.8663047848813832\n",
      " ---- 90 metric ood_eval_time = 14.847406513872135\n",
      " ---- 45 metric train_eval_f1 = 0.6342488721890911\n",
      " ---- 45 metric train_eval_time = 12.700545702592088\n",
      " ---- 45 metric incorrect_ood_train = 0.04456571168713051\n",
      " ---- 91000 metric q_loss = 0.2783520360067487\n",
      " ---- 91000 metric hint_loss = 0.07734027643129229\n",
      " ---- 91 metric test_eval_f1 = 0.7192497902280691\n",
      " ---- 91 metric test_eval_time = 10.732272727272727\n",
      " ---- 91 metric incorrect_ood_test = 0.006818181818181818\n",
      " ---- 91 metric ood_eval = 0.6367108966626458\n",
      " ---- 91 metric ood_eval_time = 14.458785685564937\n",
      " ---- 92000 metric q_loss = 0.2752214368656278\n",
      " ---- 92000 metric hint_loss = 0.07705504111200571\n",
      " ---- 92 metric test_eval_f1 = 0.7366689886536174\n",
      " ---- 92 metric test_eval_time = 11.772727272727273\n",
      " ---- 92 metric incorrect_ood_test = 0.011363636363636364\n",
      " ---- 92 metric ood_eval = 0.8226779252110977\n",
      " ---- 92 metric ood_eval_time = 14.566948130277442\n",
      " ---- 46 metric train_eval_f1 = 0.6568934167995482\n",
      " ---- 46 metric train_eval_time = 12.296157344247385\n",
      " ---- 46 metric incorrect_ood_train = 0.021145975443383355\n",
      " ---- 93000 metric q_loss = 0.27927449211478234\n",
      " ---- 93000 metric hint_loss = 0.08075937917083502\n",
      " ---- 93 metric test_eval_f1 = 0.7622065619554377\n",
      " ---- 93 metric test_eval_time = 11.322727272727272\n",
      " ---- 93 metric incorrect_ood_test = 0.013181818181818182\n",
      " ---- 93 metric ood_eval = 0.773220747889023\n",
      " ---- 93 metric ood_eval_time = 14.749899477281867\n",
      " ---- 94000 metric q_loss = 0.2779453895688057\n",
      " ---- 94000 metric hint_loss = 0.08247532916441559\n",
      " ---- 94 metric test_eval_f1 = 0.7325779151226953\n",
      " ---- 94 metric test_eval_time = 11.428181818181818\n",
      " ---- 94 metric incorrect_ood_test = 0.011818181818181818\n",
      " ---- 94 metric ood_eval = 0.7438681141938078\n",
      " ---- 94 metric ood_eval_time = 14.620024125452352\n",
      " ---- 47 metric train_eval_f1 = 0.6541544324189364\n",
      " ---- 47 metric train_eval_time = 12.063210550250114\n",
      " ---- 47 metric incorrect_ood_train = 0.024897680763983628\n",
      " ---- 95000 metric q_loss = 0.2788315867483616\n",
      " ---- 95000 metric hint_loss = 0.08119188221916557\n",
      " ---- 95 metric test_eval_f1 = 0.7337907453231032\n",
      " ---- 95 metric test_eval_time = 9.04\n",
      " ---- 95 metric incorrect_ood_test = 0.006363636363636364\n",
      " ---- 95 metric ood_eval = 0.7046642541214314\n",
      " ---- 95 metric ood_eval_time = 13.953960595094491\n",
      " ---- 96000 metric q_loss = 0.2804539685547352\n",
      " ---- 96000 metric hint_loss = 0.08306077291071415\n",
      " ---- 96 metric test_eval_f1 = 0.7408865066788942\n",
      " ---- 96 metric test_eval_time = 12.165\n",
      " ---- 96 metric incorrect_ood_test = 0.014090909090909091\n",
      " ---- 96 metric ood_eval = 0.7790510655408123\n",
      " ---- 96 metric ood_eval_time = 14.865299557700041\n",
      " ---- 48 metric train_eval_f1 = 0.6766614763017792\n",
      " ---- 48 metric train_eval_time = 12.68781264211005\n",
      " ---- 48 metric incorrect_ood_train = 0.04308776716689404\n",
      " ---- 97000 metric q_loss = 0.2741041135787964\n",
      " ---- 97000 metric hint_loss = 0.07550463049486279\n",
      " ---- 97 metric test_eval_f1 = 0.7374776879611812\n",
      " ---- 97 metric test_eval_time = 10.187272727272727\n",
      " ---- 97 metric incorrect_ood_test = 0.008636363636363636\n",
      " ---- 97 metric ood_eval = 0.8126256533976679\n",
      " ---- 97 metric ood_eval_time = 14.344792923200643\n",
      " ---- 98000 metric q_loss = 0.2707605491429567\n",
      " ---- 98000 metric hint_loss = 0.07797526537254452\n",
      " ---- 98 metric test_eval_f1 = 0.6704410256464384\n",
      " ---- 98 metric test_eval_time = 9.05\n",
      " ---- 98 metric incorrect_ood_test = 0.005909090909090909\n",
      " ---- 98 metric ood_eval = 0.7531162042621633\n",
      " ---- 98 metric ood_eval_time = 14.321873743466023\n",
      " ---- 49 metric train_eval_f1 = 0.6465956503259137\n",
      " ---- 49 metric train_eval_time = 10.111755343337881\n",
      " ---- 49 metric incorrect_ood_train = 0.010686675761709868\n",
      " ---- 99000 metric q_loss = 0.27180803058296443\n",
      " ---- 99000 metric hint_loss = 0.07626422566175461\n",
      " ---- 99 metric test_eval_f1 = 0.6613353788470501\n",
      " ---- 99 metric test_eval_time = 9.161818181818182\n",
      " ---- 99 metric incorrect_ood_test = 0.01\n",
      " ---- 99 metric ood_eval = 0.6974266184157619\n",
      " ---- 99 metric ood_eval_time = 14.188178528347407\n",
      " ---- 100000 metric q_loss = 0.2729221987724304\n",
      " ---- 100000 metric hint_loss = 0.08002350485324859\n",
      " ---- 100 metric test_eval_f1 = 0.7197882337892928\n",
      " ---- 100 metric test_eval_time = 10.595454545454546\n",
      " ---- 100 metric incorrect_ood_test = 0.008636363636363636\n",
      " ---- 100 metric ood_eval = 0.7643747486932047\n",
      " ---- 100 metric ood_eval_time = 14.68777643747487\n",
      " ---- 50 metric train_eval_f1 = 0.6587085886852083\n",
      " ---- 50 metric train_eval_time = 11.231014097316962\n",
      " ---- 50 metric incorrect_ood_train = 0.01625738972260118\n",
      " ---- 101000 metric q_loss = 0.2731059219315648\n",
      " ---- 101000 metric hint_loss = 0.0822127233222127\n",
      " ---- 101 metric test_eval_f1 = 0.6569964064514493\n",
      " ---- 101 metric test_eval_time = 8.306818181818182\n",
      " ---- 101 metric incorrect_ood_test = 0.00909090909090909\n",
      " ---- 101 metric ood_eval = 0.7175311620426217\n",
      " ---- 101 metric ood_eval_time = 13.994772818657017\n",
      " ---- 102000 metric q_loss = 0.27187662483751773\n",
      " ---- 102000 metric hint_loss = 0.07780346274748444\n",
      " ---- 102 metric test_eval_f1 = 0.702865825664892\n",
      " ---- 102 metric test_eval_time = 8.41090909090909\n",
      " ---- 102 metric incorrect_ood_test = 0.00909090909090909\n",
      " ---- 102 metric ood_eval = 0.8361479694410937\n",
      " ---- 102 metric ood_eval_time = 14.623039806996381\n",
      " ---- 51 metric train_eval_f1 = 0.6482781046363552\n",
      " ---- 51 metric train_eval_time = 9.677694406548431\n",
      " ---- 51 metric incorrect_ood_train = 0.017280582082764895\n",
      " ---- 103000 metric q_loss = 0.27211372628062963\n",
      " ---- 103000 metric hint_loss = 0.07857387190684677\n",
      " ---- 103 metric test_eval_f1 = 0.6606685266226996\n",
      " ---- 103 metric test_eval_time = 8.90090909090909\n",
      " ---- 103 metric incorrect_ood_test = 0.01\n",
      " ---- 103 metric ood_eval = 0.6556091676718938\n",
      " ---- 103 metric ood_eval_time = 14.186168073984721\n",
      " ---- 104000 metric q_loss = 0.26818409349024297\n",
      " ---- 104000 metric hint_loss = 0.08025294564664363\n",
      " ---- 104 metric test_eval_f1 = 0.7137543058037306\n",
      " ---- 104 metric test_eval_time = 10.9\n",
      " ---- 104 metric incorrect_ood_test = 0.011818181818181818\n",
      " ---- 104 metric ood_eval = 0.7706071572175311\n",
      " ---- 104 metric ood_eval_time = 14.61761158021713\n",
      " ---- 52 metric train_eval_f1 = 0.6569790243939121\n",
      " ---- 52 metric train_eval_time = 11.522055479763528\n",
      " ---- 52 metric incorrect_ood_train = 0.029331514324693043\n",
      " ---- 105000 metric q_loss = 0.27335919718444346\n",
      " ---- 105000 metric hint_loss = 0.08121524781361222\n",
      " ---- 105 metric test_eval_f1 = 0.7092624800113533\n",
      " ---- 105 metric test_eval_time = 10.154545454545454\n",
      " ---- 105 metric incorrect_ood_test = 0.010454545454545454\n",
      " ---- 105 metric ood_eval = 0.6950140731805388\n",
      " ---- 105 metric ood_eval_time = 14.241857659831123\n",
      " ---- 106000 metric q_loss = 0.2679611370414495\n",
      " ---- 106000 metric hint_loss = 0.07670799495652318\n",
      " ---- 106 metric test_eval_f1 = 0.7271765882618765\n",
      " ---- 106 metric test_eval_time = 8.635909090909092\n",
      " ---- 106 metric incorrect_ood_test = 0.006818181818181818\n",
      " ---- 106 metric ood_eval = 0.7965420184961801\n",
      " ---- 106 metric ood_eval_time = 14.390229191797346\n",
      " ---- 53 metric train_eval_f1 = 0.6537291897897176\n",
      " ---- 53 metric train_eval_time = 9.641086857662573\n",
      " ---- 53 metric incorrect_ood_train = 0.009549795361527967\n",
      " ---- 107000 metric q_loss = 0.2688271497040987\n",
      " ---- 107000 metric hint_loss = 0.08074759754911065\n",
      " ---- 107 metric test_eval_f1 = 0.6437052242526086\n",
      " ---- 107 metric test_eval_time = 9.367272727272727\n",
      " ---- 107 metric incorrect_ood_test = 0.010454545454545454\n",
      " ---- 107 metric ood_eval = 0.7094893445918777\n",
      " ---- 107 metric ood_eval_time = 14.37253719340571\n",
      " ---- 108000 metric q_loss = 0.2712020610719919\n",
      " ---- 108000 metric hint_loss = 0.08518583633750677\n",
      " ---- 108 metric test_eval_f1 = 0.6411681477742641\n",
      " ---- 108 metric test_eval_time = 9.34\n",
      " ---- 108 metric incorrect_ood_test = 0.013636363636363636\n",
      " ---- 108 metric ood_eval = 0.8015681544028951\n",
      " ---- 108 metric ood_eval_time = 14.682549256131885\n",
      " ---- 54 metric train_eval_f1 = 0.6356544674442364\n",
      " ---- 54 metric train_eval_time = 10.493178717598909\n",
      " ---- 54 metric incorrect_ood_train = 0.022964984083674398\n",
      " ---- 109000 metric q_loss = 0.2704096231982112\n",
      " ---- 109000 metric hint_loss = 0.08096445160731673\n",
      " ---- 109 metric test_eval_f1 = 0.6464194120086331\n",
      " ---- 109 metric test_eval_time = 8.176363636363636\n",
      " ---- 109 metric incorrect_ood_test = 0.008636363636363636\n",
      " ---- 109 metric ood_eval = 0.7866907921190189\n",
      " ---- 109 metric ood_eval_time = 14.248693204664255\n",
      " ---- 110000 metric q_loss = 0.2634205524250865\n",
      " ---- 110000 metric hint_loss = 0.07939842042699456\n",
      " ---- 110 metric test_eval_f1 = 0.6293119664627643\n",
      " ---- 110 metric test_eval_time = 12.149545454545455\n",
      " ---- 110 metric incorrect_ood_test = 0.010454545454545454\n",
      " ---- 110 metric ood_eval = 0.88681141938078\n",
      " ---- 110 metric ood_eval_time = 14.733815842380379\n",
      " ---- 55 metric train_eval_f1 = 0.5934617068384327\n",
      " ---- 55 metric train_eval_time = 12.423829013187813\n",
      " ---- 55 metric incorrect_ood_train = 0.022282855843565257\n",
      " ---- 111000 metric q_loss = 0.26996853137761356\n",
      " ---- 111000 metric hint_loss = 0.07923953092470765\n",
      " ---- 111 metric test_eval_f1 = 0.6288840316030906\n",
      " ---- 111 metric test_eval_time = 7.951818181818182\n",
      " ---- 111 metric incorrect_ood_test = 0.005454545454545455\n",
      " ---- 111 metric ood_eval = 0.7434660233212707\n",
      " ---- 111 metric ood_eval_time = 14.169883393646964\n",
      " ---- 112000 metric q_loss = 0.2798699444681406\n",
      " ---- 112000 metric hint_loss = 0.08306373693794013\n",
      " ---- 112 metric test_eval_f1 = 0.7708096543890687\n",
      " ---- 112 metric test_eval_time = 12.079090909090908\n",
      " ---- 112 metric incorrect_ood_test = 0.015909090909090907\n",
      " ---- 112 metric ood_eval = 0.742259750703659\n",
      " ---- 112 metric ood_eval_time = 14.795938882187375\n",
      " ---- 56 metric train_eval_f1 = 0.6825031794755464\n",
      " ---- 56 metric train_eval_time = 12.362551159618008\n",
      " ---- 56 metric incorrect_ood_train = 0.04695316052751251\n",
      " ---- 113000 metric q_loss = 0.27223974497616293\n",
      " ---- 113000 metric hint_loss = 0.08150659693032503\n",
      " ---- 113 metric test_eval_f1 = 0.7036452589268637\n",
      " ---- 113 metric test_eval_time = 9.777272727272727\n",
      " ---- 113 metric incorrect_ood_test = 0.01090909090909091\n",
      " ---- 113 metric ood_eval = 0.8246883795737837\n",
      " ---- 113 metric ood_eval_time = 14.21632488942501\n",
      " ---- 114000 metric q_loss = 0.2738833304643631\n",
      " ---- 114000 metric hint_loss = 0.08525323043018579\n",
      " ---- 114 metric test_eval_f1 = 0.6764711341178375\n",
      " ---- 114 metric test_eval_time = 9.328636363636363\n",
      " ---- 114 metric incorrect_ood_test = 0.01090909090909091\n",
      " ---- 114 metric ood_eval = 0.8230800160836349\n",
      " ---- 114 metric ood_eval_time = 14.619622034579814\n",
      " ---- 57 metric train_eval_f1 = 0.6550961131783297\n",
      " ---- 57 metric train_eval_time = 10.432696680309231\n",
      " ---- 57 metric incorrect_ood_train = 0.01580263756252842\n",
      " ---- 115000 metric q_loss = 0.26380954349786045\n",
      " ---- 115000 metric hint_loss = 0.07787103825807572\n",
      " ---- 115 metric test_eval_f1 = 0.760080979651213\n",
      " ---- 115 metric test_eval_time = 10.162727272727272\n",
      " ---- 115 metric incorrect_ood_test = 0.02\n",
      " ---- 115 metric ood_eval = 0.7225572979493365\n",
      " ---- 115 metric ood_eval_time = 14.623441897868918\n",
      " ---- 116000 metric q_loss = 0.2665641109496355\n",
      " ---- 116000 metric hint_loss = 0.07944721007719636\n",
      " ---- 116 metric test_eval_f1 = 0.7317190570884211\n",
      " ---- 116 metric test_eval_time = 8.782272727272728\n",
      " ---- 116 metric incorrect_ood_test = 0.008636363636363636\n",
      " ---- 116 metric ood_eval = 0.6656614394853236\n",
      " ---- 116 metric ood_eval_time = 14.055689585846402\n",
      " ---- 58 metric train_eval_f1 = 0.6400447374202128\n",
      " ---- 58 metric train_eval_time = 9.667689859026831\n",
      " ---- 58 metric incorrect_ood_train = 0.014438381082310141\n",
      " ---- 117000 metric q_loss = 0.2637228834927082\n",
      " ---- 117000 metric hint_loss = 0.08295890349894762\n",
      " ---- 117 metric test_eval_f1 = 0.7022474857173308\n",
      " ---- 117 metric test_eval_time = 9.811818181818182\n",
      " ---- 117 metric incorrect_ood_test = 0.015\n",
      " ---- 117 metric ood_eval = 0.7569360675512666\n",
      " ---- 117 metric ood_eval_time = 13.948733413751508\n",
      " ---- 118000 metric q_loss = 0.2715707205981016\n",
      " ---- 118000 metric hint_loss = 0.08300799179822206\n",
      " ---- 118 metric test_eval_f1 = 0.725425903560099\n",
      " ---- 118 metric test_eval_time = 10.931363636363637\n",
      " ---- 118 metric incorrect_ood_test = 0.014545454545454545\n",
      " ---- 118 metric ood_eval = 0.7010454362685967\n",
      " ---- 118 metric ood_eval_time = 14.405106554081222\n",
      " ---- 59 metric train_eval_f1 = 0.6613822249460157\n",
      " ---- 59 metric train_eval_time = 11.405866302864938\n",
      " ---- 59 metric incorrect_ood_train = 0.02307867212369259\n",
      " ---- 119000 metric q_loss = 0.2666846992895007\n",
      " ---- 119000 metric hint_loss = 0.08556366505473852\n",
      " ---- 119 metric test_eval_f1 = 0.6808980390345196\n",
      " ---- 119 metric test_eval_time = 8.362727272727273\n",
      " ---- 119 metric incorrect_ood_test = 0.01\n",
      " ---- 119 metric ood_eval = 0.6962203457981504\n",
      " ---- 119 metric ood_eval_time = 13.86409328508243\n",
      " ---- 120000 metric q_loss = 0.26400378746539355\n",
      " ---- 120000 metric hint_loss = 0.08237148664891719\n",
      " ---- 120 metric test_eval_f1 = 0.7359732308027843\n",
      " ---- 120 metric test_eval_time = 8.578181818181818\n",
      " ---- 120 metric incorrect_ood_test = 0.007727272727272728\n",
      " ---- 120 metric ood_eval = 0.7822677925211098\n",
      " ---- 120 metric ood_eval_time = 14.23059911540008\n",
      " ---- 60 metric train_eval_f1 = 0.6532387907693018\n",
      " ---- 60 metric train_eval_time = 9.732719417917234\n",
      " ---- 60 metric incorrect_ood_train = 0.014211005002273762\n",
      " ---- 121000 metric q_loss = 0.2675624354556203\n",
      " ---- 121000 metric hint_loss = 0.08318226650357247\n",
      " ---- 121 metric test_eval_f1 = 0.7438125395779243\n",
      " ---- 121 metric test_eval_time = 9.668181818181818\n",
      " ---- 121 metric incorrect_ood_test = 0.011818181818181818\n",
      " ---- 121 metric ood_eval = 0.6942098914354644\n",
      " ---- 121 metric ood_eval_time = 14.02291917973462\n",
      " ---- 122000 metric q_loss = 0.2579330736845732\n",
      " ---- 122000 metric hint_loss = 0.0781893014870584\n",
      " ---- 122 metric test_eval_f1 = 0.7523107680562791\n",
      " ---- 122 metric test_eval_time = 9.264545454545454\n",
      " ---- 122 metric incorrect_ood_test = 0.01\n",
      " ---- 122 metric ood_eval = 0.7092882991556092\n",
      " ---- 122 metric ood_eval_time = 14.311620426216324\n",
      " ---- 61 metric train_eval_f1 = 0.6889426441169215\n",
      " ---- 61 metric train_eval_time = 10.281264211005002\n",
      " ---- 61 metric incorrect_ood_train = 0.01409731696225557\n",
      " ---- 123000 metric q_loss = 0.25658724327385424\n",
      " ---- 123000 metric hint_loss = 0.07573530229926109\n",
      " ---- 123 metric test_eval_f1 = 0.7360266312805712\n",
      " ---- 123 metric test_eval_time = 11.763636363636364\n",
      " ---- 123 metric incorrect_ood_test = 0.00909090909090909\n",
      " ---- 123 metric ood_eval = 0.6336952151186168\n",
      " ---- 123 metric ood_eval_time = 14.841576196220347\n",
      " ---- 124000 metric q_loss = 0.2616272646412253\n",
      " ---- 124000 metric hint_loss = 0.081928814381361\n",
      " ---- 124 metric test_eval_f1 = 0.7555732243277883\n",
      " ---- 124 metric test_eval_time = 10.957727272727272\n",
      " ---- 124 metric incorrect_ood_test = 0.009545454545454546\n",
      " ---- 124 metric ood_eval = 0.7687977482911138\n",
      " ---- 124 metric ood_eval_time = 14.48009650180941\n",
      " ---- 62 metric train_eval_f1 = 0.7036643825182425\n",
      " ---- 62 metric train_eval_time = 11.39199636198272\n",
      " ---- 62 metric incorrect_ood_train = 0.01307412460209186\n",
      " ---- 125000 metric q_loss = 0.2619698006287217\n",
      " ---- 125000 metric hint_loss = 0.07925183826312422\n",
      " ---- 125 metric test_eval_f1 = 0.7575839986660612\n",
      " ---- 125 metric test_eval_time = 11.336818181818181\n",
      " ---- 125 metric incorrect_ood_test = 0.01090909090909091\n",
      " ---- 125 metric ood_eval = 0.828508242862887\n",
      " ---- 125 metric ood_eval_time = 14.559911540008041\n",
      " ---- 126000 metric q_loss = 0.26117282500863076\n",
      " ---- 126000 metric hint_loss = 0.0797931094393134\n",
      " ---- 126 metric test_eval_f1 = 0.7595905640741228\n",
      " ---- 126 metric test_eval_time = 11.811818181818182\n",
      " ---- 126 metric incorrect_ood_test = 0.01\n",
      " ---- 126 metric ood_eval = 0.873341375150784\n",
      " ---- 126 metric ood_eval_time = 14.825894652191396\n",
      " ---- 63 metric train_eval_f1 = 0.7000633961399543\n",
      " ---- 63 metric train_eval_time = 11.980218281036835\n",
      " ---- 63 metric incorrect_ood_train = 0.016939517962710322\n",
      " ---- 127000 metric q_loss = 0.2641766795217991\n",
      " ---- 127000 metric hint_loss = 0.08470683843642474\n",
      " ---- 127 metric test_eval_f1 = 0.7207707109500809\n",
      " ---- 127 metric test_eval_time = 10.157727272727273\n",
      " ---- 127 metric incorrect_ood_test = 0.006818181818181818\n",
      " ---- 127 metric ood_eval = 0.7320064334539605\n",
      " ---- 127 metric ood_eval_time = 13.979493365500604\n",
      " ---- 128000 metric q_loss = 0.25746413638442756\n",
      " ---- 128000 metric hint_loss = 0.08260518212988972\n",
      " ---- 128 metric test_eval_f1 = 0.785862085023545\n",
      " ---- 128 metric test_eval_time = 10.932272727272727\n",
      " ---- 128 metric incorrect_ood_test = 0.011818181818181818\n",
      " ---- 128 metric ood_eval = 0.8351427422597507\n",
      " ---- 128 metric ood_eval_time = 14.764374748693205\n",
      " ---- 64 metric train_eval_f1 = 0.7276920120199413\n",
      " ---- 64 metric train_eval_time = 11.54138244656662\n",
      " ---- 64 metric incorrect_ood_train = 0.016030013642564803\n",
      " ---- 129000 metric q_loss = 0.26109642384946347\n",
      " ---- 129000 metric hint_loss = 0.08501055078580975\n",
      " ---- 129 metric test_eval_f1 = 0.7622568253100567\n",
      " ---- 129 metric test_eval_time = 9.465454545454545\n",
      " ---- 129 metric incorrect_ood_test = 0.008181818181818182\n",
      " ---- 129 metric ood_eval = 0.7951347004423\n",
      " ---- 129 metric ood_eval_time = 14.29372738238842\n",
      " ---- 130000 metric q_loss = 0.2510797962322831\n",
      " ---- 130000 metric hint_loss = 0.07836576422303915\n",
      " ---- 130 metric test_eval_f1 = 0.7535564921073785\n",
      " ---- 130 metric test_eval_time = 9.93590909090909\n",
      " ---- 130 metric incorrect_ood_test = 0.007727272727272728\n",
      " ---- 130 metric ood_eval = 0.828508242862887\n",
      " ---- 130 metric ood_eval_time = 14.399075190993164\n",
      " ---- 65 metric train_eval_f1 = 0.6893993262586887\n",
      " ---- 65 metric train_eval_time = 10.548658481127786\n",
      " ---- 65 metric incorrect_ood_train = 0.015006821282401092\n",
      " ---- 131000 metric q_loss = 0.26035827662050726\n",
      " ---- 131000 metric hint_loss = 0.08063849830254913\n",
      " ---- 131 metric test_eval_f1 = 0.7651096994560013\n",
      " ---- 131 metric test_eval_time = 9.55090909090909\n",
      " ---- 131 metric incorrect_ood_test = 0.007727272727272728\n",
      " ---- 131 metric ood_eval = 0.8039806996381182\n",
      " ---- 131 metric ood_eval_time = 14.30237233614797\n",
      " ---- 132000 metric q_loss = 0.2531684713363647\n",
      " ---- 132000 metric hint_loss = 0.07963452716544271\n",
      " ---- 132 metric test_eval_f1 = 0.7414802359470166\n",
      " ---- 132 metric test_eval_time = 11.128181818181819\n",
      " ---- 132 metric incorrect_ood_test = 0.005909090909090909\n",
      " ---- 132 metric ood_eval = 0.8114193807800563\n",
      " ---- 132 metric ood_eval_time = 14.623843988741456\n",
      " ---- 66 metric train_eval_f1 = 0.6969992726677536\n",
      " ---- 66 metric train_eval_time = 11.405979990904957\n",
      " ---- 66 metric incorrect_ood_train = 0.010686675761709868\n",
      " ---- 133000 metric q_loss = 0.2577151581868529\n",
      " ---- 133000 metric hint_loss = 0.07790951879322529\n",
      " ---- 133 metric test_eval_f1 = 0.7583189217549204\n",
      " ---- 133 metric test_eval_time = 10.321363636363637\n",
      " ---- 133 metric incorrect_ood_test = 0.012272727272727272\n",
      " ---- 133 metric ood_eval = 0.7201447527141134\n",
      " ---- 133 metric ood_eval_time = 14.463208685162847\n",
      " ---- 134000 metric q_loss = 0.2511852967888117\n",
      " ---- 134000 metric hint_loss = 0.07629712611436844\n",
      " ---- 134 metric test_eval_f1 = 0.7805855026579093\n",
      " ---- 134 metric test_eval_time = 10.729545454545455\n",
      " ---- 134 metric incorrect_ood_test = 0.011363636363636364\n",
      " ---- 134 metric ood_eval = 0.6974266184157619\n",
      " ---- 134 metric ood_eval_time = 14.557096903900282\n",
      " ---- 67 metric train_eval_f1 = 0.7060195610211276\n",
      " ---- 67 metric train_eval_time = 11.016598453842656\n",
      " ---- 67 metric incorrect_ood_train = 0.01625738972260118\n",
      " ---- 135000 metric q_loss = 0.25936860966682435\n",
      " ---- 135000 metric hint_loss = 0.08635111684724689\n",
      " ---- 135 metric test_eval_f1 = 0.7746672959585649\n",
      " ---- 135 metric test_eval_time = 10.033636363636363\n",
      " ---- 135 metric incorrect_ood_test = 0.008181818181818182\n",
      " ---- 135 metric ood_eval = 0.7496984318455971\n",
      " ---- 135 metric ood_eval_time = 14.033373542420588\n",
      " ---- 136000 metric q_loss = 0.2550048719495535\n",
      " ---- 136000 metric hint_loss = 0.083058081664145\n",
      " ---- 136 metric test_eval_f1 = 0.7971830016900424\n",
      " ---- 136 metric test_eval_time = 11.096363636363636\n",
      " ---- 136 metric incorrect_ood_test = 0.011818181818181818\n",
      " ---- 136 metric ood_eval = 0.8441897868918375\n",
      " ---- 136 metric ood_eval_time = 14.64053075995175\n",
      " ---- 68 metric train_eval_f1 = 0.7129311885251337\n",
      " ---- 68 metric train_eval_time = 11.178603910868576\n",
      " ---- 68 metric incorrect_ood_train = 0.017053206002728513\n",
      " ---- 137000 metric q_loss = 0.24742671053111553\n",
      " ---- 137000 metric hint_loss = 0.07518564175441861\n",
      " ---- 137 metric test_eval_f1 = 0.8048831103084773\n",
      " ---- 137 metric test_eval_time = 11.712727272727273\n",
      " ---- 137 metric incorrect_ood_test = 0.011363636363636364\n",
      " ---- 137 metric ood_eval = 0.8192601527945316\n",
      " ---- 137 metric ood_eval_time = 14.537394451145959\n",
      " ---- 138000 metric q_loss = 0.25387043369561435\n",
      " ---- 138000 metric hint_loss = 0.08134985911101103\n",
      " ---- 138 metric test_eval_f1 = 0.8083176658422893\n",
      " ---- 138 metric test_eval_time = 11.2\n",
      " ---- 138 metric incorrect_ood_test = 0.012272727272727272\n",
      " ---- 138 metric ood_eval = 0.8443908323281062\n",
      " ---- 138 metric ood_eval_time = 14.526336952151187\n",
      " ---- 69 metric train_eval_f1 = 0.7203780426022008\n",
      " ---- 69 metric train_eval_time = 11.614711232378355\n",
      " ---- 69 metric incorrect_ood_train = 0.018758526603001365\n",
      " ---- 139000 metric q_loss = 0.25138232155889273\n",
      " ---- 139000 metric hint_loss = 0.07428151258453727\n",
      " ---- 139 metric test_eval_f1 = 0.7473995000432605\n",
      " ---- 139 metric test_eval_time = 12.75590909090909\n",
      " ---- 139 metric incorrect_ood_test = 0.014545454545454545\n",
      " ---- 139 metric ood_eval = 0.8254925613188581\n",
      " ---- 139 metric ood_eval_time = 14.887213510253318\n",
      " ---- 140000 metric q_loss = 0.2460647603943944\n",
      " ---- 140000 metric hint_loss = 0.07611868611723184\n",
      " ---- 140 metric test_eval_f1 = 0.7980803687324607\n",
      " ---- 140 metric test_eval_time = 10.684545454545454\n",
      " ---- 140 metric incorrect_ood_test = 0.008181818181818182\n",
      " ---- 140 metric ood_eval = 0.7760353839967833\n",
      " ---- 140 metric ood_eval_time = 14.017893043827906\n",
      " ---- 70 metric train_eval_f1 = 0.7168436974717841\n",
      " ---- 70 metric train_eval_time = 11.057639836289223\n",
      " ---- 70 metric incorrect_ood_train = 0.01205093224192815\n",
      " ---- 141000 metric q_loss = 0.25308398001268506\n",
      " ---- 141000 metric hint_loss = 0.07980447490513325\n",
      " ---- 141 metric test_eval_f1 = 0.8008086674497811\n",
      " ---- 141 metric test_eval_time = 11.671363636363637\n",
      " ---- 141 metric incorrect_ood_test = 0.011818181818181818\n",
      " ---- 141 metric ood_eval = 0.8001608363490149\n",
      " ---- 141 metric ood_eval_time = 14.53015681544029\n",
      " ---- 142000 metric q_loss = 0.247223834708333\n",
      " ---- 142000 metric hint_loss = 0.08124810276180505\n",
      " ---- 142 metric test_eval_f1 = 0.777563172250752\n",
      " ---- 142 metric test_eval_time = 10.468636363636364\n",
      " ---- 142 metric incorrect_ood_test = 0.008636363636363636\n",
      " ---- 142 metric ood_eval = 0.728789706473663\n",
      " ---- 142 metric ood_eval_time = 14.189183755528749\n",
      " ---- 71 metric train_eval_f1 = 0.7087297256285391\n",
      " ---- 71 metric train_eval_time = 10.959527057753524\n",
      " ---- 71 metric incorrect_ood_train = 0.01250568440200091\n",
      " ---- 143000 metric q_loss = 0.24681937983632088\n",
      " ---- 143000 metric hint_loss = 0.080258215803653\n",
      " ---- 143 metric test_eval_f1 = 0.6757483167975702\n",
      " ---- 143 metric test_eval_time = 10.861818181818181\n",
      " ---- 143 metric incorrect_ood_test = 0.01\n",
      " ---- 143 metric ood_eval = 0.7289907519099317\n",
      " ---- 143 metric ood_eval_time = 14.54443104141536\n",
      " ---- 144000 metric q_loss = 0.24709923008829354\n",
      " ---- 144000 metric hint_loss = 0.07995533048734069\n",
      " ---- 144 metric test_eval_f1 = 0.7723930801470278\n",
      " ---- 144 metric test_eval_time = 9.660454545454545\n",
      " ---- 144 metric incorrect_ood_test = 0.009545454545454546\n",
      " ---- 144 metric ood_eval = 0.746280659429031\n",
      " ---- 144 metric ood_eval_time = 14.177523120225171\n",
      " ---- 72 metric train_eval_f1 = 0.702636500427536\n",
      " ---- 72 metric train_eval_time = 10.322987721691678\n",
      " ---- 72 metric incorrect_ood_train = 0.01352887676216462\n",
      " ---- 145000 metric q_loss = 0.24858275321125983\n",
      " ---- 145000 metric hint_loss = 0.08043592696636916\n",
      " ---- 145 metric test_eval_f1 = 0.7619735760607038\n",
      " ---- 145 metric test_eval_time = 10.572727272727272\n",
      " ---- 145 metric incorrect_ood_test = 0.008636363636363636\n",
      " ---- 145 metric ood_eval = 0.7575392038600723\n",
      " ---- 145 metric ood_eval_time = 14.391636509851226\n",
      " ---- 146000 metric q_loss = 0.24635326270014046\n",
      " ---- 146000 metric hint_loss = 0.08067818345874547\n",
      " ---- 146 metric test_eval_f1 = 0.7883171406993561\n",
      " ---- 146 metric test_eval_time = 9.852727272727273\n",
      " ---- 146 metric incorrect_ood_test = 0.009545454545454546\n",
      " ---- 146 metric ood_eval = 0.7889022919179735\n",
      " ---- 146 metric ood_eval_time = 14.181141938078005\n",
      " ---- 73 metric train_eval_f1 = 0.7201714222737259\n",
      " ---- 73 metric train_eval_time = 10.490109140518417\n",
      " ---- 73 metric incorrect_ood_train = 0.01296043656207367\n",
      " ---- 147000 metric q_loss = 0.24901117016375066\n",
      " ---- 147000 metric hint_loss = 0.07951696501672267\n",
      " ---- 147 metric test_eval_f1 = 0.7775897666037417\n",
      " ---- 147 metric test_eval_time = 10.050454545454546\n",
      " ---- 147 metric incorrect_ood_test = 0.01\n",
      " ---- 147 metric ood_eval = 0.7923200643345396\n",
      " ---- 147 metric ood_eval_time = 14.16747084841174\n",
      " ---- 148000 metric q_loss = 0.2378045261017978\n",
      " ---- 148000 metric hint_loss = 0.07546299117431045\n",
      " ---- 148 metric test_eval_f1 = 0.7799029837107789\n",
      " ---- 148 metric test_eval_time = 11.017272727272728\n",
      " ---- 148 metric incorrect_ood_test = 0.007727272727272728\n",
      " ---- 148 metric ood_eval = 0.6232408524326498\n",
      " ---- 148 metric ood_eval_time = 14.189585846401286\n",
      " ---- 74 metric train_eval_f1 = 0.7247437589136209\n",
      " ---- 74 metric train_eval_time = 11.219417917235107\n",
      " ---- 74 metric incorrect_ood_train = 0.014893133242382901\n",
      " ---- 149000 metric q_loss = 0.2509311301186681\n",
      " ---- 149000 metric hint_loss = 0.07608900018036366\n",
      " ---- 149 metric test_eval_f1 = 0.8014363610223526\n",
      " ---- 149 metric test_eval_time = 12.360909090909091\n",
      " ---- 149 metric incorrect_ood_test = 0.008181818181818182\n",
      " ---- 149 metric ood_eval = 0.8845999195818255\n",
      " ---- 149 metric ood_eval_time = 14.615802171290712\n",
      " ---- 150000 metric q_loss = 0.23973338658362628\n",
      " ---- 150000 metric hint_loss = 0.07400953404605388\n",
      " ---- 150 metric test_eval_f1 = 0.7782565251691037\n",
      " ---- 150 metric test_eval_time = 11.546363636363637\n",
      " ---- 150 metric incorrect_ood_test = 0.009545454545454546\n",
      " ---- 150 metric ood_eval = 0.8472054684358665\n",
      " ---- 150 metric ood_eval_time = 14.5243264977885\n",
      " ---- 75 metric train_eval_f1 = 0.7076977344573822\n",
      " ---- 75 metric train_eval_time = 11.694861300591178\n",
      " ---- 75 metric incorrect_ood_train = 0.016143701682582993\n",
      " ---- 151000 metric q_loss = 0.24035254725813865\n",
      " ---- 151000 metric hint_loss = 0.07827553342282773\n",
      " ---- 151 metric test_eval_f1 = 0.8050119758564798\n",
      " ---- 151 metric test_eval_time = 11.479090909090909\n",
      " ---- 151 metric incorrect_ood_test = 0.005909090909090909\n",
      " ---- 151 metric ood_eval = 0.6926015279453156\n",
      " ---- 151 metric ood_eval_time = 14.516083634901488\n",
      " ---- 152000 metric q_loss = 0.24880469577014447\n",
      " ---- 152000 metric hint_loss = 0.08583480524271726\n",
      " ---- 152 metric test_eval_f1 = 0.8064116580224312\n",
      " ---- 152 metric test_eval_time = 11.466363636363637\n",
      " ---- 152 metric incorrect_ood_test = 0.009545454545454546\n",
      " ---- 152 metric ood_eval = 0.730800160836349\n",
      " ---- 152 metric ood_eval_time = 14.37816646562123\n",
      " ---- 76 metric train_eval_f1 = 0.7352541465416503\n",
      " ---- 76 metric train_eval_time = 11.908367439745339\n",
      " ---- 76 metric incorrect_ood_train = 0.016030013642564803\n",
      " ---- 153000 metric q_loss = 0.24629371454566718\n",
      " ---- 153000 metric hint_loss = 0.07953475461155177\n",
      " ---- 153 metric test_eval_f1 = 0.7973576953132432\n",
      " ---- 153 metric test_eval_time = 11.528636363636364\n",
      " ---- 153 metric incorrect_ood_test = 0.008181818181818182\n",
      " ---- 153 metric ood_eval = 0.8186570164857258\n",
      " ---- 153 metric ood_eval_time = 14.488339364696422\n",
      " ---- 154000 metric q_loss = 0.24018170977383851\n",
      " ---- 154000 metric hint_loss = 0.07738763712719082\n",
      " ---- 154 metric test_eval_f1 = 0.796250298995374\n",
      " ---- 154 metric test_eval_time = 10.993181818181819\n",
      " ---- 154 metric incorrect_ood_test = 0.006818181818181818\n",
      " ---- 154 metric ood_eval = 0.8351427422597507\n",
      " ---- 154 metric ood_eval_time = 14.488741455568958\n",
      " ---- 77 metric train_eval_f1 = 0.7307254078073413\n",
      " ---- 77 metric train_eval_time = 11.368235561618917\n",
      " ---- 77 metric incorrect_ood_train = 0.010345611641655298\n",
      " ---- 155000 metric q_loss = 0.23853039260208606\n",
      " ---- 155000 metric hint_loss = 0.08094545183703303\n",
      " ---- 155 metric test_eval_f1 = 0.8158749974733486\n",
      " ---- 155 metric test_eval_time = 11.122727272727273\n",
      " ---- 155 metric incorrect_ood_test = 0.007727272727272728\n",
      " ---- 155 metric ood_eval = 0.7253719340570969\n",
      " ---- 155 metric ood_eval_time = 14.385806192199437\n",
      " ---- 156000 metric q_loss = 0.24206997974216937\n",
      " ---- 156000 metric hint_loss = 0.08055253892019391\n",
      " ---- 156 metric test_eval_f1 = 0.786883006588538\n",
      " ---- 156 metric test_eval_time = 10.60909090909091\n",
      " ---- 156 metric incorrect_ood_test = 0.007727272727272728\n",
      " ---- 156 metric ood_eval = 0.7800562927221552\n",
      " ---- 156 metric ood_eval_time = 14.48411741053478\n",
      " ---- 78 metric train_eval_f1 = 0.7242842122700899\n",
      " ---- 78 metric train_eval_time = 11.277285129604365\n",
      " ---- 78 metric incorrect_ood_train = 0.016484765802637562\n",
      " ---- 157000 metric q_loss = 0.2405441080853343\n",
      " ---- 157000 metric hint_loss = 0.07564203487709165\n",
      " ---- 157 metric test_eval_f1 = 0.8013983305428151\n",
      " ---- 157 metric test_eval_time = 11.262727272727274\n",
      " ---- 157 metric incorrect_ood_test = 0.007727272727272728\n",
      " ---- 157 metric ood_eval = 0.7844792923200643\n",
      " ---- 157 metric ood_eval_time = 14.572577402492964\n",
      " ---- 158000 metric q_loss = 0.24172329834103584\n",
      " ---- 158000 metric hint_loss = 0.07970145428925753\n",
      " ---- 158 metric test_eval_f1 = 0.7685065940161827\n",
      " ---- 158 metric test_eval_time = 13.745454545454546\n",
      " ---- 158 metric incorrect_ood_test = 0.010454545454545454\n",
      " ---- 158 metric ood_eval = 0.7539203860072377\n",
      " ---- 158 metric ood_eval_time = 14.9097305991154\n",
      " ---- 79 metric train_eval_f1 = 0.7041571858998554\n",
      " ---- 79 metric train_eval_time = 13.726239199636199\n",
      " ---- 79 metric incorrect_ood_train = 0.022282855843565257\n",
      " ---- 159000 metric q_loss = 0.2490582105219364\n",
      " ---- 159000 metric hint_loss = 0.08773960515484214\n",
      " ---- 159 metric test_eval_f1 = 0.7963382251553784\n",
      " ---- 159 metric test_eval_time = 9.914545454545454\n",
      " ---- 159 metric incorrect_ood_test = 0.011363636363636364\n",
      " ---- 159 metric ood_eval = 0.728789706473663\n",
      " ---- 159 metric ood_eval_time = 14.326296743063933\n",
      " ---- 160000 metric q_loss = 0.24468824408948422\n",
      " ---- 160000 metric hint_loss = 0.08764115459099411\n",
      " ---- 160 metric test_eval_f1 = 0.7826528430264613\n",
      " ---- 160 metric test_eval_time = 11.289090909090909\n",
      " ---- 160 metric incorrect_ood_test = 0.01090909090909091\n",
      " ---- 160 metric ood_eval = 0.7072778447929232\n",
      " ---- 160 metric ood_eval_time = 14.107961399276236\n",
      " ---- 80 metric train_eval_f1 = 0.7261084326939286\n",
      " ---- 80 metric train_eval_time = 11.699408822191906\n",
      " ---- 80 metric incorrect_ood_train = 0.019895407003183267\n",
      " ---- 161000 metric q_loss = 0.24135331434756518\n",
      " ---- 161000 metric hint_loss = 0.08319021687284112\n",
      " ---- 161 metric test_eval_f1 = 0.8102106475399548\n",
      " ---- 161 metric test_eval_time = 10.524545454545455\n",
      " ---- 161 metric incorrect_ood_test = 0.01090909090909091\n",
      " ---- 161 metric ood_eval = 0.779654201849618\n",
      " ---- 161 metric ood_eval_time = 14.460997185363892\n",
      " ---- 162000 metric q_loss = 0.2313949555233121\n",
      " ---- 162000 metric hint_loss = 0.07941130823269486\n",
      " ---- 162 metric test_eval_f1 = 0.8033129518672412\n",
      " ---- 162 metric test_eval_time = 11.188636363636364\n",
      " ---- 162 metric incorrect_ood_test = 0.010454545454545454\n",
      " ---- 162 metric ood_eval = 0.7511057498994773\n",
      " ---- 162 metric ood_eval_time = 14.379171692802574\n",
      " ---- 81 metric train_eval_f1 = 0.7381891252811402\n",
      " ---- 81 metric train_eval_time = 11.536834924965893\n",
      " ---- 81 metric incorrect_ood_train = 0.016143701682582993\n",
      " ---- 163000 metric q_loss = 0.23778545544669033\n",
      " ---- 163000 metric hint_loss = 0.08272933688759804\n",
      " ---- 163 metric test_eval_f1 = 0.7682346921121515\n",
      " ---- 163 metric test_eval_time = 9.934090909090909\n",
      " ---- 163 metric incorrect_ood_test = 0.008181818181818182\n",
      " ---- 163 metric ood_eval = 0.8767591475673502\n",
      " ---- 163 metric ood_eval_time = 14.448130277442703\n",
      " ---- 164000 metric q_loss = 0.2382288084551692\n",
      " ---- 164000 metric hint_loss = 0.08026607540994883\n",
      " ---- 164 metric test_eval_f1 = 0.802697973713022\n",
      " ---- 164 metric test_eval_time = 11.312727272727273\n",
      " ---- 164 metric incorrect_ood_test = 0.006818181818181818\n",
      " ---- 164 metric ood_eval = 0.7269802975472457\n",
      " ---- 164 metric ood_eval_time = 14.663047848813832\n",
      " ---- 82 metric train_eval_f1 = 0.7364038014830636\n",
      " ---- 82 metric train_eval_time = 11.515916325602547\n",
      " ---- 82 metric incorrect_ood_train = 0.01352887676216462\n",
      " ---- 165000 metric q_loss = 0.23008530013263226\n",
      " ---- 165000 metric hint_loss = 0.0753348175548017\n",
      " ---- 165 metric test_eval_f1 = 0.7579115297191197\n",
      " ---- 165 metric test_eval_time = 10.962272727272728\n",
      " ---- 165 metric incorrect_ood_test = 0.01\n",
      " ---- 165 metric ood_eval = 0.7601527945315641\n",
      " ---- 165 metric ood_eval_time = 14.269199839163651\n",
      " ---- 166000 metric q_loss = 0.23722199287265539\n",
      " ---- 166000 metric hint_loss = 0.07583415075019002\n",
      " ---- 166 metric test_eval_f1 = 0.7729543084068432\n",
      " ---- 166 metric test_eval_time = 10.849545454545455\n",
      " ---- 166 metric incorrect_ood_test = 0.005454545454545455\n",
      " ---- 166 metric ood_eval = 0.7464817048652995\n",
      " ---- 166 metric ood_eval_time = 14.467430639324487\n",
      " ---- 83 metric train_eval_f1 = 0.7317336555390461\n",
      " ---- 83 metric train_eval_time = 11.400977717144157\n",
      " ---- 83 metric incorrect_ood_train = 0.01250568440200091\n",
      " ---- 167000 metric q_loss = 0.2365269754976034\n",
      " ---- 167000 metric hint_loss = 0.08273172594979405\n",
      " ---- 167 metric test_eval_f1 = 0.8068247033460412\n",
      " ---- 167 metric test_eval_time = 11.518636363636364\n",
      " ---- 167 metric incorrect_ood_test = 0.011363636363636364\n",
      " ---- 167 metric ood_eval = 0.7299959790912747\n",
      " ---- 167 metric ood_eval_time = 14.586449537595497\n",
      " ---- 168000 metric q_loss = 0.22497130247205496\n",
      " ---- 168000 metric hint_loss = 0.07033175661787391\n",
      " ---- 168 metric test_eval_f1 = 0.8158840078659331\n",
      " ---- 168 metric test_eval_time = 10.954545454545455\n",
      " ---- 168 metric incorrect_ood_test = 0.011818181818181818\n",
      " ---- 168 metric ood_eval = 0.7694008845999196\n",
      " ---- 168 metric ood_eval_time = 14.490148773622838\n",
      " ---- 84 metric train_eval_f1 = 0.7443166106153601\n",
      " ---- 84 metric train_eval_time = 11.301159618008185\n",
      " ---- 84 metric incorrect_ood_train = 0.020463847203274217\n",
      " ---- 169000 metric q_loss = 0.22353887981921433\n",
      " ---- 169000 metric hint_loss = 0.06754620782285929\n",
      " ---- 169 metric test_eval_f1 = 0.8036527513566853\n",
      " ---- 169 metric test_eval_time = 12.007727272727273\n",
      " ---- 169 metric incorrect_ood_test = 0.008636363636363636\n",
      " ---- 169 metric ood_eval = 0.6895858464012867\n",
      " ---- 169 metric ood_eval_time = 14.419179734620025\n",
      " ---- 170000 metric q_loss = 0.22759523494541645\n",
      " ---- 170000 metric hint_loss = 0.07219349107518792\n",
      " ---- 170 metric test_eval_f1 = 0.8110636727198373\n",
      " ---- 170 metric test_eval_time = 11.94590909090909\n",
      " ---- 170 metric incorrect_ood_test = 0.01\n",
      " ---- 170 metric ood_eval = 0.8178528347406514\n",
      " ---- 170 metric ood_eval_time = 14.499396863691194\n",
      " ---- 85 metric train_eval_f1 = 0.7487386361564657\n",
      " ---- 85 metric train_eval_time = 12.088108231014097\n",
      " ---- 85 metric incorrect_ood_train = 0.015575261482492041\n",
      " ---- 171000 metric q_loss = 0.23219286117330193\n",
      " ---- 171000 metric hint_loss = 0.07376311670616269\n",
      " ---- 171 metric test_eval_f1 = 0.8156290637065314\n",
      " ---- 171 metric test_eval_time = 11.879090909090909\n",
      " ---- 171 metric incorrect_ood_test = 0.007272727272727273\n",
      " ---- 171 metric ood_eval = 0.6926015279453156\n",
      " ---- 171 metric ood_eval_time = 14.499195818254925\n",
      " ---- 172000 metric q_loss = 0.22878906669467688\n",
      " ---- 172000 metric hint_loss = 0.0770695793516934\n",
      " ---- 172 metric test_eval_f1 = 0.804587302712595\n",
      " ---- 172 metric test_eval_time = 10.217272727272727\n",
      " ---- 172 metric incorrect_ood_test = 0.005909090909090909\n",
      " ---- 172 metric ood_eval = 0.8009650180940893\n",
      " ---- 172 metric ood_eval_time = 14.420184961801366\n",
      " ---- 86 metric train_eval_f1 = 0.7400475051040938\n",
      " ---- 86 metric train_eval_time = 10.90950432014552\n",
      " ---- 86 metric incorrect_ood_train = 0.0126193724420191\n",
      " ---- 173000 metric q_loss = 0.2274825579226017\n",
      " ---- 173000 metric hint_loss = 0.07600259144976736\n",
      " ---- 173 metric test_eval_f1 = 0.7978701747898952\n",
      " ---- 173 metric test_eval_time = 10.919545454545455\n",
      " ---- 173 metric incorrect_ood_test = 0.007272727272727273\n",
      " ---- 173 metric ood_eval = 0.7189384800965019\n",
      " ---- 173 metric ood_eval_time = 14.344390832328106\n",
      " ---- 174000 metric q_loss = 0.23159948002547026\n",
      " ---- 174000 metric hint_loss = 0.08284537269547582\n",
      " ---- 174 metric test_eval_f1 = 0.8130219385451387\n",
      " ---- 174 metric test_eval_time = 9.918636363636363\n",
      " ---- 174 metric incorrect_ood_test = 0.013181818181818182\n",
      " ---- 174 metric ood_eval = 0.7619622034579815\n",
      " ---- 174 metric ood_eval_time = 14.294129473260957\n",
      " ---- 87 metric train_eval_f1 = 0.7369072054292517\n",
      " ---- 87 metric train_eval_time = 10.51318781264211\n",
      " ---- 87 metric incorrect_ood_train = 0.019440654843110503\n",
      " ---- 175000 metric q_loss = 0.2304774341545999\n",
      " ---- 175000 metric hint_loss = 0.07881674821674824\n",
      " ---- 175 metric test_eval_f1 = 0.8052747992572911\n",
      " ---- 175 metric test_eval_time = 11.248636363636363\n",
      " ---- 175 metric incorrect_ood_test = 0.010454545454545454\n",
      " ---- 175 metric ood_eval = 0.742259750703659\n",
      " ---- 175 metric ood_eval_time = 14.469441093687173\n",
      " ---- 176000 metric q_loss = 0.22641791452094912\n",
      " ---- 176000 metric hint_loss = 0.07828933106735349\n",
      " ---- 176 metric test_eval_f1 = 0.8080167212579599\n",
      " ---- 176 metric test_eval_time = 10.715454545454545\n",
      " ---- 176 metric incorrect_ood_test = 0.009545454545454546\n",
      " ---- 176 metric ood_eval = 0.7555287494973865\n",
      " ---- 176 metric ood_eval_time = 14.414354644149578\n",
      " ---- 88 metric train_eval_f1 = 0.7402334849884086\n",
      " ---- 88 metric train_eval_time = 11.26819008640291\n",
      " ---- 88 metric incorrect_ood_train = 0.015006821282401092\n",
      " ---- 177000 metric q_loss = 0.23282630325481296\n",
      " ---- 177000 metric hint_loss = 0.08159123611822724\n",
      " ---- 177 metric test_eval_f1 = 0.8012927998721135\n",
      " ---- 177 metric test_eval_time = 10.911363636363637\n",
      " ---- 177 metric incorrect_ood_test = 0.007272727272727273\n",
      " ---- 177 metric ood_eval = 0.7235625251306795\n",
      " ---- 177 metric ood_eval_time = 14.23361479694411\n",
      " ---- 178000 metric q_loss = 0.2271480369269848\n",
      " ---- 178000 metric hint_loss = 0.08250383072718978\n",
      " ---- 178 metric test_eval_f1 = 0.7923311351727012\n",
      " ---- 178 metric test_eval_time = 10.420454545454545\n",
      " ---- 178 metric incorrect_ood_test = 0.007272727272727273\n",
      " ---- 178 metric ood_eval = 0.7609569762766385\n",
      " ---- 178 metric ood_eval_time = 14.253920386007238\n",
      " ---- 89 metric train_eval_f1 = 0.7340628340398679\n",
      " ---- 89 metric train_eval_time = 10.768985902683038\n",
      " ---- 89 metric incorrect_ood_train = 0.01330150068212824\n",
      " ---- 179000 metric q_loss = 0.2312027624770999\n",
      " ---- 179000 metric hint_loss = 0.08675248965993523\n",
      " ---- 179 metric test_eval_f1 = 0.7992200646642598\n",
      " ---- 179 metric test_eval_time = 10.077272727272728\n",
      " ---- 179 metric incorrect_ood_test = 0.005\n",
      " ---- 179 metric ood_eval = 0.6787293928427824\n",
      " ---- 179 metric ood_eval_time = 13.974668275030156\n",
      " ---- 180000 metric q_loss = 0.2303954251334071\n",
      " ---- 180000 metric hint_loss = 0.08336151481792331\n",
      " ---- 180 metric test_eval_f1 = 0.7993409874814851\n",
      " ---- 180 metric test_eval_time = 11.652272727272727\n",
      " ---- 180 metric incorrect_ood_test = 0.008636363636363636\n",
      " ---- 180 metric ood_eval = 0.7082830719742662\n",
      " ---- 180 metric ood_eval_time = 14.53297145154805\n",
      " ---- 90 metric train_eval_f1 = 0.7512127118011588\n",
      " ---- 90 metric train_eval_time = 12.005457025920872\n",
      " ---- 90 metric incorrect_ood_train = 0.016598453842655753\n",
      " ---- 181000 metric q_loss = 0.22829910571128129\n",
      " ---- 181000 metric hint_loss = 0.08432525958493352\n",
      " ---- 181 metric test_eval_f1 = 0.789680229544615\n",
      " ---- 181 metric test_eval_time = 11.511818181818182\n",
      " ---- 181 metric incorrect_ood_test = 0.01\n",
      " ---- 181 metric ood_eval = 0.7519099316445517\n",
      " ---- 181 metric ood_eval_time = 14.266988339364696\n",
      " ---- 182000 metric q_loss = 0.22765285819023848\n",
      " ---- 182000 metric hint_loss = 0.0836351480782032\n",
      " ---- 182 metric test_eval_f1 = 0.7413425416917397\n",
      " ---- 182 metric test_eval_time = 11.441818181818181\n",
      " ---- 182 metric incorrect_ood_test = 0.012272727272727272\n",
      " ---- 182 metric ood_eval = 0.7253719340570969\n",
      " ---- 182 metric ood_eval_time = 14.35806192199437\n",
      " ---- 91 metric train_eval_f1 = 0.713145099609974\n",
      " ---- 91 metric train_eval_time = 11.915984538426558\n",
      " ---- 91 metric incorrect_ood_train = 0.018417462482946793\n",
      " ---- 183000 metric q_loss = 0.22594344340264796\n",
      " ---- 183000 metric hint_loss = 0.08241443016007542\n",
      " ---- 183 metric test_eval_f1 = 0.7897626658700201\n",
      " ---- 183 metric test_eval_time = 9.778181818181817\n",
      " ---- 183 metric incorrect_ood_test = 0.008181818181818182\n",
      " ---- 183 metric ood_eval = 0.7589465219139525\n",
      " ---- 183 metric ood_eval_time = 14.258343385605146\n",
      " ---- 184000 metric q_loss = 0.2164794322066009\n",
      " ---- 184000 metric hint_loss = 0.06898188201710581\n",
      " ---- 184 metric test_eval_f1 = 0.8312413834027225\n",
      " ---- 184 metric test_eval_time = 12.132727272727273\n",
      " ---- 184 metric incorrect_ood_test = 0.01090909090909091\n",
      " ---- 184 metric ood_eval = 0.7454764776839565\n",
      " ---- 184 metric ood_eval_time = 14.685967028548452\n",
      " ---- 92 metric train_eval_f1 = 0.753374608610104\n",
      " ---- 92 metric train_eval_time = 12.162232833105957\n",
      " ---- 92 metric incorrect_ood_train = 0.01455206912232833\n",
      " ---- 185000 metric q_loss = 0.21952146320790053\n",
      " ---- 185000 metric hint_loss = 0.07016470553725958\n",
      " ---- 185 metric test_eval_f1 = 0.8155134355164108\n",
      " ---- 185 metric test_eval_time = 11.382727272727273\n",
      " ---- 185 metric incorrect_ood_test = 0.010454545454545454\n",
      " ---- 185 metric ood_eval = 0.7281865701648572\n",
      " ---- 185 metric ood_eval_time = 14.38962605548854\n",
      " ---- 186000 metric q_loss = 0.21565042289346456\n",
      " ---- 186000 metric hint_loss = 0.07043539256602525\n",
      " ---- 186 metric test_eval_f1 = 0.8136075057972267\n",
      " ---- 186 metric test_eval_time = 10.328636363636363\n",
      " ---- 186 metric incorrect_ood_test = 0.009545454545454546\n",
      " ---- 186 metric ood_eval = 0.7245677523120225\n",
      " ---- 186 metric ood_eval_time = 14.352231604342581\n",
      " ---- 93 metric train_eval_f1 = 0.7488972186870367\n",
      " ---- 93 metric train_eval_time = 11.023988176443838\n",
      " ---- 93 metric incorrect_ood_train = 0.01273306048203729\n",
      " ---- 187000 metric q_loss = 0.21412814412638545\n",
      " ---- 187000 metric hint_loss = 0.07228225030750036\n",
      " ---- 187 metric test_eval_f1 = 0.8045184959380234\n",
      " ---- 187 metric test_eval_time = 12.302727272727273\n",
      " ---- 187 metric incorrect_ood_test = 0.008636363636363636\n",
      " ---- 187 metric ood_eval = 0.7569360675512666\n",
      " ---- 187 metric ood_eval_time = 14.596702854845194\n",
      " ---- 188000 metric q_loss = 0.21368077578395606\n",
      " ---- 188000 metric hint_loss = 0.07261143876984716\n",
      " ---- 188 metric test_eval_f1 = 0.8022593402286318\n",
      " ---- 188 metric test_eval_time = 11.456363636363637\n",
      " ---- 188 metric incorrect_ood_test = 0.012272727272727272\n",
      " ---- 188 metric ood_eval = 0.8118214716525934\n",
      " ---- 188 metric ood_eval_time = 14.454764776839566\n",
      " ---- 94 metric train_eval_f1 = 0.7446687231708554\n",
      " ---- 94 metric train_eval_time = 11.82344247385175\n",
      " ---- 94 metric incorrect_ood_train = 0.01398362892223738\n",
      " ---- 189000 metric q_loss = 0.21133713256195188\n",
      " ---- 189000 metric hint_loss = 0.07263015696778893\n",
      " ---- 189 metric test_eval_f1 = 0.8134133608785485\n",
      " ---- 189 metric test_eval_time = 10.461363636363636\n",
      " ---- 189 metric incorrect_ood_test = 0.00909090909090909\n",
      " ---- 189 metric ood_eval = 0.7685967028548452\n",
      " ---- 189 metric ood_eval_time = 14.353638922396462\n",
      " ---- 190000 metric q_loss = 0.2267653339728713\n",
      " ---- 190000 metric hint_loss = 0.09558623792976141\n",
      " ---- 190 metric test_eval_f1 = 0.8203589823457214\n",
      " ---- 190 metric test_eval_time = 10.584545454545454\n",
      " ---- 190 metric incorrect_ood_test = 0.010454545454545454\n",
      " ---- 190 metric ood_eval = 0.8435866505830317\n",
      " ---- 190 metric ood_eval_time = 14.400884599919582\n",
      " ---- 95 metric train_eval_f1 = 0.7517462516845215\n",
      " ---- 95 metric train_eval_time = 11.185425193269667\n",
      " ---- 95 metric incorrect_ood_train = 0.017507958162801273\n",
      " ---- 191000 metric q_loss = 0.21499170795455574\n",
      " ---- 191000 metric hint_loss = 0.07665972241014242\n",
      " ---- 191 metric test_eval_f1 = 0.8077370505640068\n",
      " ---- 191 metric test_eval_time = 10.951363636363636\n",
      " ---- 191 metric incorrect_ood_test = 0.009545454545454546\n",
      " ---- 191 metric ood_eval = 0.8154402895054282\n",
      " ---- 191 metric ood_eval_time = 14.402090872537194\n",
      " ---- 192000 metric q_loss = 0.222619260199368\n",
      " ---- 192000 metric hint_loss = 0.0868322152979672\n",
      " ---- 192 metric test_eval_f1 = 0.8003153164719152\n",
      " ---- 192 metric test_eval_time = 11.255\n",
      " ---- 192 metric incorrect_ood_test = 0.009545454545454546\n",
      " ---- 192 metric ood_eval = 0.7792521109770808\n",
      " ---- 192 metric ood_eval_time = 14.402492963409731\n",
      " ---- 96 metric train_eval_f1 = 0.7438929121168184\n",
      " ---- 96 metric train_eval_time = 11.55400181900864\n",
      " ---- 96 metric incorrect_ood_train = 0.01477944520236471\n",
      " ---- 193000 metric q_loss = 0.21614962557703257\n",
      " ---- 193000 metric hint_loss = 0.07865019314736128\n",
      " ---- 193 metric test_eval_f1 = 0.7993586470624251\n",
      " ---- 193 metric test_eval_time = 10.605\n",
      " ---- 193 metric incorrect_ood_test = 0.007727272727272728\n",
      " ---- 193 metric ood_eval = 0.6974266184157619\n",
      " ---- 193 metric ood_eval_time = 14.350020104543626\n",
      " ---- 194000 metric q_loss = 0.21322802378982306\n",
      " ---- 194000 metric hint_loss = 0.07319171514734626\n",
      " ---- 194 metric test_eval_f1 = 0.803860573030494\n",
      " ---- 194 metric test_eval_time = 10.466818181818182\n",
      " ---- 194 metric incorrect_ood_test = 0.008636363636363636\n",
      " ---- 194 metric ood_eval = 0.7503015681544029\n",
      " ---- 194 metric ood_eval_time = 14.37675914756735\n",
      " ---- 97 metric train_eval_f1 = 0.7407028160830276\n",
      " ---- 97 metric train_eval_time = 10.899045020463847\n",
      " ---- 97 metric incorrect_ood_train = 0.01386994088221919\n",
      " ---- 195000 metric q_loss = 0.2188975183442235\n",
      " ---- 195000 metric hint_loss = 0.08180202619731426\n",
      " ---- 195 metric test_eval_f1 = 0.8224489936030221\n",
      " ---- 195 metric test_eval_time = 11.724545454545455\n",
      " ---- 195 metric incorrect_ood_test = 0.015454545454545455\n",
      " ---- 195 metric ood_eval = 0.7625653397667873\n",
      " ---- 195 metric ood_eval_time = 14.460997185363892\n",
      " ---- 196000 metric q_loss = 0.2178059702552855\n",
      " ---- 196000 metric hint_loss = 0.07993936466425658\n",
      " ---- 196 metric test_eval_f1 = 0.8159859722476109\n",
      " ---- 196 metric test_eval_time = 10.569545454545455\n",
      " ---- 196 metric incorrect_ood_test = 0.007272727272727273\n",
      " ---- 196 metric ood_eval = 0.7657820667470848\n",
      " ---- 196 metric ood_eval_time = 14.249095295536792\n",
      " ---- 98 metric train_eval_f1 = 0.7513062702577252\n",
      " ---- 98 metric train_eval_time = 10.970327421555252\n",
      " ---- 98 metric incorrect_ood_train = 0.010345611641655298\n",
      " ---- 197000 metric q_loss = 0.21012482238933444\n",
      " ---- 197000 metric hint_loss = 0.0758430817052722\n",
      " ---- 197 metric test_eval_f1 = 0.805867648273998\n",
      " ---- 197 metric test_eval_time = 10.716818181818182\n",
      " ---- 197 metric incorrect_ood_test = 0.005454545454545455\n",
      " ---- 197 metric ood_eval = 0.6507840772014475\n",
      " ---- 197 metric ood_eval_time = 14.164455166867713\n",
      " ---- 198000 metric q_loss = 0.20750318874418736\n",
      " ---- 198000 metric hint_loss = 0.06795977584645152\n",
      " ---- 198 metric test_eval_f1 = 0.8198086533348025\n",
      " ---- 198 metric test_eval_time = 10.829545454545455\n",
      " ---- 198 metric incorrect_ood_test = 0.008636363636363636\n",
      " ---- 198 metric ood_eval = 0.6813429835142742\n",
      " ---- 198 metric ood_eval_time = 14.3508242862887\n",
      " ---- 99 metric train_eval_f1 = 0.7457178227528426\n",
      " ---- 99 metric train_eval_time = 11.30593451568895\n",
      " ---- 99 metric incorrect_ood_train = 0.014211005002273762\n",
      " ---- 199000 metric q_loss = 0.21898978638648986\n",
      " ---- 199000 metric hint_loss = 0.07909710582718253\n",
      " ---- 199 metric test_eval_f1 = 0.8128272713728013\n",
      " ---- 199 metric test_eval_time = 11.226363636363637\n",
      " ---- 199 metric incorrect_ood_test = 0.01090909090909091\n",
      " ---- 199 metric ood_eval = 0.7706071572175311\n",
      " ---- 199 metric ood_eval_time = 14.531363088057901\n",
      " ---- 200000 metric q_loss = 0.20831561702489854\n",
      " ---- 200000 metric hint_loss = 0.06394599194452166\n",
      " ---- 200 metric test_eval_f1 = 0.8140410329809981\n",
      " ---- 200 metric test_eval_time = 11.59\n",
      " ---- 200 metric incorrect_ood_test = 0.00909090909090909\n",
      " ---- 200 metric ood_eval = 0.7559308403699236\n",
      " ---- 200 metric ood_eval_time = 14.507438681141938\n",
      " ---- 100 metric train_eval_f1 = 0.7454666993089131\n",
      " ---- 100 metric train_eval_time = 11.778990450204638\n",
      " ---- 100 metric incorrect_ood_train = 0.017280582082764895\n",
      " ---- 201000 metric q_loss = 0.1978189435712993\n",
      " ---- 201000 metric hint_loss = 0.06354300383105874\n",
      " ---- 201 metric test_eval_f1 = 0.7864458892543417\n",
      " ---- 201 metric test_eval_time = 12.546818181818182\n",
      " ---- 201 metric incorrect_ood_test = 0.012272727272727272\n",
      " ---- 201 metric ood_eval = 0.7370325693606755\n",
      " ---- 201 metric ood_eval_time = 14.706473663047849\n",
      " ---- 202000 metric q_loss = 0.2007060644030571\n",
      " ---- 202000 metric hint_loss = 0.06390480945259333\n",
      " ---- 202 metric test_eval_f1 = 0.8156447470370236\n",
      " ---- 202 metric test_eval_time = 12.139090909090909\n",
      " ---- 202 metric incorrect_ood_test = 0.011363636363636364\n",
      " ---- 202 metric ood_eval = 0.8600723763570567\n",
      " ---- 202 metric ood_eval_time = 14.649979895456374\n",
      " ---- 101 metric train_eval_f1 = 0.75045335521395\n",
      " ---- 101 metric train_eval_time = 12.22419281491587\n",
      " ---- 101 metric incorrect_ood_train = 0.019554342883128694\n",
      " ---- 203000 metric q_loss = 0.20482022661715746\n",
      " ---- 203000 metric hint_loss = 0.07344959537684917\n",
      " ---- 203 metric test_eval_f1 = 0.7989537376437753\n",
      " ---- 203 metric test_eval_time = 11.75590909090909\n",
      " ---- 203 metric incorrect_ood_test = 0.011818181818181818\n",
      " ---- 203 metric ood_eval = 0.7581423401688782\n",
      " ---- 203 metric ood_eval_time = 14.477281865701649\n",
      " ---- 204000 metric q_loss = 0.2050114801004529\n",
      " ---- 204000 metric hint_loss = 0.07245061354339123\n",
      " ---- 204 metric test_eval_f1 = 0.7940605790918395\n",
      " ---- 204 metric test_eval_time = 11.166363636363636\n",
      " ---- 204 metric incorrect_ood_test = 0.006363636363636364\n",
      " ---- 204 metric ood_eval = 0.7275834338560515\n",
      " ---- 204 metric ood_eval_time = 14.266586248492159\n",
      " ---- 102 metric train_eval_f1 = 0.735872571287993\n",
      " ---- 102 metric train_eval_time = 11.425989085948158\n",
      " ---- 102 metric incorrect_ood_train = 0.010231923601637109\n",
      " ---- 205000 metric q_loss = 0.20560510677099228\n",
      " ---- 205000 metric hint_loss = 0.0738696714155376\n",
      " ---- 205 metric test_eval_f1 = 0.8164033179402407\n",
      " ---- 205 metric test_eval_time = 11.441818181818181\n",
      " ---- 205 metric incorrect_ood_test = 0.007727272727272728\n",
      " ---- 205 metric ood_eval = 0.8323281061519904\n",
      " ---- 205 metric ood_eval_time = 14.554081222356253\n",
      " ---- 206000 metric q_loss = 0.19716604149714112\n",
      " ---- 206000 metric hint_loss = 0.06696744593605398\n",
      " ---- 206 metric test_eval_f1 = 0.8164789212657599\n",
      " ---- 206 metric test_eval_time = 11.63\n",
      " ---- 206 metric incorrect_ood_test = 0.008636363636363636\n",
      " ---- 206 metric ood_eval = 0.7961399276236429\n",
      " ---- 206 metric ood_eval_time = 14.57016485725774\n",
      " ---- 103 metric train_eval_f1 = 0.7479158079718254\n",
      " ---- 103 metric train_eval_time = 11.801614370168258\n",
      " ---- 103 metric incorrect_ood_train = 0.014211005002273762\n",
      " ---- 207000 metric q_loss = 0.21792740167677402\n",
      " ---- 207000 metric hint_loss = 0.09137707288563252\n",
      " ---- 207 metric test_eval_f1 = 0.8060410760322018\n",
      " ---- 207 metric test_eval_time = 10.401363636363635\n",
      " ---- 207 metric incorrect_ood_test = 0.006818181818181818\n",
      " ---- 207 metric ood_eval = 0.7279855247285887\n",
      " ---- 207 metric ood_eval_time = 14.234217933252916\n",
      " ---- 208000 metric q_loss = 0.20823433077707887\n",
      " ---- 208000 metric hint_loss = 0.0809304600842297\n",
      " ---- 208 metric test_eval_f1 = 0.8029185121824159\n",
      " ---- 208 metric test_eval_time = 10.333181818181819\n",
      " ---- 208 metric incorrect_ood_test = 0.006818181818181818\n",
      " ---- 208 metric ood_eval = 0.8154402895054282\n",
      " ---- 208 metric ood_eval_time = 14.374748693204664\n",
      " ---- 104 metric train_eval_f1 = 0.7494432336039328\n",
      " ---- 104 metric train_eval_time = 10.775579809004093\n",
      " ---- 104 metric incorrect_ood_train = 0.01330150068212824\n",
      " ---- 209000 metric q_loss = 0.20049497106857597\n",
      " ---- 209000 metric hint_loss = 0.07089174251258373\n",
      " ---- 209 metric test_eval_f1 = 0.812027283793933\n",
      " ---- 209 metric test_eval_time = 10.615\n",
      " ---- 209 metric incorrect_ood_test = 0.005454545454545455\n",
      " ---- 209 metric ood_eval = 0.747285886610374\n",
      " ---- 209 metric ood_eval_time = 14.316244471250503\n",
      " ---- 210000 metric q_loss = 0.20086977254226804\n",
      " ---- 210000 metric hint_loss = 0.06769331369549036\n",
      " ---- 210 metric test_eval_f1 = 0.8243833558962219\n",
      " ---- 210 metric test_eval_time = 11.141363636363636\n",
      " ---- 210 metric incorrect_ood_test = 0.01090909090909091\n",
      " ---- 210 metric ood_eval = 0.7366304784881383\n",
      " ---- 210 metric ood_eval_time = 14.370526739043024\n",
      " ---- 105 metric train_eval_f1 = 0.7536979002106673\n",
      " ---- 105 metric train_eval_time = 11.542291950886767\n",
      " ---- 105 metric incorrect_ood_train = 0.020691223283310595\n",
      " ---- 211000 metric q_loss = 0.21804365107417106\n",
      " ---- 211000 metric hint_loss = 0.07928610329702497\n",
      " ---- 211 metric test_eval_f1 = 0.8054574765738828\n",
      " ---- 211 metric test_eval_time = 9.971363636363636\n",
      " ---- 211 metric incorrect_ood_test = 0.009545454545454546\n",
      " ---- 211 metric ood_eval = 0.864897466827503\n",
      " ---- 211 metric ood_eval_time = 14.370124648170487\n",
      " ---- 212000 metric q_loss = 0.20595578864961864\n",
      " ---- 212000 metric hint_loss = 0.08032446626573801\n",
      " ---- 212 metric test_eval_f1 = 0.8106987729182967\n",
      " ---- 212 metric test_eval_time = 11.650454545454545\n",
      " ---- 212 metric incorrect_ood_test = 0.011818181818181818\n",
      " ---- 212 metric ood_eval = 0.743264977885002\n",
      " ---- 212 metric ood_eval_time = 14.606956172094893\n",
      " ---- 106 metric train_eval_f1 = 0.7431858246072358\n",
      " ---- 106 metric train_eval_time = 11.994429286039109\n",
      " ---- 106 metric incorrect_ood_train = 0.020236471123237836\n",
      " ---- 213000 metric q_loss = 0.20559989354759456\n",
      " ---- 213000 metric hint_loss = 0.07248933950066566\n",
      " ---- 213 metric test_eval_f1 = 0.8185605346395687\n",
      " ---- 213 metric test_eval_time = 10.587727272727273\n",
      " ---- 213 metric incorrect_ood_test = 0.01\n",
      " ---- 213 metric ood_eval = 0.7159227985524729\n",
      " ---- 213 metric ood_eval_time = 14.35524728588661\n",
      " ---- 214000 metric q_loss = 0.20736009987071158\n",
      " ---- 214000 metric hint_loss = 0.07869805490970612\n",
      " ---- 214 metric test_eval_f1 = 0.8179327697340667\n",
      " ---- 214 metric test_eval_time = 10.17909090909091\n",
      " ---- 214 metric incorrect_ood_test = 0.010454545454545454\n",
      " ---- 214 metric ood_eval = 0.8160434258142341\n",
      " ---- 214 metric ood_eval_time = 14.340168878166466\n",
      " ---- 107 metric train_eval_f1 = 0.7482144105875025\n",
      " ---- 107 metric train_eval_time = 10.891200545702592\n",
      " ---- 107 metric incorrect_ood_train = 0.01637107776261937\n",
      " ---- 215000 metric q_loss = 0.19628362924605608\n",
      " ---- 215000 metric hint_loss = 0.06702961834520102\n",
      " ---- 215 metric test_eval_f1 = 0.77586229477075\n",
      " ---- 215 metric test_eval_time = 10.885454545454545\n",
      " ---- 215 metric incorrect_ood_test = 0.006363636363636364\n",
      " ---- 215 metric ood_eval = 0.7372336147969442\n",
      " ---- 215 metric ood_eval_time = 14.410936871733012\n",
      " ---- 216000 metric q_loss = 0.20916472118347884\n",
      " ---- 216000 metric hint_loss = 0.08239340663701296\n",
      " ---- 216 metric test_eval_f1 = 0.781316345166953\n",
      " ---- 216 metric test_eval_time = 11.274090909090908\n",
      " ---- 216 metric incorrect_ood_test = 0.010454545454545454\n",
      " ---- 216 metric ood_eval = 0.7237635705669482\n",
      " ---- 216 metric ood_eval_time = 14.26075593084037\n",
      " ---- 108 metric train_eval_f1 = 0.7286072090145249\n",
      " ---- 108 metric train_eval_time = 11.655184174624829\n",
      " ---- 108 metric incorrect_ood_train = 0.01409731696225557\n",
      " ---- 217000 metric q_loss = 0.20488780134916307\n",
      " ---- 217000 metric hint_loss = 0.08176094966381789\n",
      " ---- 217 metric test_eval_f1 = 0.8111630972655092\n",
      " ---- 217 metric test_eval_time = 10.872272727272728\n",
      " ---- 217 metric incorrect_ood_test = 0.011363636363636364\n",
      " ---- 217 metric ood_eval = 0.805589063128267\n",
      " ---- 217 metric ood_eval_time = 14.472054684358666\n",
      " ---- 218000 metric q_loss = 0.1867976842932403\n",
      " ---- 218000 metric hint_loss = 0.06544079799205064\n",
      " ---- 218 metric test_eval_f1 = 0.8134436478654802\n",
      " ---- 218 metric test_eval_time = 11.041818181818181\n",
      " ---- 218 metric incorrect_ood_test = 0.01090909090909091\n",
      " ---- 218 metric ood_eval = 0.7720144752714113\n",
      " ---- 218 metric ood_eval_time = 14.460394049055086\n",
      " ---- 109 metric train_eval_f1 = 0.7551889529013412\n",
      " ---- 109 metric train_eval_time = 11.45350159163256\n",
      " ---- 109 metric incorrect_ood_train = 0.014665757162346521\n",
      " ---- 219000 metric q_loss = 0.18565711630880832\n",
      " ---- 219000 metric hint_loss = 0.06760471596568823\n",
      " ---- 219 metric test_eval_f1 = 0.8192039716018447\n",
      " ---- 219 metric test_eval_time = 11.370454545454546\n",
      " ---- 219 metric incorrect_ood_test = 0.011363636363636364\n",
      " ---- 219 metric ood_eval = 0.7549256131885806\n",
      " ---- 219 metric ood_eval_time = 14.441093687173302\n",
      " ---- 220000 metric q_loss = 0.19780533641576767\n",
      " ---- 220000 metric hint_loss = 0.07482297213003039\n",
      " ---- 220 metric test_eval_f1 = 0.8079264820295563\n",
      " ---- 220 metric test_eval_time = 11.236363636363636\n",
      " ---- 220 metric incorrect_ood_test = 0.008636363636363636\n",
      " ---- 220 metric ood_eval = 0.7885002010454363\n",
      " ---- 220 metric ood_eval_time = 14.517490952955368\n",
      " ---- 110 metric train_eval_f1 = 0.7494322670225464\n",
      " ---- 110 metric train_eval_time = 11.564120054570258\n",
      " ---- 110 metric incorrect_ood_train = 0.017053206002728513\n",
      " ---- 221000 metric q_loss = 0.1908867608755827\n",
      " ---- 221000 metric hint_loss = 0.06802671162411571\n",
      " ---- 221 metric test_eval_f1 = 0.8076522896824572\n",
      " ---- 221 metric test_eval_time = 10.149090909090908\n",
      " ---- 221 metric incorrect_ood_test = 0.007727272727272728\n",
      " ---- 221 metric ood_eval = 0.7808604744672296\n",
      " ---- 221 metric ood_eval_time = 14.337153196622436\n",
      " ---- 222000 metric q_loss = 0.18693635159730912\n",
      " ---- 222000 metric hint_loss = 0.06400588934868574\n",
      " ---- 222 metric test_eval_f1 = 0.8021478252831045\n",
      " ---- 222 metric test_eval_time = 10.969545454545454\n",
      " ---- 222 metric incorrect_ood_test = 0.00909090909090909\n",
      " ---- 222 metric ood_eval = 0.7585444310414153\n",
      " ---- 222 metric ood_eval_time = 14.322476879774829\n",
      " ---- 111 metric train_eval_f1 = 0.7501239570257305\n",
      " ---- 111 metric train_eval_time = 11.41018644838563\n",
      " ---- 111 metric incorrect_ood_train = 0.016030013642564803\n",
      " ---- 223000 metric q_loss = 0.19822975055873393\n",
      " ---- 223000 metric hint_loss = 0.07218360146135092\n",
      " ---- 223 metric test_eval_f1 = 0.8190744801382421\n",
      " ---- 223 metric test_eval_time = 11.544545454545455\n",
      " ---- 223 metric incorrect_ood_test = 0.00909090909090909\n",
      " ---- 223 metric ood_eval = 0.7957378367511058\n",
      " ---- 223 metric ood_eval_time = 14.482911137917169\n",
      " ---- 224000 metric q_loss = 0.18889307056739926\n",
      " ---- 224000 metric hint_loss = 0.06349273867160082\n",
      " ---- 224 metric test_eval_f1 = 0.8080875275071772\n",
      " ---- 224 metric test_eval_time = 12.106363636363636\n",
      " ---- 224 metric incorrect_ood_test = 0.015454545454545455\n",
      " ---- 224 metric ood_eval = 0.7380377965420185\n",
      " ---- 224 metric ood_eval_time = 14.449336550060314\n",
      " ---- 112 metric train_eval_f1 = 0.7589055830486214\n",
      " ---- 112 metric train_eval_time = 12.403024101864483\n",
      " ---- 112 metric incorrect_ood_train = 0.033879035925420645\n",
      " ---- 225000 metric q_loss = 0.18995903708785772\n",
      " ---- 225000 metric hint_loss = 0.06725655897334218\n",
      " ---- 225 metric test_eval_f1 = 0.8077972395777909\n",
      " ---- 225 metric test_eval_time = 11.287727272727272\n",
      " ---- 225 metric incorrect_ood_test = 0.01090909090909091\n",
      " ---- 225 metric ood_eval = 0.8051869722557298\n",
      " ---- 225 metric ood_eval_time = 14.431041415359871\n",
      " ---- 226000 metric q_loss = 0.19585715302824974\n",
      " ---- 226000 metric hint_loss = 0.07616663459688425\n",
      " ---- 226 metric test_eval_f1 = 0.8011365543009856\n",
      " ---- 226 metric test_eval_time = 10.309545454545454\n",
      " ---- 226 metric incorrect_ood_test = 0.01\n",
      " ---- 226 metric ood_eval = 0.7828709288299156\n",
      " ---- 226 metric ood_eval_time = 14.16043425814234\n",
      " ---- 113 metric train_eval_f1 = 0.7442597903355125\n",
      " ---- 113 metric train_eval_time = 10.803774442928605\n",
      " ---- 113 metric incorrect_ood_train = 0.01580263756252842\n",
      " ---- 227000 metric q_loss = 0.18889547707512974\n",
      " ---- 227000 metric hint_loss = 0.07117796014621854\n",
      " ---- 227 metric test_eval_f1 = 0.815367923293849\n",
      " ---- 227 metric test_eval_time = 12.038636363636364\n",
      " ---- 227 metric incorrect_ood_test = 0.01\n",
      " ---- 227 metric ood_eval = 0.7740249296340973\n",
      " ---- 227 metric ood_eval_time = 14.483313228789706\n",
      " ---- 228000 metric q_loss = 0.2054930135831237\n",
      " ---- 228000 metric hint_loss = 0.08790264379605651\n",
      " ---- 228 metric test_eval_f1 = 0.8063284143213546\n",
      " ---- 228 metric test_eval_time = 11.794545454545455\n",
      " ---- 228 metric incorrect_ood_test = 0.011363636363636364\n",
      " ---- 228 metric ood_eval = 0.7850824286288701\n",
      " ---- 228 metric ood_eval_time = 14.612585444310414\n",
      " ---- 114 metric train_eval_f1 = 0.7486913613342541\n",
      " ---- 114 metric train_eval_time = 11.94406548431105\n",
      " ---- 114 metric incorrect_ood_train = 0.019213278763074125\n",
      " ---- 229000 metric q_loss = 0.1947654212936759\n",
      " ---- 229000 metric hint_loss = 0.07486886888742447\n",
      " ---- 229 metric test_eval_f1 = 0.8199256238711491\n",
      " ---- 229 metric test_eval_time = 10.559545454545454\n",
      " ---- 229 metric incorrect_ood_test = 0.010454545454545454\n",
      " ---- 229 metric ood_eval = 0.7778447929232006\n",
      " ---- 229 metric ood_eval_time = 14.289907519099316\n",
      " ---- 230000 metric q_loss = 0.19412302221730351\n",
      " ---- 230000 metric hint_loss = 0.07570882688835263\n",
      " ---- 230 metric test_eval_f1 = 0.8209167540668422\n",
      " ---- 230 metric test_eval_time = 10.714545454545455\n",
      " ---- 230 metric incorrect_ood_test = 0.012272727272727272\n",
      " ---- 230 metric ood_eval = 0.7400482509047045\n",
      " ---- 230 metric ood_eval_time = 14.444913550462404\n",
      " ---- 115 metric train_eval_f1 = 0.7577396379809513\n",
      " ---- 115 metric train_eval_time = 11.09049567985448\n",
      " ---- 115 metric incorrect_ood_train = 0.01625738972260118\n",
      " ---- 231000 metric q_loss = 0.18069029653817414\n",
      " ---- 231000 metric hint_loss = 0.0640236716195941\n",
      " ---- 231 metric test_eval_f1 = 0.8168702193043402\n",
      " ---- 231 metric test_eval_time = 10.951818181818181\n",
      " ---- 231 metric incorrect_ood_test = 0.005454545454545455\n",
      " ---- 231 metric ood_eval = 0.7490952955367913\n",
      " ---- 231 metric ood_eval_time = 14.378970647366305\n",
      " ---- 232000 metric q_loss = 0.18797645574435592\n",
      " ---- 232000 metric hint_loss = 0.07297146229073405\n",
      " ---- 232 metric test_eval_f1 = 0.8171771747750678\n",
      " ---- 232 metric test_eval_time = 11.051363636363636\n",
      " ---- 232 metric incorrect_ood_test = 0.011363636363636364\n",
      " ---- 232 metric ood_eval = 0.7022517088862082\n",
      " ---- 232 metric ood_eval_time = 14.43124246079614\n",
      " ---- 116 metric train_eval_f1 = 0.7532630451510179\n",
      " ---- 116 metric train_eval_time = 11.505798090040928\n",
      " ---- 116 metric incorrect_ood_train = 0.020236471123237836\n",
      " ---- 233000 metric q_loss = 0.18712331825867295\n",
      " ---- 233000 metric hint_loss = 0.07494155264645815\n",
      " ---- 233 metric test_eval_f1 = 0.8246355112289963\n",
      " ---- 233 metric test_eval_time = 10.637727272727274\n",
      " ---- 233 metric incorrect_ood_test = 0.011363636363636364\n",
      " ---- 233 metric ood_eval = 0.6926015279453156\n",
      " ---- 233 metric ood_eval_time = 14.197225572979493\n",
      " ---- 234000 metric q_loss = 0.17219178623333573\n",
      " ---- 234000 metric hint_loss = 0.05512566862255335\n",
      " ---- 234 metric test_eval_f1 = 0.8004352374616537\n",
      " ---- 234 metric test_eval_time = 10.579090909090908\n",
      " ---- 234 metric incorrect_ood_test = 0.01\n",
      " ---- 234 metric ood_eval = 0.7185363892239646\n",
      " ---- 234 metric ood_eval_time = 14.261962203457982\n",
      " ---- 117 metric train_eval_f1 = 0.7404396168896619\n",
      " ---- 117 metric train_eval_time = 10.984765802637563\n",
      " ---- 117 metric incorrect_ood_train = 0.015006821282401092\n",
      " ---- 235000 metric q_loss = 0.1803952677845955\n",
      " ---- 235000 metric hint_loss = 0.07027191692963243\n",
      " ---- 235 metric test_eval_f1 = 0.8057167294635273\n",
      " ---- 235 metric test_eval_time = 11.54\n",
      " ---- 235 metric incorrect_ood_test = 0.01090909090909091\n",
      " ---- 235 metric ood_eval = 0.7696019300361882\n",
      " ---- 235 metric ood_eval_time = 14.42119018898271\n",
      " ---- 236000 metric q_loss = 0.18039453811198472\n",
      " ---- 236000 metric hint_loss = 0.06748382737487554\n",
      " ---- 236 metric test_eval_f1 = 0.8116315881243527\n",
      " ---- 236 metric test_eval_time = 10.248181818181818\n",
      " ---- 236 metric incorrect_ood_test = 0.010454545454545454\n",
      " ---- 236 metric ood_eval = 0.7613590671491757\n",
      " ---- 236 metric ood_eval_time = 14.31926015279453\n",
      " ---- 118 metric train_eval_f1 = 0.7549277696786544\n",
      " ---- 118 metric train_eval_time = 10.972828558435653\n",
      " ---- 118 metric incorrect_ood_train = 0.011596180081855388\n",
      " ---- 237000 metric q_loss = 0.18838390762731433\n",
      " ---- 237000 metric hint_loss = 0.08243734881654381\n",
      " ---- 237 metric test_eval_f1 = 0.8192716534045897\n",
      " ---- 237 metric test_eval_time = 10.988636363636363\n",
      " ---- 237 metric incorrect_ood_test = 0.009545454545454546\n",
      " ---- 237 metric ood_eval = 0.7947326095697628\n",
      " ---- 237 metric ood_eval_time = 14.411942098914354\n",
      " ---- 238000 metric q_loss = 0.18135661112889648\n",
      " ---- 238000 metric hint_loss = 0.06756624864786863\n",
      " ---- 238 metric test_eval_f1 = 0.827147455773006\n",
      " ---- 238 metric test_eval_time = 11.165454545454546\n",
      " ---- 238 metric incorrect_ood_test = 0.009545454545454546\n",
      " ---- 238 metric ood_eval = 0.8391636509851227\n",
      " ---- 238 metric ood_eval_time = 14.576598311218335\n",
      " ---- 119 metric train_eval_f1 = 0.7580502812475373\n",
      " ---- 119 metric train_eval_time = 11.680991359708958\n",
      " ---- 119 metric incorrect_ood_train = 0.017394270122783082\n",
      " ---- 239000 metric q_loss = 0.18559839110448956\n",
      " ---- 239000 metric hint_loss = 0.07271572361513973\n",
      " ---- 239 metric test_eval_f1 = 0.8270235366364086\n",
      " ---- 239 metric test_eval_time = 10.260909090909092\n",
      " ---- 239 metric incorrect_ood_test = 0.008181818181818182\n",
      " ---- 239 metric ood_eval = 0.8218737434660234\n",
      " ---- 239 metric ood_eval_time = 14.400884599919582\n",
      " ---- 240000 metric q_loss = 0.18114411579072476\n",
      " ---- 240000 metric hint_loss = 0.07123293217644096\n",
      " ---- 240 metric test_eval_f1 = 0.8131028903755844\n",
      " ---- 240 metric test_eval_time = 11.369545454545454\n",
      " ---- 240 metric incorrect_ood_test = 0.006363636363636364\n",
      " ---- 240 metric ood_eval = 0.8224768797748291\n",
      " ---- 240 metric ood_eval_time = 14.44993968636912\n",
      " ---- 120 metric train_eval_f1 = 0.752034002531802\n",
      " ---- 120 metric train_eval_time = 11.653024101864483\n",
      " ---- 120 metric incorrect_ood_train = 0.01455206912232833\n",
      " ---- 241000 metric q_loss = 0.18162705847993493\n",
      " ---- 241000 metric hint_loss = 0.07338224257528782\n",
      " ---- 241 metric test_eval_f1 = 0.814333969831408\n",
      " ---- 241 metric test_eval_time = 11.425\n",
      " ---- 241 metric incorrect_ood_test = 0.009545454545454546\n",
      " ---- 241 metric ood_eval = 0.8717330116606353\n",
      " ---- 241 metric ood_eval_time = 14.50864495375955\n",
      " ---- 242000 metric q_loss = 0.1680907012782991\n",
      " ---- 242000 metric hint_loss = 0.054130629483610394\n",
      " ---- 242 metric test_eval_f1 = 0.8295105802306946\n",
      " ---- 242 metric test_eval_time = 11.120454545454546\n",
      " ---- 242 metric incorrect_ood_test = 0.011818181818181818\n",
      " ---- 242 metric ood_eval = 0.8118214716525934\n",
      " ---- 242 metric ood_eval_time = 14.479694410936872\n",
      " ---- 121 metric train_eval_f1 = 0.7639697331015154\n",
      " ---- 121 metric train_eval_time = 11.673601637107776\n",
      " ---- 121 metric incorrect_ood_train = 0.018758526603001365\n",
      " ---- 243000 metric q_loss = 0.17919269090890885\n",
      " ---- 243000 metric hint_loss = 0.07047485702857376\n",
      " ---- 243 metric test_eval_f1 = 0.8195355152200245\n",
      " ---- 243 metric test_eval_time = 12.212727272727273\n",
      " ---- 243 metric incorrect_ood_test = 0.01090909090909091\n",
      " ---- 243 metric ood_eval = 0.7878970647366305\n",
      " ---- 243 metric ood_eval_time = 14.526135906714918\n",
      " ---- 244000 metric q_loss = 0.17544834131374956\n",
      " ---- 244000 metric hint_loss = 0.06281989036500454\n",
      " ---- 244 metric test_eval_f1 = 0.8213091232553694\n",
      " ---- 244 metric test_eval_time = 10.846818181818183\n",
      " ---- 244 metric incorrect_ood_test = 0.00909090909090909\n",
      " ---- 244 metric ood_eval = 0.767189384800965\n",
      " ---- 244 metric ood_eval_time = 14.315440289505428\n",
      " ---- 122 metric train_eval_f1 = 0.7598228719469756\n",
      " ---- 122 metric train_eval_time = 11.406434743065029\n",
      " ---- 122 metric incorrect_ood_train = 0.013415188722146431\n",
      " ---- 245000 metric q_loss = 0.17681929245591163\n",
      " ---- 245000 metric hint_loss = 0.06650666123628617\n",
      " ---- 245 metric test_eval_f1 = 0.8078274581690855\n",
      " ---- 245 metric test_eval_time = 10.491363636363637\n",
      " ---- 245 metric incorrect_ood_test = 0.011363636363636364\n",
      " ---- 245 metric ood_eval = 0.7840772014475271\n",
      " ---- 245 metric ood_eval_time = 14.335946924004825\n",
      " ---- 246000 metric q_loss = 0.18085422851890326\n",
      " ---- 246000 metric hint_loss = 0.06937364514172077\n",
      " ---- 246 metric test_eval_f1 = 0.8049006976963257\n",
      " ---- 246 metric test_eval_time = 11.189545454545454\n",
      " ---- 246 metric incorrect_ood_test = 0.008636363636363636\n",
      " ---- 246 metric ood_eval = 0.7808604744672296\n",
      " ---- 246 metric ood_eval_time = 14.419179734620025\n",
      " ---- 123 metric train_eval_f1 = 0.7468705351997413\n",
      " ---- 123 metric train_eval_time = 11.862551159618008\n",
      " ---- 123 metric incorrect_ood_train = 0.017849022282855842\n",
      " ---- 247000 metric q_loss = 0.17177834433689715\n",
      " ---- 247000 metric hint_loss = 0.06165842985734343\n",
      " ---- 247 metric test_eval_f1 = 0.80637372772517\n",
      " ---- 247 metric test_eval_time = 10.184545454545454\n",
      " ---- 247 metric incorrect_ood_test = 0.008636363636363636\n",
      " ---- 247 metric ood_eval = 0.76075593084037\n",
      " ---- 247 metric ood_eval_time = 14.342179332529152\n",
      " ---- 248000 metric q_loss = 0.17656311764568092\n",
      " ---- 248000 metric hint_loss = 0.07119093326851726\n",
      " ---- 248 metric test_eval_f1 = 0.8141427711746604\n",
      " ---- 248 metric test_eval_time = 10.017727272727273\n",
      " ---- 248 metric incorrect_ood_test = 0.005454545454545455\n",
      " ---- 248 metric ood_eval = 0.7919179734620024\n",
      " ---- 248 metric ood_eval_time = 14.352633695215118\n",
      " ---- 124 metric train_eval_f1 = 0.7499253406678633\n",
      " ---- 124 metric train_eval_time = 10.986584811277854\n",
      " ---- 124 metric incorrect_ood_train = 0.01330150068212824\n",
      " ---- 249000 metric q_loss = 0.17574347809702157\n",
      " ---- 249000 metric hint_loss = 0.0741447387225926\n",
      " ---- 249 metric test_eval_f1 = 0.8114472606317751\n",
      " ---- 249 metric test_eval_time = 9.87590909090909\n",
      " ---- 249 metric incorrect_ood_test = 0.007727272727272728\n",
      " ---- 249 metric ood_eval = 0.7394451145958987\n",
      " ---- 249 metric ood_eval_time = 14.251708886208283\n",
      " ---- 250000 metric q_loss = 0.17915267046168445\n",
      " ---- 250000 metric hint_loss = 0.07758964101225138\n",
      " ---- 250 metric test_eval_f1 = 0.8274241992971418\n",
      " ---- 250 metric test_eval_time = 10.86909090909091\n",
      " ---- 250 metric incorrect_ood_test = 0.01\n",
      " ---- 250 metric ood_eval = 0.7714113389626055\n",
      " ---- 250 metric ood_eval_time = 14.422798552472859\n",
      " ---- 125 metric train_eval_f1 = 0.761037645094246\n",
      " ---- 125 metric train_eval_time = 11.404956798544793\n",
      " ---- 125 metric incorrect_ood_train = 0.017735334242837655\n",
      " ---- 251000 metric q_loss = 0.16450269775465132\n",
      " ---- 251000 metric hint_loss = 0.06236025274172425\n",
      " ---- 251 metric test_eval_f1 = 0.8020554817259297\n",
      " ---- 251 metric test_eval_time = 9.764090909090909\n",
      " ---- 251 metric incorrect_ood_test = 0.005909090909090909\n",
      " ---- 251 metric ood_eval = 0.7987535182951347\n",
      " ---- 251 metric ood_eval_time = 14.371733011660636\n",
      " ---- 252000 metric q_loss = 0.15956723114475607\n",
      " ---- 252000 metric hint_loss = 0.05908394578844309\n",
      " ---- 252 metric test_eval_f1 = 0.8151673572531591\n",
      " ---- 252 metric test_eval_time = 11.083181818181819\n",
      " ---- 252 metric incorrect_ood_test = 0.010454545454545454\n",
      " ---- 252 metric ood_eval = 0.778648974668275\n",
      " ---- 252 metric ood_eval_time = 14.360273421793325\n",
      " ---- 126 metric train_eval_f1 = 0.754241104586931\n",
      " ---- 126 metric train_eval_time = 11.577421555252387\n",
      " ---- 126 metric incorrect_ood_train = 0.021828103683492497\n",
      " ---- 253000 metric q_loss = 0.17516970824077727\n",
      " ---- 253000 metric hint_loss = 0.06526837845891714\n",
      " ---- 253 metric test_eval_f1 = 0.8028241978086675\n",
      " ---- 253 metric test_eval_time = 10.402727272727272\n",
      " ---- 253 metric incorrect_ood_test = 0.005909090909090909\n",
      " ---- 253 metric ood_eval = 0.7496984318455971\n",
      " ---- 253 metric ood_eval_time = 14.41837555287495\n",
      " ---- 254000 metric q_loss = 0.17206589255854488\n",
      " ---- 254000 metric hint_loss = 0.06962007820233702\n",
      " ---- 254 metric test_eval_f1 = 0.811419306770523\n",
      " ---- 254 metric test_eval_time = 11.966363636363637\n",
      " ---- 254 metric incorrect_ood_test = 0.013636363636363636\n",
      " ---- 254 metric ood_eval = 0.7891033373542421\n",
      " ---- 254 metric ood_eval_time = 14.573180538801768\n",
      " ---- 127 metric train_eval_f1 = 0.751849047505781\n",
      " ---- 127 metric train_eval_time = 12.170532060027286\n",
      " ---- 127 metric incorrect_ood_train = 0.02671668940427467\n",
      " ---- 255000 metric q_loss = 0.173982671584934\n",
      " ---- 255000 metric hint_loss = 0.0736232890933752\n",
      " ---- 255 metric test_eval_f1 = 0.8175494170522147\n",
      " ---- 255 metric test_eval_time = 11.073636363636364\n",
      " ---- 255 metric incorrect_ood_test = 0.008181818181818182\n",
      " ---- 255 metric ood_eval = 0.7977482911137918\n",
      " ---- 255 metric ood_eval_time = 14.395657418576599\n",
      " ---- 256000 metric q_loss = 0.1694217097274959\n",
      " ---- 256000 metric hint_loss = 0.06358434842899442\n",
      " ---- 256 metric test_eval_f1 = 0.8275468844234986\n",
      " ---- 256 metric test_eval_time = 10.891363636363636\n",
      " ---- 256 metric incorrect_ood_test = 0.010454545454545454\n",
      " ---- 256 metric ood_eval = 0.7834740651387213\n",
      " ---- 256 metric ood_eval_time = 14.462203457981504\n",
      " ---- 128 metric train_eval_f1 = 0.7529119889885845\n",
      " ---- 128 metric train_eval_time = 11.600841291496135\n",
      " ---- 128 metric incorrect_ood_train = 0.019326966803092316\n",
      " ---- 257000 metric q_loss = 0.1703565894216299\n",
      " ---- 257000 metric hint_loss = 0.056832848589867355\n",
      " ---- 257 metric test_eval_f1 = 0.8209104781413266\n",
      " ---- 257 metric test_eval_time = 9.960909090909091\n",
      " ---- 257 metric incorrect_ood_test = 0.008636363636363636\n",
      " ---- 257 metric ood_eval = 0.766184157619622\n",
      " ---- 257 metric ood_eval_time = 14.31926015279453\n",
      " ---- 258000 metric q_loss = 0.17217729003727436\n",
      " ---- 258000 metric hint_loss = 0.06917397288233042\n",
      " ---- 258 metric test_eval_f1 = 0.8147121891358318\n",
      " ---- 258 metric test_eval_time = 10.625\n",
      " ---- 258 metric incorrect_ood_test = 0.01090909090909091\n",
      " ---- 258 metric ood_eval = 0.759750703659027\n",
      " ---- 258 metric ood_eval_time = 14.344591877764374\n",
      " ---- 129 metric train_eval_f1 = 0.751028838656362\n",
      " ---- 129 metric train_eval_time = 11.225898135516143\n",
      " ---- 129 metric incorrect_ood_train = 0.022169167803547066\n",
      " ---- 259000 metric q_loss = 0.1641783796399832\n",
      " ---- 259000 metric hint_loss = 0.058898749876767395\n",
      " ---- 259 metric test_eval_f1 = 0.8179162362712635\n",
      " ---- 259 metric test_eval_time = 11.243181818181819\n",
      " ---- 259 metric incorrect_ood_test = 0.008181818181818182\n",
      " ---- 259 metric ood_eval = 0.747285886610374\n",
      " ---- 259 metric ood_eval_time = 14.341777241656615\n",
      " ---- 260000 metric q_loss = 0.16121179313585163\n",
      " ---- 260000 metric hint_loss = 0.05665187529847026\n",
      " ---- 260 metric test_eval_f1 = 0.8135293788551077\n",
      " ---- 260 metric test_eval_time = 10.38\n",
      " ---- 260 metric incorrect_ood_test = 0.005909090909090909\n",
      " ---- 260 metric ood_eval = 0.7376357056694813\n",
      " ---- 260 metric ood_eval_time = 14.333735424205871\n",
      " ---- 130 metric train_eval_f1 = 0.7569810754461304\n",
      " ---- 130 metric train_eval_time = 11.21487039563438\n",
      " ---- 130 metric incorrect_ood_train = 0.01455206912232833\n",
      " ---- 261000 metric q_loss = 0.15965270886942745\n",
      " ---- 261000 metric hint_loss = 0.05931143881008029\n",
      " ---- 261 metric test_eval_f1 = 0.8138895029685387\n",
      " ---- 261 metric test_eval_time = 10.485454545454546\n",
      " ---- 261 metric incorrect_ood_test = 0.007727272727272728\n",
      " ---- 261 metric ood_eval = 0.7810615199034981\n",
      " ---- 261 metric ood_eval_time = 14.352030558906312\n",
      " ---- 262000 metric q_loss = 0.1647954860702157\n",
      " ---- 262000 metric hint_loss = 0.06357427205517888\n",
      " ---- 262 metric test_eval_f1 = 0.8306898130611272\n",
      " ---- 262 metric test_eval_time = 11.389090909090909\n",
      " ---- 262 metric incorrect_ood_test = 0.00909090909090909\n",
      " ---- 262 metric ood_eval = 0.7758343385605146\n",
      " ---- 262 metric ood_eval_time = 14.390631282669883\n",
      " ---- 131 metric train_eval_f1 = 0.7594272426785071\n",
      " ---- 131 metric train_eval_time = 11.904388358344702\n",
      " ---- 131 metric incorrect_ood_train = 0.020122783083219645\n",
      " ---- 263000 metric q_loss = 0.1655145914927125\n",
      " ---- 263000 metric hint_loss = 0.06502686604857445\n",
      " ---- 263 metric test_eval_f1 = 0.8186149454441815\n",
      " ---- 263 metric test_eval_time = 10.859545454545454\n",
      " ---- 263 metric incorrect_ood_test = 0.006818181818181818\n",
      " ---- 263 metric ood_eval = 0.7655810213108163\n",
      " ---- 263 metric ood_eval_time = 14.44993968636912\n",
      " ---- 264000 metric q_loss = 0.16225973932817578\n",
      " ---- 264000 metric hint_loss = 0.06018936762213707\n",
      " ---- 264 metric test_eval_f1 = 0.8254705396095902\n",
      " ---- 264 metric test_eval_time = 9.874545454545455\n",
      " ---- 264 metric incorrect_ood_test = 0.008181818181818182\n",
      " ---- 264 metric ood_eval = 0.7579412947326095\n",
      " ---- 264 metric ood_eval_time = 14.248894250100523\n",
      " ---- 132 metric train_eval_f1 = 0.7534583907154171\n",
      " ---- 132 metric train_eval_time = 10.690541155070486\n",
      " ---- 132 metric incorrect_ood_train = 0.01398362892223738\n",
      " ---- 265000 metric q_loss = 0.16236476888507603\n",
      " ---- 265000 metric hint_loss = 0.06428020993992686\n",
      " ---- 265 metric test_eval_f1 = 0.8224846972365387\n",
      " ---- 265 metric test_eval_time = 10.561818181818182\n",
      " ---- 265 metric incorrect_ood_test = 0.005909090909090909\n",
      " ---- 265 metric ood_eval = 0.7245677523120225\n",
      " ---- 265 metric ood_eval_time = 14.328709288299155\n",
      " ---- 266000 metric q_loss = 0.1560426992289722\n",
      " ---- 266000 metric hint_loss = 0.05054036379978061\n",
      " ---- 266 metric test_eval_f1 = 0.8149192172536629\n",
      " ---- 266 metric test_eval_time = 10.319090909090908\n",
      " ---- 266 metric incorrect_ood_test = 0.006818181818181818\n",
      " ---- 266 metric ood_eval = 0.7476879774829112\n",
      " ---- 266 metric ood_eval_time = 14.376558102131082\n",
      " ---- 133 metric train_eval_f1 = 0.749803915272081\n",
      " ---- 133 metric train_eval_time = 10.915416098226467\n",
      " ---- 133 metric incorrect_ood_train = 0.009663483401546158\n",
      " ---- 267000 metric q_loss = 0.15495501149259508\n",
      " ---- 267000 metric hint_loss = 0.05999130574986339\n",
      " ---- 267 metric test_eval_f1 = 0.816315286300571\n",
      " ---- 267 metric test_eval_time = 11.805909090909092\n",
      " ---- 267 metric incorrect_ood_test = 0.005909090909090909\n",
      " ---- 267 metric ood_eval = 0.7965420184961801\n",
      " ---- 267 metric ood_eval_time = 14.547848813831926\n",
      " ---- 268000 metric q_loss = 0.15153444791212678\n",
      " ---- 268000 metric hint_loss = 0.05079581169039011\n",
      " ---- 268 metric test_eval_f1 = 0.8152957643147629\n",
      " ---- 268 metric test_eval_time = 10.682727272727274\n",
      " ---- 268 metric incorrect_ood_test = 0.01\n",
      " ---- 268 metric ood_eval = 0.7372336147969442\n",
      " ---- 268 metric ood_eval_time = 14.334137515078408\n",
      " ---- 134 metric train_eval_f1 = 0.7606618399911774\n",
      " ---- 134 metric train_eval_time = 11.344474761255116\n",
      " ---- 134 metric incorrect_ood_train = 0.016939517962710322\n",
      " ---- 269000 metric q_loss = 0.15624773709475995\n",
      " ---- 269000 metric hint_loss = 0.05597719429060817\n",
      " ---- 269 metric test_eval_f1 = 0.8282226909312699\n",
      " ---- 269 metric test_eval_time = 12.206363636363637\n",
      " ---- 269 metric incorrect_ood_test = 0.013181818181818182\n",
      " ---- 269 metric ood_eval = 0.7384398874145557\n",
      " ---- 269 metric ood_eval_time = 14.517691998391637\n",
      " ---- 270000 metric q_loss = 0.15956203436478972\n",
      " ---- 270000 metric hint_loss = 0.06351858301460743\n",
      " ---- 270 metric test_eval_f1 = 0.807472636194887\n",
      " ---- 270 metric test_eval_time = 10.341363636363637\n",
      " ---- 270 metric incorrect_ood_test = 0.01\n",
      " ---- 270 metric ood_eval = 0.7488942501005227\n",
      " ---- 270 metric ood_eval_time = 13.92983514274226\n",
      " ---- 135 metric train_eval_f1 = 0.7431813188267822\n",
      " ---- 135 metric train_eval_time = 10.918599363346976\n",
      " ---- 135 metric incorrect_ood_train = 0.016143701682582993\n",
      " ---- 271000 metric q_loss = 0.15624578267335892\n",
      " ---- 271000 metric hint_loss = 0.060133433934301136\n",
      " ---- 271 metric test_eval_f1 = 0.822065591280185\n",
      " ---- 271 metric test_eval_time = 10.612727272727273\n",
      " ---- 271 metric incorrect_ood_test = 0.007727272727272728\n",
      " ---- 271 metric ood_eval = 0.7973462002412546\n",
      " ---- 271 metric ood_eval_time = 14.404503417772416\n",
      " ---- 272000 metric q_loss = 0.1556665965989232\n",
      " ---- 272000 metric hint_loss = 0.05547310376167297\n",
      " ---- 272 metric test_eval_f1 = 0.813897976352446\n",
      " ---- 272 metric test_eval_time = 9.640454545454546\n",
      " ---- 272 metric incorrect_ood_test = 0.005909090909090909\n",
      " ---- 272 metric ood_eval = 0.7842782468837958\n",
      " ---- 272 metric ood_eval_time = 14.25774024929634\n",
      " ---- 136 metric train_eval_f1 = 0.7550074115814048\n",
      " ---- 136 metric train_eval_time = 10.555479763528878\n",
      " ---- 136 metric incorrect_ood_train = 0.01409731696225557\n",
      " ---- 273000 metric q_loss = 0.15386641523614525\n",
      " ---- 273000 metric hint_loss = 0.05668936190009117\n",
      " ---- 273 metric test_eval_f1 = 0.8273361681586467\n",
      " ---- 273 metric test_eval_time = 11.534090909090908\n",
      " ---- 273 metric incorrect_ood_test = 0.009545454545454546\n",
      " ---- 273 metric ood_eval = 0.8357458785685565\n",
      " ---- 273 metric ood_eval_time = 14.68335343787696\n",
      " ---- 274000 metric q_loss = 0.15870061304047703\n",
      " ---- 274000 metric hint_loss = 0.059537712156772615\n",
      " ---- 274 metric test_eval_f1 = 0.8240658767019338\n",
      " ---- 274 metric test_eval_time = 11.719090909090909\n",
      " ---- 274 metric incorrect_ood_test = 0.009545454545454546\n",
      " ---- 274 metric ood_eval = 0.8228789706473663\n",
      " ---- 274 metric ood_eval_time = 14.599919581825493\n",
      " ---- 137 metric train_eval_f1 = 0.748587699019221\n",
      " ---- 137 metric train_eval_time = 11.76261937244202\n",
      " ---- 137 metric incorrect_ood_train = 0.016484765802637562\n",
      " ---- 275000 metric q_loss = 0.1538662379719317\n",
      " ---- 275000 metric hint_loss = 0.05862917165085673\n",
      " ---- 275 metric test_eval_f1 = 0.8183205681332774\n",
      " ---- 275 metric test_eval_time = 10.562727272727273\n",
      " ---- 275 metric incorrect_ood_test = 0.008181818181818182\n",
      " ---- 275 metric ood_eval = 0.8176517893043828\n",
      " ---- 275 metric ood_eval_time = 14.452352231604342\n",
      " ---- 276000 metric q_loss = 0.15600110640004278\n",
      " ---- 276000 metric hint_loss = 0.06325151650607586\n",
      " ---- 276 metric test_eval_f1 = 0.8119050167440997\n",
      " ---- 276 metric test_eval_time = 11.248181818181818\n",
      " ---- 276 metric incorrect_ood_test = 0.009545454545454546\n",
      " ---- 276 metric ood_eval = 0.7750301568154403\n",
      " ---- 276 metric ood_eval_time = 14.47285886610374\n",
      " ---- 138 metric train_eval_f1 = 0.7534398667459574\n",
      " ---- 138 metric train_eval_time = 11.79081400636653\n",
      " ---- 138 metric incorrect_ood_train = 0.016030013642564803\n",
      " ---- 277000 metric q_loss = 0.14520505722612143\n",
      " ---- 277000 metric hint_loss = 0.050252168238162996\n",
      " ---- 277 metric test_eval_f1 = 0.8061913067733439\n",
      " ---- 277 metric test_eval_time = 9.871363636363636\n",
      " ---- 277 metric incorrect_ood_test = 0.011363636363636364\n",
      " ---- 277 metric ood_eval = 0.7563329312424608\n",
      " ---- 277 metric ood_eval_time = 14.265581021310815\n",
      " ---- 278000 metric q_loss = 0.1649199717864394\n",
      " ---- 278000 metric hint_loss = 0.07123338072001933\n",
      " ---- 278 metric test_eval_f1 = 0.8170944693850692\n",
      " ---- 278 metric test_eval_time = 11.088181818181818\n",
      " ---- 278 metric incorrect_ood_test = 0.01090909090909091\n",
      " ---- 278 metric ood_eval = 0.756735022114998\n",
      " ---- 278 metric ood_eval_time = 14.457378367511058\n",
      " ---- 139 metric train_eval_f1 = 0.755012929973709\n",
      " ---- 139 metric train_eval_time = 11.778422010004547\n",
      " ---- 139 metric incorrect_ood_train = 0.021714415643474306\n",
      " ---- 279000 metric q_loss = 0.1423167035728693\n",
      " ---- 279000 metric hint_loss = 0.04602967792376876\n",
      " ---- 279 metric test_eval_f1 = 0.7926220834396328\n",
      " ---- 279 metric test_eval_time = 11.18909090909091\n",
      " ---- 279 metric incorrect_ood_test = 0.009545454545454546\n",
      " ---- 279 metric ood_eval = 0.758745476477684\n",
      " ---- 279 metric ood_eval_time = 14.409127462806595\n",
      " ---- 280000 metric q_loss = 0.1703959169574082\n",
      " ---- 280000 metric hint_loss = 0.07687308950722217\n",
      " ---- 280 metric test_eval_f1 = 0.8215186876052876\n",
      " ---- 280 metric test_eval_time = 10.649545454545455\n",
      " ---- 280 metric incorrect_ood_test = 0.006818181818181818\n",
      " ---- 280 metric ood_eval = 0.8049859268194612\n",
      " ---- 280 metric ood_eval_time = 14.439686369119421\n",
      " ---- 140 metric train_eval_f1 = 0.7462197880495997\n",
      " ---- 140 metric train_eval_time = 11.201114142792179\n",
      " ---- 140 metric incorrect_ood_train = 0.01205093224192815\n",
      " ---- 281000 metric q_loss = 0.15100761637091636\n",
      " ---- 281000 metric hint_loss = 0.059677264872938396\n",
      " ---- 281 metric test_eval_f1 = 0.8171973496719359\n",
      " ---- 281 metric test_eval_time = 9.782727272727273\n",
      " ---- 281 metric incorrect_ood_test = 0.010454545454545454\n",
      " ---- 281 metric ood_eval = 0.8108162444712506\n",
      " ---- 281 metric ood_eval_time = 14.400482509047045\n",
      " ---- 282000 metric q_loss = 0.1574365386068821\n",
      " ---- 282000 metric hint_loss = 0.06505988087505102\n",
      " ---- 282 metric test_eval_f1 = 0.8214568439273715\n",
      " ---- 282 metric test_eval_time = 12.563636363636364\n",
      " ---- 282 metric incorrect_ood_test = 0.014090909090909091\n",
      " ---- 282 metric ood_eval = 0.837957378367511\n",
      " ---- 282 metric ood_eval_time = 14.525130679533575\n",
      " ---- 141 metric train_eval_f1 = 0.7527426447383928\n",
      " ---- 141 metric train_eval_time = 12.677012278308322\n",
      " ---- 141 metric incorrect_ood_train = 0.02853569804456571\n",
      " ---- 283000 metric q_loss = 0.1492432457730174\n",
      " ---- 283000 metric hint_loss = 0.05704897999018431\n",
      " ---- 283 metric test_eval_f1 = 0.7986419229443515\n",
      " ---- 283 metric test_eval_time = 11.263636363636364\n",
      " ---- 283 metric incorrect_ood_test = 0.01090909090909091\n",
      " ---- 283 metric ood_eval = 0.7764374748693205\n",
      " ---- 283 metric ood_eval_time = 14.52593486127865\n",
      " ---- 284000 metric q_loss = 0.14854317431151867\n",
      " ---- 284000 metric hint_loss = 0.05840271820500493\n",
      " ---- 284 metric test_eval_f1 = 0.8186348523756475\n",
      " ---- 284 metric test_eval_time = 10.629090909090909\n",
      " ---- 284 metric incorrect_ood_test = 0.011363636363636364\n",
      " ---- 284 metric ood_eval = 0.8558504221954162\n",
      " ---- 284 metric ood_eval_time = 14.553679131483715\n",
      " ---- 142 metric train_eval_f1 = 0.7643017750633156\n",
      " ---- 142 metric train_eval_time = 11.267735334242838\n",
      " ---- 142 metric incorrect_ood_train = 0.018985902683037743\n",
      " ---- 285000 metric q_loss = 0.14627925663441418\n",
      " ---- 285000 metric hint_loss = 0.0611122724339366\n",
      " ---- 285 metric test_eval_f1 = 0.8235334327855036\n",
      " ---- 285 metric test_eval_time = 9.920454545454545\n",
      " ---- 285 metric incorrect_ood_test = 0.006818181818181818\n",
      " ---- 285 metric ood_eval = 0.7378367511057499\n",
      " ---- 285 metric ood_eval_time = 14.41133896260555\n",
      " ---- 286000 metric q_loss = 0.14285086811333894\n",
      " ---- 286000 metric hint_loss = 0.051287005577236415\n",
      " ---- 286 metric test_eval_f1 = 0.8149761611137982\n",
      " ---- 286 metric test_eval_time = 11.36590909090909\n",
      " ---- 286 metric incorrect_ood_test = 0.008181818181818182\n",
      " ---- 286 metric ood_eval = 0.7770406111781263\n",
      " ---- 286 metric ood_eval_time = 14.470848411741054\n",
      " ---- 143 metric train_eval_f1 = 0.7509988610200155\n",
      " ---- 143 metric train_eval_time = 11.794110959527059\n",
      " ---- 143 metric incorrect_ood_train = 0.022510231923601638\n",
      " ---- 287000 metric q_loss = 0.15479876075312496\n",
      " ---- 287000 metric hint_loss = 0.061694926377385856\n",
      " ---- 287 metric test_eval_f1 = 0.8197117585267112\n",
      " ---- 287 metric test_eval_time = 10.097272727272728\n",
      " ---- 287 metric incorrect_ood_test = 0.008181818181818182\n",
      " ---- 287 metric ood_eval = 0.8007639726578206\n",
      " ---- 287 metric ood_eval_time = 14.416566143948533\n",
      " ---- 288000 metric q_loss = 0.14134887049905956\n",
      " ---- 288000 metric hint_loss = 0.050814749501645565\n",
      " ---- 288 metric test_eval_f1 = 0.8181285754772692\n",
      " ---- 288 metric test_eval_time = 10.284545454545455\n",
      " ---- 288 metric incorrect_ood_test = 0.007272727272727273\n",
      " ---- 288 metric ood_eval = 0.7983514274225975\n",
      " ---- 288 metric ood_eval_time = 14.375150784077201\n",
      " ---- 144 metric train_eval_f1 = 0.7614867370993449\n",
      " ---- 144 metric train_eval_time = 10.96725784447476\n",
      " ---- 144 metric incorrect_ood_train = 0.01227830832196453\n",
      " ---- 289000 metric q_loss = 0.149702226344496\n",
      " ---- 289000 metric hint_loss = 0.05777759959548712\n",
      " ---- 289 metric test_eval_f1 = 0.8226215336475267\n",
      " ---- 289 metric test_eval_time = 11.342272727272727\n",
      " ---- 289 metric incorrect_ood_test = 0.013636363636363636\n",
      " ---- 289 metric ood_eval = 0.7913148371531966\n",
      " ---- 289 metric ood_eval_time = 14.44853236831524\n",
      " ---- 290000 metric q_loss = 0.13324591118656098\n",
      " ---- 290000 metric hint_loss = 0.04126636698096991\n",
      " ---- 290 metric test_eval_f1 = 0.8226411390242483\n",
      " ---- 290 metric test_eval_time = 10.804545454545455\n",
      " ---- 290 metric incorrect_ood_test = 0.00909090909090909\n",
      " ---- 290 metric ood_eval = 0.8088057901085646\n",
      " ---- 290 metric ood_eval_time = 14.507639726578207\n",
      " ---- 145 metric train_eval_f1 = 0.759987680487798\n",
      " ---- 145 metric train_eval_time = 11.351182355616189\n",
      " ---- 145 metric incorrect_ood_train = 0.019554342883128694\n",
      " ---- 291000 metric q_loss = 0.13923927276954054\n",
      " ---- 291000 metric hint_loss = 0.05559810996800661\n",
      " ---- 291 metric test_eval_f1 = 0.8171320556101684\n",
      " ---- 291 metric test_eval_time = 9.99090909090909\n",
      " ---- 291 metric incorrect_ood_test = 0.005\n",
      " ---- 291 metric ood_eval = 0.7486932046642542\n",
      " ---- 291 metric ood_eval_time = 14.345597104945718\n",
      " ---- 292000 metric q_loss = 0.14403139279037713\n",
      " ---- 292000 metric hint_loss = 0.062142125017940995\n",
      " ---- 292 metric test_eval_f1 = 0.8220863385653513\n",
      " ---- 292 metric test_eval_time = 11.037727272727272\n",
      " ---- 292 metric incorrect_ood_test = 0.013181818181818182\n",
      " ---- 292 metric ood_eval = 0.8455971049457177\n",
      " ---- 292 metric ood_eval_time = 14.509851226377162\n",
      " ---- 146 metric train_eval_f1 = 0.7628620957026331\n",
      " ---- 146 metric train_eval_time = 11.556048203728968\n",
      " ---- 146 metric incorrect_ood_train = 0.02205547976352888\n",
      " ---- 293000 metric q_loss = 0.15018280971050263\n",
      " ---- 293000 metric hint_loss = 0.06684306599572301\n",
      " ---- 293 metric test_eval_f1 = 0.8202987449995907\n",
      " ---- 293 metric test_eval_time = 12.084545454545454\n",
      " ---- 293 metric incorrect_ood_test = 0.011363636363636364\n",
      " ---- 293 metric ood_eval = 0.7862887012464818\n",
      " ---- 293 metric ood_eval_time = 14.55870526739043\n",
      " ---- 294000 metric q_loss = 0.1621550239883363\n",
      " ---- 294000 metric hint_loss = 0.07869968281686306\n",
      " ---- 294 metric test_eval_f1 = 0.8187657188233523\n",
      " ---- 294 metric test_eval_time = 10.75590909090909\n",
      " ---- 294 metric incorrect_ood_test = 0.011363636363636364\n",
      " ---- 294 metric ood_eval = 0.7625653397667873\n",
      " ---- 294 metric ood_eval_time = 14.388821873743465\n",
      " ---- 147 metric train_eval_f1 = 0.7500582749685223\n",
      " ---- 147 metric train_eval_time = 11.336516598453843\n",
      " ---- 147 metric incorrect_ood_train = 0.018985902683037743\n",
      " ---- 295000 metric q_loss = 0.14392205475643277\n",
      " ---- 295000 metric hint_loss = 0.06042872985824942\n",
      " ---- 295 metric test_eval_f1 = 0.8259863760245598\n",
      " ---- 295 metric test_eval_time = 9.723181818181818\n",
      " ---- 295 metric incorrect_ood_test = 0.006818181818181818\n",
      " ---- 295 metric ood_eval = 0.7929232006433454\n",
      " ---- 295 metric ood_eval_time = 14.326296743063933\n",
      " ---- 296000 metric q_loss = 0.14572613608650864\n",
      " ---- 296000 metric hint_loss = 0.06504506043344736\n",
      " ---- 296 metric test_eval_f1 = 0.8138630994641681\n",
      " ---- 296 metric test_eval_time = 11.477727272727273\n",
      " ---- 296 metric incorrect_ood_test = 0.01681818181818182\n",
      " ---- 296 metric ood_eval = 0.8134298351427423\n",
      " ---- 296 metric ood_eval_time = 14.381986328910333\n",
      " ---- 148 metric train_eval_f1 = 0.7575927358700612\n",
      " ---- 148 metric train_eval_time = 12.029217826284675\n",
      " ---- 148 metric incorrect_ood_train = 0.025352432924056388\n",
      " ---- 297000 metric q_loss = 0.15175873659178615\n",
      " ---- 297000 metric hint_loss = 0.06207641364634037\n",
      " ---- 297 metric test_eval_f1 = 0.8100837006632186\n",
      " ---- 297 metric test_eval_time = 10.15090909090909\n",
      " ---- 297 metric incorrect_ood_test = 0.008181818181818182\n",
      " ---- 297 metric ood_eval = 0.7667872939284278\n",
      " ---- 297 metric ood_eval_time = 14.428025733815842\n",
      " ---- 298000 metric q_loss = 0.13466132851317525\n",
      " ---- 298000 metric hint_loss = 0.04210658787190914\n",
      " ---- 298 metric test_eval_f1 = 0.8222467815413972\n",
      " ---- 298 metric test_eval_time = 10.397272727272727\n",
      " ---- 298 metric incorrect_ood_test = 0.011818181818181818\n",
      " ---- 298 metric ood_eval = 0.7386409328508243\n",
      " ---- 298 metric ood_eval_time = 14.410132689987938\n",
      " ---- 149 metric train_eval_f1 = 0.7535779548505119\n",
      " ---- 149 metric train_eval_time = 11.020009095043202\n",
      " ---- 149 metric incorrect_ood_train = 0.017053206002728513\n",
      " ---- 299000 metric q_loss = 0.13677934682369233\n",
      " ---- 299000 metric hint_loss = 0.05199546752125025\n",
      " ---- 299 metric test_eval_f1 = 0.8254936693338277\n",
      " ---- 299 metric test_eval_time = 10.698636363636364\n",
      " ---- 299 metric incorrect_ood_test = 0.008181818181818182\n",
      " ---- 299 metric ood_eval = 0.7657820667470848\n",
      " ---- 299 metric ood_eval_time = 14.357056694813028\n",
      " ---- 300000 metric q_loss = 0.1309995074328035\n",
      " ---- 300000 metric hint_loss = 0.048323126774281265\n",
      " ---- 300 metric test_eval_f1 = 0.809315917619309\n",
      " ---- 300 metric test_eval_time = 10.984545454545454\n",
      " ---- 300 metric incorrect_ood_test = 0.009545454545454546\n",
      " ---- 300 metric ood_eval = 0.740249296340973\n",
      " ---- 300 metric ood_eval_time = 14.34519501407318\n",
      " ---- 150 metric train_eval_f1 = 0.7521040081568645\n",
      " ---- 150 metric train_eval_time = 11.446907685311505\n",
      " ---- 150 metric incorrect_ood_train = 0.01352887676216462\n",
      " ---- 301000 metric q_loss = 0.1317966968175024\n",
      " ---- 301000 metric hint_loss = 0.046870214130729435\n",
      " ---- 301 metric test_eval_f1 = 0.8279465976026518\n",
      " ---- 301 metric test_eval_time = 10.911818181818182\n",
      " ---- 301 metric incorrect_ood_test = 0.012727272727272728\n",
      " ---- 301 metric ood_eval = 0.791113791716928\n",
      " ---- 301 metric ood_eval_time = 14.527543224768797\n",
      " ---- 302000 metric q_loss = 0.15046492847055196\n",
      " ---- 302000 metric hint_loss = 0.06699131457507611\n",
      " ---- 302 metric test_eval_f1 = 0.8307788450373391\n",
      " ---- 302 metric test_eval_time = 10.923636363636364\n",
      " ---- 302 metric incorrect_ood_test = 0.012727272727272728\n",
      " ---- 302 metric ood_eval = 0.7766385203055891\n",
      " ---- 302 metric ood_eval_time = 14.403699236027343\n",
      " ---- 151 metric train_eval_f1 = 0.757675331379729\n",
      " ---- 151 metric train_eval_time = 11.431218735788995\n",
      " ---- 151 metric incorrect_ood_train = 0.020350159163256026\n",
      " ---- 303000 metric q_loss = 0.13441521169431508\n",
      " ---- 303000 metric hint_loss = 0.0513111587651074\n",
      " ---- 303 metric test_eval_f1 = 0.8263599188378895\n",
      " ---- 303 metric test_eval_time = 11.983181818181817\n",
      " ---- 303 metric incorrect_ood_test = 0.011818181818181818\n",
      " ---- 303 metric ood_eval = 0.7460796139927623\n",
      " ---- 303 metric ood_eval_time = 14.562726176115802\n",
      " ---- 304000 metric q_loss = 0.13591115044243635\n",
      " ---- 304000 metric hint_loss = 0.05201653460413218\n",
      " ---- 304 metric test_eval_f1 = 0.8218614358183366\n",
      " ---- 304 metric test_eval_time = 10.86909090909091\n",
      " ---- 304 metric incorrect_ood_test = 0.01090909090909091\n",
      " ---- 304 metric ood_eval = 0.7738238841978287\n",
      " ---- 304 metric ood_eval_time = 14.44270205066345\n",
      " ---- 152 metric train_eval_f1 = 0.752146632217981\n",
      " ---- 152 metric train_eval_time = 11.597203274215552\n",
      " ---- 152 metric incorrect_ood_train = 0.018190086402910415\n",
      " ---- 305000 metric q_loss = 0.15041285721957684\n",
      " ---- 305000 metric hint_loss = 0.07371902210265398\n",
      " ---- 305 metric test_eval_f1 = 0.8277350412117207\n",
      " ---- 305 metric test_eval_time = 11.695\n",
      " ---- 305 metric incorrect_ood_test = 0.011818181818181818\n",
      " ---- 305 metric ood_eval = 0.7989545637314033\n",
      " ---- 305 metric ood_eval_time = 14.543425814234016\n",
      " ---- 306000 metric q_loss = 0.1309712717421353\n",
      " ---- 306000 metric hint_loss = 0.046260834094136956\n",
      " ---- 306 metric test_eval_f1 = 0.8209579530447256\n",
      " ---- 306 metric test_eval_time = 9.703181818181818\n",
      " ---- 306 metric incorrect_ood_test = 0.010454545454545454\n",
      " ---- 306 metric ood_eval = 0.8325291515882589\n",
      " ---- 306 metric ood_eval_time = 14.422396461600322\n",
      " ---- 153 metric train_eval_f1 = 0.7541488615164311\n",
      " ---- 153 metric train_eval_time = 10.703615279672578\n",
      " ---- 153 metric incorrect_ood_train = 0.014211005002273762\n",
      " ---- 307000 metric q_loss = 0.1312506125718355\n",
      " ---- 307000 metric hint_loss = 0.05320410760119557\n",
      " ---- 307 metric test_eval_f1 = 0.8134989195604766\n",
      " ---- 307 metric test_eval_time = 10.56\n",
      " ---- 307 metric incorrect_ood_test = 0.009545454545454546\n",
      " ---- 307 metric ood_eval = 0.765178930438279\n",
      " ---- 307 metric ood_eval_time = 14.407720144752714\n",
      " ---- 308000 metric q_loss = 0.1347856540773064\n",
      " ---- 308000 metric hint_loss = 0.051996032413095236\n",
      " ---- 308 metric test_eval_f1 = 0.8281134049405751\n",
      " ---- 308 metric test_eval_time = 10.19\n",
      " ---- 308 metric incorrect_ood_test = 0.012272727272727272\n",
      " ---- 308 metric ood_eval = 0.7919179734620024\n",
      " ---- 308 metric ood_eval_time = 14.406111781262565\n",
      " ---- 154 metric train_eval_f1 = 0.7657154755453845\n",
      " ---- 154 metric train_eval_time = 10.97555707139609\n",
      " ---- 154 metric incorrect_ood_train = 0.016939517962710322\n",
      " ---- 309000 metric q_loss = 0.12659991540759802\n",
      " ---- 309000 metric hint_loss = 0.044246840432286265\n",
      " ---- 309 metric test_eval_f1 = 0.8141317216123092\n",
      " ---- 309 metric test_eval_time = 11.140454545454546\n",
      " ---- 309 metric incorrect_ood_test = 0.016363636363636365\n",
      " ---- 309 metric ood_eval = 0.8080016083634901\n",
      " ---- 309 metric ood_eval_time = 14.493365500603137\n",
      " ---- 310000 metric q_loss = 0.13833575777150692\n",
      " ---- 310000 metric hint_loss = 0.063070819362998\n",
      " ---- 310 metric test_eval_f1 = 0.8291464354203234\n",
      " ---- 310 metric test_eval_time = 11.034545454545455\n",
      " ---- 310 metric incorrect_ood_test = 0.022727272727272728\n",
      " ---- 310 metric ood_eval = 0.7844792923200643\n",
      " ---- 310 metric ood_eval_time = 14.439083232810615\n",
      " ---- 155 metric train_eval_f1 = 0.7566999413077997\n",
      " ---- 155 metric train_eval_time = 11.734538426557526\n",
      " ---- 155 metric incorrect_ood_train = 0.03228740336516599\n",
      " ---- 311000 metric q_loss = 0.14266178159601986\n",
      " ---- 311000 metric hint_loss = 0.06803486650437117\n",
      " ---- 311 metric test_eval_f1 = 0.8238970174790992\n",
      " ---- 311 metric test_eval_time = 10.707727272727272\n",
      " ---- 311 metric incorrect_ood_test = 0.011818181818181818\n",
      " ---- 311 metric ood_eval = 0.7074788902291917\n",
      " ---- 311 metric ood_eval_time = 14.432247687977483\n",
      " ---- 312000 metric q_loss = 0.13944311718642713\n",
      " ---- 312000 metric hint_loss = 0.057566964879632\n",
      " ---- 312 metric test_eval_f1 = 0.8152174715940077\n",
      " ---- 312 metric test_eval_time = 11.602272727272727\n",
      " ---- 312 metric incorrect_ood_test = 0.03\n",
      " ---- 312 metric ood_eval = 0.7925211097708083\n",
      " ---- 312 metric ood_eval_time = 14.486328910333736\n",
      " ---- 156 metric train_eval_f1 = 0.7483084093855776\n",
      " ---- 156 metric train_eval_time = 11.831400636653024\n",
      " ---- 156 metric incorrect_ood_train = 0.0286493860845839\n",
      " ---- 313000 metric q_loss = 0.1305839217081666\n",
      " ---- 313000 metric hint_loss = 0.05579580780491233\n",
      " ---- 313 metric test_eval_f1 = 0.8032839012059175\n",
      " ---- 313 metric test_eval_time = 13.11590909090909\n",
      " ---- 313 metric incorrect_ood_test = 0.03363636363636364\n",
      " ---- 313 metric ood_eval = 0.7878970647366305\n",
      " ---- 313 metric ood_eval_time = 14.79533574587857\n",
      " ---- 314000 metric q_loss = 0.1592273192293942\n",
      " ---- 314000 metric hint_loss = 0.08459045811742544\n",
      " ---- 314 metric test_eval_f1 = 0.82419742525381\n",
      " ---- 314 metric test_eval_time = 10.256363636363636\n",
      " ---- 314 metric incorrect_ood_test = 0.010454545454545454\n",
      " ---- 314 metric ood_eval = 0.7655810213108163\n",
      " ---- 314 metric ood_eval_time = 14.452352231604342\n",
      " ---- 157 metric train_eval_f1 = 0.7530351905675515\n",
      " ---- 157 metric train_eval_time = 11.03149158708504\n",
      " ---- 157 metric incorrect_ood_train = 0.015347885402455661\n",
      " ---- 315000 metric q_loss = 0.14669773504137992\n",
      " ---- 315000 metric hint_loss = 0.06881015650555491\n",
      " ---- 315 metric test_eval_f1 = 0.7971011475800136\n",
      " ---- 315 metric test_eval_time = 11.398636363636363\n",
      " ---- 315 metric incorrect_ood_test = 0.017272727272727273\n",
      " ---- 315 metric ood_eval = 0.7143144350623241\n",
      " ---- 315 metric ood_eval_time = 14.450542822677924\n",
      " ---- 316000 metric q_loss = 0.15557491258345543\n",
      " ---- 316000 metric hint_loss = 0.0828257684931159\n",
      " ---- 316 metric test_eval_f1 = 0.8057240786876558\n",
      " ---- 316 metric test_eval_time = 9.452272727272728\n",
      " ---- 316 metric incorrect_ood_test = 0.008636363636363636\n",
      " ---- 316 metric ood_eval = 0.7655810213108163\n",
      " ---- 316 metric ood_eval_time = 14.377764374748693\n",
      " ---- 158 metric train_eval_f1 = 0.739958709726462\n",
      " ---- 158 metric train_eval_time = 10.482037289677127\n",
      " ---- 158 metric incorrect_ood_train = 0.01398362892223738\n",
      " ---- 317000 metric q_loss = 0.13391234842315317\n",
      " ---- 317000 metric hint_loss = 0.060484241113066675\n",
      " ---- 317 metric test_eval_f1 = 0.829945752785446\n",
      " ---- 317 metric test_eval_time = 10.337272727272728\n",
      " ---- 317 metric incorrect_ood_test = 0.010454545454545454\n",
      " ---- 317 metric ood_eval = 0.743264977885002\n",
      " ---- 317 metric ood_eval_time = 14.430237233614797\n",
      " ---- 318000 metric q_loss = 0.1331035664230585\n",
      " ---- 318000 metric hint_loss = 0.05195562769472599\n",
      " ---- 318 metric test_eval_f1 = 0.8135881178085698\n",
      " ---- 318 metric test_eval_time = 11.838636363636363\n",
      " ---- 318 metric incorrect_ood_test = 0.017272727272727273\n",
      " ---- 318 metric ood_eval = 0.7949336550060314\n",
      " ---- 318 metric ood_eval_time = 14.482911137917169\n",
      " ---- 159 metric train_eval_f1 = 0.7553563405479196\n",
      " ---- 159 metric train_eval_time = 12.358458390177354\n",
      " ---- 159 metric incorrect_ood_train = 0.02648931332423829\n",
      " ---- 319000 metric q_loss = 0.1318239935208112\n",
      " ---- 319000 metric hint_loss = 0.0556209414601326\n",
      " ---- 319 metric test_eval_f1 = 0.8204731685908299\n",
      " ---- 319 metric test_eval_time = 10.214545454545455\n",
      " ---- 319 metric incorrect_ood_test = 0.010454545454545454\n",
      " ---- 319 metric ood_eval = 0.7096903900281464\n",
      " ---- 319 metric ood_eval_time = 14.34097305991154\n",
      " ---- 320000 metric q_loss = 0.1273261538669467\n",
      " ---- 320000 metric hint_loss = 0.05302556066587567\n",
      " ---- 320 metric test_eval_f1 = 0.820637556117566\n",
      " ---- 320 metric test_eval_time = 9.90090909090909\n",
      " ---- 320 metric incorrect_ood_test = 0.011363636363636364\n",
      " ---- 320 metric ood_eval = 0.7917169280257338\n",
      " ---- 320 metric ood_eval_time = 14.40691596300764\n",
      " ---- 160 metric train_eval_f1 = 0.7478203390203751\n",
      " ---- 160 metric train_eval_time = 10.962141882673942\n",
      " ---- 160 metric incorrect_ood_train = 0.016939517962710322\n",
      " ---- 321000 metric q_loss = 0.13114788521267473\n",
      " ---- 321000 metric hint_loss = 0.05259027713537216\n",
      " ---- 321 metric test_eval_f1 = 0.7996646437201733\n",
      " ---- 321 metric test_eval_time = 12.532727272727273\n",
      " ---- 321 metric incorrect_ood_test = 0.014545454545454545\n",
      " ---- 321 metric ood_eval = 0.8192601527945316\n",
      " ---- 321 metric ood_eval_time = 14.568355448331323\n",
      " ---- 322000 metric q_loss = 0.12701133432984352\n",
      " ---- 322000 metric hint_loss = 0.045020139049738644\n",
      " ---- 322 metric test_eval_f1 = 0.8153477614797612\n",
      " ---- 322 metric test_eval_time = 10.955\n",
      " ---- 322 metric incorrect_ood_test = 0.014545454545454545\n",
      " ---- 322 metric ood_eval = 0.8214716525934861\n",
      " ---- 322 metric ood_eval_time = 14.474266184157619\n",
      " ---- 161 metric train_eval_f1 = 0.7568762353057977\n",
      " ---- 161 metric train_eval_time = 11.679740791268758\n",
      " ---- 161 metric incorrect_ood_train = 0.02660300136425648\n",
      " ---- 323000 metric q_loss = 0.13591807020455599\n",
      " ---- 323000 metric hint_loss = 0.06287865836173295\n",
      " ---- 323 metric test_eval_f1 = 0.8142746704880571\n",
      " ---- 323 metric test_eval_time = 11.614090909090908\n",
      " ---- 323 metric incorrect_ood_test = 0.015454545454545455\n",
      " ---- 323 metric ood_eval = 0.7878970647366305\n",
      " ---- 323 metric ood_eval_time = 14.506433453960595\n",
      " ---- 324000 metric q_loss = 0.13006544880010187\n",
      " ---- 324000 metric hint_loss = 0.0565661286637187\n",
      " ---- 324 metric test_eval_f1 = 0.8100980702473378\n",
      " ---- 324 metric test_eval_time = 10.880454545454546\n",
      " ---- 324 metric incorrect_ood_test = 0.012727272727272728\n",
      " ---- 324 metric ood_eval = 0.8341375150784077\n",
      " ---- 324 metric ood_eval_time = 14.503216726980298\n",
      " ---- 162 metric train_eval_f1 = 0.7486313840233325\n",
      " ---- 162 metric train_eval_time = 11.552182810368349\n",
      " ---- 162 metric incorrect_ood_train = 0.02773988176443838\n",
      " ---- 325000 metric q_loss = 0.13656315241754055\n",
      " ---- 325000 metric hint_loss = 0.06174953231960535\n",
      " ---- 325 metric test_eval_f1 = 0.815415864161375\n",
      " ---- 325 metric test_eval_time = 10.670909090909092\n",
      " ---- 325 metric incorrect_ood_test = 0.006363636363636364\n",
      " ---- 325 metric ood_eval = 0.7488942501005227\n",
      " ---- 325 metric ood_eval_time = 14.302774427020507\n",
      " ---- 326000 metric q_loss = 0.1452233422640711\n",
      " ---- 326000 metric hint_loss = 0.07252322294935584\n",
      " ---- 326 metric test_eval_f1 = 0.8256809177350303\n",
      " ---- 326 metric test_eval_time = 11.44909090909091\n",
      " ---- 326 metric incorrect_ood_test = 0.014545454545454545\n",
      " ---- 326 metric ood_eval = 0.7955367913148371\n",
      " ---- 326 metric ood_eval_time = 14.547848813831926\n",
      " ---- 163 metric train_eval_f1 = 0.7635798230042611\n",
      " ---- 163 metric train_eval_time = 11.901659845384266\n",
      " ---- 163 metric incorrect_ood_train = 0.024215552523874487\n",
      " ---- 327000 metric q_loss = 0.13661506605148316\n",
      " ---- 327000 metric hint_loss = 0.05924759608507156\n",
      " ---- 327 metric test_eval_f1 = 0.8343719578534892\n",
      " ---- 327 metric test_eval_time = 11.293181818181818\n",
      " ---- 327 metric incorrect_ood_test = 0.015\n",
      " ---- 327 metric ood_eval = 0.8132287897064736\n",
      " ---- 327 metric ood_eval_time = 14.502412545235224\n",
      " ---- 328000 metric q_loss = 0.12507828874513507\n",
      " ---- 328000 metric hint_loss = 0.044707641802728175\n",
      " ---- 328 metric test_eval_f1 = 0.8288295486732004\n",
      " ---- 328 metric test_eval_time = 10.08\n",
      " ---- 328 metric incorrect_ood_test = 0.01\n",
      " ---- 328 metric ood_eval = 0.741254523522316\n",
      " ---- 328 metric ood_eval_time = 14.31523924406916\n",
      " ---- 164 metric train_eval_f1 = 0.7562976603415043\n",
      " ---- 164 metric train_eval_time = 10.792405638926786\n",
      " ---- 164 metric incorrect_ood_train = 0.015575261482492041\n",
      " ---- 329000 metric q_loss = 0.13581437965482474\n",
      " ---- 329000 metric hint_loss = 0.06037907766550779\n",
      " ---- 329 metric test_eval_f1 = 0.82633493636199\n",
      " ---- 329 metric test_eval_time = 10.189545454545454\n",
      " ---- 329 metric incorrect_ood_test = 0.011818181818181818\n",
      " ---- 329 metric ood_eval = 0.7613590671491757\n",
      " ---- 329 metric ood_eval_time = 14.395054282267793\n",
      " ---- 330000 metric q_loss = 0.13438653082028032\n",
      " ---- 330000 metric hint_loss = 0.059112122882157565\n",
      " ---- 330 metric test_eval_f1 = 0.8060869651314037\n",
      " ---- 330 metric test_eval_time = 9.873636363636363\n",
      " ---- 330 metric incorrect_ood_test = 0.01090909090909091\n",
      " ---- 330 metric ood_eval = 0.7746280659429031\n",
      " ---- 330 metric ood_eval_time = 14.341978287092884\n",
      " ---- 165 metric train_eval_f1 = 0.753454810099639\n",
      " ---- 165 metric train_eval_time = 10.767735334242838\n",
      " ---- 165 metric incorrect_ood_train = 0.018758526603001365\n",
      " ---- 331000 metric q_loss = 0.12510492475144566\n",
      " ---- 331000 metric hint_loss = 0.05076485130190849\n",
      " ---- 331 metric test_eval_f1 = 0.8196927660801979\n",
      " ---- 331 metric test_eval_time = 11.129090909090909\n",
      " ---- 331 metric incorrect_ood_test = 0.011818181818181818\n",
      " ---- 331 metric ood_eval = 0.7657820667470848\n",
      " ---- 331 metric ood_eval_time = 14.43425814234017\n",
      " ---- 332000 metric q_loss = 0.12064085119217634\n",
      " ---- 332000 metric hint_loss = 0.04907252490520477\n",
      " ---- 332 metric test_eval_f1 = 0.8264695806952982\n",
      " ---- 332 metric test_eval_time = 11.02\n",
      " ---- 332 metric incorrect_ood_test = 0.018636363636363635\n",
      " ---- 332 metric ood_eval = 0.8021712907117008\n",
      " ---- 332 metric ood_eval_time = 14.434459187776438\n",
      " ---- 166 metric train_eval_f1 = 0.7595604322038564\n",
      " ---- 166 metric train_eval_time = 11.488972260118235\n",
      " ---- 166 metric incorrect_ood_train = 0.02467030468394725\n"
     ]
    }
   ],
   "source": [
    "ddq_model.train(epochs= 20,batch_size= 128,lr= .0003,lam= .99) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "documenter = Documenter(train_dataset= train_dataset,test_dataset= test_dataset, ood_dataset= ood_dataset,full_model= classification_trainer.best[\"model\"], early_model= ddq_model.best[\"model\"],\n",
    "                        configs= configs\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "documenter.document(name= configs[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'micro_f1': 0.8836363636363637,\n",
       " 'macro_f1': 0.8103467652435339,\n",
       " 'accuracy': 0.8836363636363637,\n",
       " 'cm': array([[191,   1,   3,   0,   6,  35,   5,   0,   0,   0],\n",
       "        [  0, 408,   0,   1,   4,   2,   0,   0,   2,   0],\n",
       "        [  0,   3, 159,   1,   2,   0,   2,   1,   0,   3],\n",
       "        [  0,   1,   1, 168,   2,   0,   2,   0,   0,   0],\n",
       "        [  0,  15,   0,   1, 280,  11,   4,   1,   1,   6],\n",
       "        [ 15,   5,   0,   2,   5, 255,   1,   0,   0,   0],\n",
       "        [  1,   4,   0,   1,  37,   2, 204,   0,   3,   4],\n",
       "        [  0,   1,   0,   0,   0,   1,   0,  66,   0,   0],\n",
       "        [  0,  14,   0,   2,   0,   0,   0,   0,  68,   0],\n",
       "        [  0,   1,   7,   0,   6,   0,   1,   4,   0, 145]]),\n",
       " 'incorrect_ood': 0.010454545454545454,\n",
       " 'time': 11.312272727272727,\n",
       " 'ood_accuracy': 0.779654201849618,\n",
       " 'ood_time': 14.231202251708886}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EarlyEvaluation(min_steps= 5,device= device,model= ddq_model.predictor).getMetrices(dataset= test_dataset, ood_dataset= ood_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'micro_f1': 0.9040909090909091,\n",
       " 'macro_f1': 0.8343719578534892,\n",
       " 'accuracy': 0.9040909090909091,\n",
       " 'cm': array([[204,   1,   0,   0,   9,  23,   3,   0,   0,   0],\n",
       "        [  1, 404,   0,   1,   8,   2,   0,   0,   0,   0],\n",
       "        [  0,   1, 160,   1,   7,   0,   1,   0,   0,   1],\n",
       "        [  0,   1,   0, 170,   1,   0,   1,   0,   0,   0],\n",
       "        [  1,   2,   2,   0, 297,   9,   2,   1,   0,   3],\n",
       "        [ 11,   0,   1,   2,   9, 259,   0,   0,   0,   0],\n",
       "        [  0,   1,   0,   1,  39,   2, 206,   0,   1,   3],\n",
       "        [  0,   0,   0,   1,   0,   1,   0,  65,   0,   0],\n",
       "        [  0,   0,   0,   3,   1,   0,   0,   0,  80,   0],\n",
       "        [  0,   0,   2,   0,  13,   0,   1,   4,   0, 144]]),\n",
       " 'incorrect_ood': 0.015,\n",
       " 'time': 11.293181818181818,\n",
       " 'ood_accuracy': 0.8132287897064736,\n",
       " 'ood_time': 14.502412545235224}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EarlyEvaluation(min_steps= 5,device= device,model= ddq_model.best[\"model\"]).getMetrices(dataset= test_dataset,ood_dataset= ood_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x74878ae2de40>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(logger.getMetric(\"test_eval_f1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mddq_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m res\n",
      "File \u001b[0;32m~/Desktop/UNSW/flowprintOptimal/sekigo/earlyClassification/DQL/trainers.py:153\u001b[0m, in \u001b[0;36mEarlyClassificationtrainer.eval\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval\u001b[39m(\u001b[38;5;28mself\u001b[39m,dataset : BaseFlowDataset):\n\u001b[0;32m--> 153\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictOnDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x : x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m], dataset))\n\u001b[1;32m    156\u001b[0m     predicted_labels,time \u001b[38;5;241m=\u001b[39m [],[]\n",
      "File \u001b[0;32m~/Desktop/UNSW/flowprintOptimal/sekigo/earlyClassification/DQL/trainers.py:140\u001b[0m, in \u001b[0;36mEarlyClassificationtrainer.predictOnDataset\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    138\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m--> 140\u001b[0m     batch_X,batch_y \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    141\u001b[0m     predicted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictStep(batch_X \u001b[38;5;241m=\u001b[39m batch_X)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;66;03m# (BS,seq_len)\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     processed_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__processSinglePrediction(x,\u001b[38;5;28mlen\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mlabel_to_index)), predicted)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "res = ddq_model.eval(dataset= test_dataset)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = ddq_model.predictOnDataset(dataset= test_dataset)\n",
    "preds = np.array(preds)[:,0]\n",
    "labels = list(map(lambda x : x[\"label\"], test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[(preds == -1)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BROWSERS': 0, 'P2P': 1, 'OTHER': 2, 'Skype': 3, 'MAIL': 4}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.label_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1796,    6,  302,  347,    6],\n",
       "       [  23, 2398,   17,    8,    8],\n",
       "       [ 501,   10, 1258,  209,   21],\n",
       "       [ 195,   12,   63, 1811,    3],\n",
       "       [  66,   13,   22,   16, 1113]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "confusion_matrix(y_true= labels,y_pred= preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.label_to_index\n",
    "index_to_label = {x:y for y,x in test_dataset.label_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(test_dataset.get_labels())\n",
    "unique_labels = np.unique(labels)\n",
    "res = ddq_model.predictOnDataset(test_dataset)\n",
    "res = np.array(res)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut_dct = dict()\n",
    "for label in unique_labels:\n",
    "    ut_dct[index_to_label[label]] =  res[labels == label].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'google-maps': 9.732919254658386,\n",
       " 'youtube': 11.95539033457249,\n",
       " 'instagram': 12.003968253968255,\n",
       " 'pinterest': 9.855371900826446,\n",
       " 'spotify': 11.63953488372093,\n",
       " 'facebook': 11.846456692913385,\n",
       " 'google-drive': 8.884146341463415,\n",
       " 'twitter': 10.19186046511628,\n",
       " 'netflix': 9.655581947743467,\n",
       " 'reddit': 11.238235294117647,\n",
       " 'hangout': 8.974025974025974,\n",
       " 'messenger': 12.655913978494624,\n",
       " 'gmail': 11.673684210526316}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ut_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "def getDataDct(dct):\n",
    "    X,y = [],[]\n",
    "    for key,value in dct.items():\n",
    "        X.append(key)\n",
    "        y.append(value)\n",
    "    return X,y\n",
    "# Sample data for 4 datasets, each containing classes and corresponding values\n",
    "class_data = {\n",
    "    'UTMobileNet-2021': ut_dct,\n",
    "    'VNAT': {'Streaming': 6.19, 'Control': 6.25, 'Chat': 6.05, 'FT': 7.07},\n",
    "    'UNIBS-2009': {'Mail': 9.75, 'Skype': 10.17, 'Browsers': 6.48, 'P2P': 7.28, 'Others': 8.62},\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "f, axes = plt.subplots(1, len(class_data), sharex='col', sharey='row', figsize=(15, 6),gridspec_kw={'width_ratios':[11,4,5]})\n",
    "\n",
    "for i,dataset in enumerate(class_data):\n",
    "    X,y = getDataDct(class_data[dataset])\n",
    "    axes[i].bar(X,y)\n",
    "    axes[i].set_title(dataset)\n",
    "    axes[i].tick_params(axis='x', rotation=70,labelsize = 11)\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel('Number of Packets')  # Set y-axis label\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.732919254658386"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[labels == 0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x765f801d4220>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(logger.getMetric(\"test_eval_f1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(np.array(logger.getMetric(metric_name= \"test_eval_f1\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.814477468839885"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.getMetric(metric_name= \"test_eval_time\")[64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9775886864813039"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.getMetric(metric_name= \"test_eval_f1\")[64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
