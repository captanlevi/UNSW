{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from flowprintOptimal.sekigo.core.flowConfig import FlowConfig\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from flowprintOptimal.sekigo.flowUtils.commons import loadFlows, saveFlows\n",
    "from flowprintOptimal.sekigo.flowUtils.sampler import FixedLengthSampler\n",
    "from flowprintOptimal.sekigo.core.flowRepresentation import FlowRepresentation\n",
    "from typing import List\n",
    "from flowprintOptimal.sekigo.flowUtils.flowDatasets import ActivityDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(nn.Module):\n",
    "    def __init__(self,lstm_input_size,lstm_hidden_size,num_classes,lr = .001):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size= lstm_input_size,hidden_size= lstm_hidden_size,batch_first= True)\n",
    "        self.linear = nn.Linear(in_features= lstm_hidden_size,out_features = num_classes)\n",
    "        self.softmax = nn.Softmax(dim= -1)\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(params= self.parameters(), lr= lr)\n",
    "        # TODO look at the projection size\n",
    "    \n",
    "    def forward(self,X):\n",
    "        \"\"\"\n",
    "        X is the timeseries input of shape \n",
    "        (BS,Seq len, lstm_input_size)\n",
    "\n",
    "        The output is of shape (BS,seq len,num_classes)\n",
    "        \"\"\"\n",
    "        lstm_out, _ = self.lstm(X)\n",
    "        return self.softmax(self.linear(lstm_out))\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def selectMaxAction(probs):\n",
    "        \"\"\"\n",
    "        probs is of shape (BS,num_actions)\n",
    "        \"\"\"\n",
    "        return torch.argmax(input= probs, dim= -1).to(\"cpu\").numpy()\n",
    "\n",
    "    @staticmethod\n",
    "    def sampleAction(probs):\n",
    "        \"\"\"\n",
    "        probs is of shape (BS,num_actions)\n",
    "        \"\"\"\n",
    "\n",
    "        return torch.multinomial(probs,1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSEnvironment:\n",
    "    def __init__(self,flow_config : FlowConfig,max_prediction_length_in_seconds,min_prediction_length_in_seconds):\n",
    "        self.flow_config = flow_config\n",
    "        # length 10 secs grain = .1\n",
    "        self.max_prediction_length = int(max_prediction_length_in_seconds/flow_config.grain)\n",
    "        self.min_prediction_length = int(min_prediction_length_in_seconds/flow_config.grain)\n",
    "\n",
    "        self.max_reward = 1\n",
    "        self.max_penalty = -1\n",
    "\n",
    "    def rewardFunction(self,predicted,target,prediction_length,num_classes):\n",
    "        \"\"\"\n",
    "        This is a vannila reward, but I have to take care of out od distrubation reward as well.\n",
    "        It returns reward and is ended flag\n",
    "        \"\"\"\n",
    "        if predicted == num_classes -1:\n",
    "            # this is a signal to wait\n",
    "            return 0,False\n",
    "        else:\n",
    "            if predicted == target:\n",
    "                return self.max_reward*(1 - (prediction_length - self.min_prediction_length)/(self.max_prediction_length - self.min_prediction_length)),True\n",
    "            else:\n",
    "                return self.max_penalty,True\n",
    "    \n",
    "    @staticmethod\n",
    "    def getFutureReturns(rewards,gamma = .99):\n",
    "        returns = [0]*len(rewards)\n",
    "        returns[-1] = rewards[-1]\n",
    "        for i in range(len(rewards)-2,-1,-1):\n",
    "            returns[i] = returns[i+1]*gamma + rewards[i]\n",
    "        \n",
    "        return returns\n",
    "\n",
    "    def generateEpisodesAndTrain(self,time_series : np.ndarray,targets : np.ndarray,agent : Agent):\n",
    "        \"\"\"\n",
    "        Here time_series is a single sample of shape\n",
    "        (BS,seq len, features)\n",
    "        target is of shape \n",
    "        (BS,1)\n",
    "        \"\"\"\n",
    "\n",
    "        def processSingleEpisode(probs : torch.Tensor,target):\n",
    "            \"\"\"\n",
    "            in this case probs is (seq len,num_classes)\n",
    "            As soon as we encounter a prediction we give the reward and terminate\n",
    "\n",
    "            target of shape (1)\n",
    "            \"\"\"\n",
    "            num_classes = probs.shape[1]\n",
    "            sampled_actions = Agent.sampleAction(probs= probs.clone().detach())  # sampled actions of shape (seq len, 1)\n",
    "            rewards = []\n",
    "            action_probs = []\n",
    "            for i in range(self.min_prediction_length,self.max_prediction_length + 1):\n",
    "                action = sampled_actions[i]\n",
    "                reward, is_ended = self.rewardFunction(predicted= action, target= target, num_classes= num_classes, prediction_length= i)\n",
    "\n",
    "                rewards.append(reward)\n",
    "                action_probs.append(probs[i,sampled_actions[i]])\n",
    "\n",
    "                if is_ended == True:\n",
    "                    break\n",
    "            \n",
    "            future_returns = TSEnvironment.getFutureReturns(rewards= rewards)\n",
    "            return action_probs,future_returns\n",
    "            \n",
    "\n",
    "\n",
    "        assert time_series.shape[1] >= self.min_prediction_length\n",
    "\n",
    "        series = torch.tensor(time_series).to(device)\n",
    "\n",
    "\n",
    "        probs = agent(series) # probs (BS,seq len, num_classes)\n",
    "\n",
    "        action_probs,future_returns = [],[]\n",
    "\n",
    "        for i in range(len(probs)):\n",
    "            action_probs_,future_returns_ = processSingleEpisode(probs= probs[i],target= targets[i])\n",
    "            action_probs.extend(action_probs_)\n",
    "            future_returns.extend(future_returns_)\n",
    "\n",
    "\n",
    "        action_probs = torch.cat(action_probs)\n",
    "        future_returns = torch.tensor(future_returns).to(device)\n",
    "\n",
    "        loss = -(torch.log(action_probs)*future_returns).mean()\n",
    "        \n",
    "        loss.backward()\n",
    "        agent.optimizer.step()\n",
    "        agent.optimizer.zero_grad()\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_config = FlowConfig(grain= 1,band_thresholds= [1250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_environ = TSEnvironment(flow_config= flow_config,max_prediction_length_in_seconds= 40, min_prediction_length_in_seconds= 5)\n",
    "agent = Agent(lstm_hidden_size= 10,lstm_input_size= 4,num_classes= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_environ.generateEpisodes(time_series= np.random.rand(64,20,4).astype(np.float32),targets= torch.zeros(64,1),agent= agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows = loadFlows(path= \"/Users/rushi/Desktop/UNSW/data/VNAT/flowStore/vnatflows1second.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "corrected_flows = FixedLengthSampler.sampleAndCutToLength(data= flows,flow_config= flows[0].flow_config,required_length_in_seconds= 40,max_cuts= 10, min_activity_for_start_point= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_dataset = ActivityDataset(flows= corrected_flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flow': array([[0.        , 0.25215995, 0.        , 0.11519994, 0.0959999 ,\n",
       "         0.        , 0.25386658, 0.        , 0.21631996, 0.15999998,\n",
       "         0.1378909 , 0.        , 0.        , 0.        , 0.1045333 ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.20036922, 0.13530872, 0.11825321, 0.32106664,\n",
       "         0.10879996, 0.23466665, 0.09599997, 0.09599998, 0.        ,\n",
       "         0.25874284, 0.10879996, 0.21270587, 0.09599995, 0.22399998,\n",
       "         0.        , 0.20479995, 0.1221703 , 0.11471304, 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.9594073 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.90725916, 0.89066637, 0.96533237,\n",
       "         0.        , 0.96533237, 0.        , 0.        , 0.        ,\n",
       "         0.96533285, 0.        , 0.95951506, 0.        , 0.96533237,\n",
       "         0.        , 0.        , 0.91911096, 0.        , 0.        ],\n",
       "        [0.        , 0.21119996, 0.        , 0.13439987, 0.0959999 ,\n",
       "         0.        , 0.1284923 , 0.        , 0.11306663, 0.17706664,\n",
       "         0.39039993, 0.        , 0.        , 0.        , 0.09599997,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.15999999, 0.29063083, 0.381952  , 0.1669818 ,\n",
       "         0.13695997, 0.14207999, 0.10879995, 0.10623998, 0.        ,\n",
       "         0.14613333, 0.16426661, 0.12254814, 0.09599995, 0.14186665,\n",
       "         0.        , 0.13439997, 0.35802353, 0.34965853, 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.96533301,\n",
       "         0.96533329, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.96481088, 0.9645977 , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.96465095, 0.96507527, 0.        ]]),\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset= activity_dataset, batch_size= 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4, 40])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
