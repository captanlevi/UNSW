{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from typing import List, Dict\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from flowprintOptimal.sekigo.core.flowRepresentation import FlowRepresentation,PacketFlowRepressentation\n",
    "from flowprintOptimal.sekigo.dataAnalysis.vNATDataFrameProcessor import VNATDataFrameProcessor\n",
    "from flowprintOptimal.sekigo.core.flowConfig import FlowConfig\n",
    "import random\n",
    "from flowprintOptimal.sekigo.flowUtils.flowDatasets import PacketFlowDataset\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from flowprintOptimal.sekigo.flowUtils.commons import normalizePacketRep\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "from flowprintOptimal.sekigo.flowUtils.commons import saveFlows,loadFlows\n",
    "from flowprintOptimal.sekigo.dataAnalysis.dataFrameProcessor import UTMobileNetProcessor\n",
    "from flowprintOptimal.sekigo.flowUtils.dataGetter import getTrainTestOOD\n",
    "from torch.functional import F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full class distrubation\n",
      "FT           16420\n",
      "control      13591\n",
      "streaming     1759\n",
      "chat          1244\n",
      "Name: count, dtype: int64\n",
      "post num packet filter class distrubation\n",
      "streaming    1265\n",
      "control       602\n",
      "chat          492\n",
      "FT            469\n",
      "Name: count, dtype: int64\n",
      "test class distrubation\n",
      "streaming    245\n",
      "control      127\n",
      "FT            96\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_flows,test_flows,ood_flows = getTrainTestOOD(dataset_name= \"VNAT\", packet_limit= 20, test_size= .2, ood_classes= [\"chat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PacketFlowDataset(flows= train_flows,label_to_index= None,do_aug= True)\n",
    "test_dataset = PacketFlowDataset(flows= test_flows,label_to_index= train_dataset.label_to_index)\n",
    "ood_dataset = PacketFlowDataset(flows= ood_flows, label_to_index= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[0.04      , 0.        , 1.        ],\n",
       "        [0.04      , 0.3473466 , 0.        ],\n",
       "        [0.03466667, 0.4152932 , 1.        ],\n",
       "        [0.19466667, 0.39307168, 1.        ],\n",
       "        [0.03466667, 0.34350683, 0.        ],\n",
       "        [0.06066667, 0.62350187, 0.        ],\n",
       "        [0.03466667, 0.4216397 , 1.        ],\n",
       "        [0.42733333, 0.54072109, 1.        ],\n",
       "        [0.176     , 0.71252412, 0.        ],\n",
       "        [0.07733333, 0.55736549, 1.        ],\n",
       "        [0.092     , 0.45822013, 1.        ],\n",
       "        [0.03466667, 0.36448998, 0.        ],\n",
       "        [0.38133333, 0.3634976 , 1.        ],\n",
       "        [0.91866667, 0.39373476, 1.        ],\n",
       "        [0.754     , 0.24807879, 1.        ],\n",
       "        [0.01205621, 0.33516189, 0.        ],\n",
       "        [0.04463436, 0.67703094, 0.        ],\n",
       "        [0.05533333, 0.68334745, 1.        ],\n",
       "        [0.05533333, 0.3473466 , 0.        ],\n",
       "        [0.91866667, 0.75948708, 0.        ]]),\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flowprintOptimal.sekigo.modeling.trainers import NNClassificationTrainer\n",
    "from flowprintOptimal.sekigo.modeling.neuralNetworks import LSTMNetwork,TransformerGenerator,CNNNetwork1D\n",
    "from flowprintOptimal.sekigo.modeling.loggers import Logger\n",
    "import torch\n",
    "#device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfClassificationTrainer(NNClassificationTrainer):\n",
    "    def __init__(self, classifier, device, logger: Logger):\n",
    "        super().__init__(classifier, device, logger)\n",
    "        self.nll_loss = nn.NLLLoss(reduction = \"none\")\n",
    "        self.bce_loss = nn.BCELoss(reduction = \"none\")\n",
    "        metric_steps = 100\n",
    "        self.logger.setMetricReportSteps(metric_name= \"train_loss\", step_size= metric_steps)\n",
    "        self.logger.setMetricReportSteps(metric_name= \"conf_loss\", step_size= metric_steps)\n",
    "        self.logger.setMetricReportSteps(metric_name= \"conf_value\", step_size= metric_steps)\n",
    "        self.logger.setMetricReportSteps(metric_name= \"conf_loss_weight\", step_size= metric_steps)\n",
    "        self.conf_loss_weight = 0\n",
    "        self.budget = .5\n",
    "\n",
    "\n",
    "    def preProcess(self,X,eps = .3):\n",
    "        X.requires_grad = True\n",
    "        _,conf_scores = self.classifier(X)\n",
    "        conf_scores = F.sigmoid(conf_scores)\n",
    "        loss = -torch.log(conf_scores + 1e-8).mean()\n",
    "        loss.backward()\n",
    "        grad = X.grad/torch.linalg.norm(X.grad)\n",
    "        X = X - grad*eps\n",
    "        X.required_grad = False\n",
    "        return X\n",
    "\n",
    "\n",
    "    \n",
    "    def trainStep(self, batch, classifier_optimizer):\n",
    "        X,y = batch[\"data\"].float().to(self.device), batch[\"label\"].to(self.device)\n",
    "        X = self.preProcess(X)\n",
    "        model_out,conf_scores = self.classifier(X)\n",
    "        # doing sigmoid on conf scores\n",
    "        model_out = F.softmax(model_out,dim= -1)\n",
    "        conf_scores = F.sigmoid(conf_scores)\n",
    "        conf_scores = torch.clamp(conf_scores,min= 1e-8, max= 1)\n",
    "        true_one_hots = F.one_hot(y,model_out.shape[-1])\n",
    "\n",
    "\n",
    "        classifier_optimizer.zero_grad()\n",
    "        conf_adjusted_model_out = conf_scores*model_out + (1- conf_scores)*true_one_hots\n",
    "\n",
    "        conf_loss = self.bce_loss(conf_scores,torch.ones_like(conf_scores)).mean()\n",
    "        classification_loss = self.nll_loss(torch.log(conf_adjusted_model_out + 1e-8),y).mean()\n",
    "\n",
    "        loss = classification_loss + conf_loss*self.conf_loss_weight\n",
    "        loss.backward()\n",
    "        classifier_optimizer.step()\n",
    "\n",
    "        self.logger.addMetric(metric_name= \"train_loss\", value= loss.cpu().item())\n",
    "        self.logger.addMetric(metric_name= \"conf_loss\", value= conf_loss.cpu().item())\n",
    "        self.logger.addMetric(metric_name= \"conf_value\", value= conf_scores.mean().cpu().item())\n",
    "        self.logger.addMetric(metric_name= \"conf_loss_weight\", value= self.conf_loss_weight)\n",
    "\n",
    "        if conf_loss.item() >= self.budget:\n",
    "            # if conf loss is more then conf is low so we increase the weight\n",
    "            self.conf_loss_weight += .1\n",
    "        else:\n",
    "            self.conf_loss_weight -= .1\n",
    "        self.conf_loss_weight = np.clip(self.conf_loss_weight,a_min= 0 , a_max= 1)\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification ---- 1 metric test_f1 = 0.22907900888265545\n",
      "classification ---- 1 metric test_accuracy = 0.5235042735042735\n",
      "classification ---- 1 metric train_accuracy = 0.5460385438972163\n",
      "classification ---- 1 metric train_f1 = 0.23545706371191136\n",
      "classification ---- 100 metric train_loss = 0.9582885217666626\n",
      "classification ---- 100 metric conf_loss = 0.6236006212234497\n",
      "classification ---- 100 metric conf_value = 0.5390512037277222\n",
      "classification ---- 100 metric conf_loss_weight = 0.795\n",
      "classification ---- 200 metric train_loss = 0.7530354642868042\n",
      "classification ---- 200 metric conf_loss = 0.5097833621501923\n",
      "classification ---- 200 metric conf_value = 0.6022334349155426\n",
      "classification ---- 200 metric conf_loss_weight = 0.61\n",
      "classification ---- 300 metric train_loss = 0.5123249210417271\n",
      "classification ---- 300 metric conf_loss = 0.475104578435421\n",
      "classification ---- 300 metric conf_value = 0.6247583073377609\n",
      "classification ---- 300 metric conf_loss_weight = 0.435\n",
      "classification ---- 400 metric train_loss = 0.43575928241014483\n",
      "classification ---- 400 metric conf_loss = 0.4929802122712135\n",
      "classification ---- 400 metric conf_value = 0.6208272308111191\n",
      "classification ---- 400 metric conf_loss_weight = 0.332\n",
      "classification ---- 500 metric train_loss = 0.45182533234357836\n",
      "classification ---- 500 metric conf_loss = 0.4888201731443405\n",
      "classification ---- 500 metric conf_value = 0.6303534108400345\n",
      "classification ---- 500 metric conf_loss_weight = 0.39099999999999996\n",
      "classification ---- 2 metric test_f1 = 0.5241614255765199\n",
      "classification ---- 2 metric test_accuracy = 0.7029914529914529\n",
      "classification ---- 600 metric train_loss = 0.41188872531056403\n",
      "classification ---- 600 metric conf_loss = 0.4918979617953301\n",
      "classification ---- 600 metric conf_value = 0.6297686302661896\n",
      "classification ---- 600 metric conf_loss_weight = 0.34300000000000014\n",
      "classification ---- 700 metric train_loss = 0.4190235851705074\n",
      "classification ---- 700 metric conf_loss = 0.4930726423859596\n",
      "classification ---- 700 metric conf_value = 0.6335332351922989\n",
      "classification ---- 700 metric conf_loss_weight = 0.36900000000000005\n",
      "classification ---- 800 metric train_loss = 0.4172531443834305\n",
      "classification ---- 800 metric conf_loss = 0.4894006875157356\n",
      "classification ---- 800 metric conf_value = 0.6371778893470764\n",
      "classification ---- 800 metric conf_loss_weight = 0.39000000000000007\n",
      "classification ---- 900 metric train_loss = 0.37418082311749457\n",
      "classification ---- 900 metric conf_loss = 0.49748010605573656\n",
      "classification ---- 900 metric conf_value = 0.6325111472606659\n",
      "classification ---- 900 metric conf_loss_weight = 0.30100000000000005\n",
      "classification ---- 1000 metric train_loss = 0.36417082384228705\n",
      "classification ---- 1000 metric conf_loss = 0.49557818412780763\n",
      "classification ---- 1000 metric conf_value = 0.6364633917808533\n",
      "classification ---- 1000 metric conf_loss_weight = 0.29900000000000004\n",
      "classification ---- 3 metric test_f1 = 0.5271516393442623\n",
      "classification ---- 3 metric test_accuracy = 0.717948717948718\n",
      "classification ---- 2 metric train_accuracy = 0.7210920770877944\n",
      "classification ---- 2 metric train_f1 = 0.5375136903059131\n",
      "classification ---- 1100 metric train_loss = 0.4302045625448227\n",
      "classification ---- 1100 metric conf_loss = 0.49710494101047514\n",
      "classification ---- 1100 metric conf_value = 0.6348659491539002\n",
      "classification ---- 1100 metric conf_loss_weight = 0.41100000000000014\n",
      "classification ---- 1200 metric train_loss = 0.35452044412493705\n",
      "classification ---- 1200 metric conf_loss = 0.49831353425979613\n",
      "classification ---- 1200 metric conf_value = 0.6354430359601975\n",
      "classification ---- 1200 metric conf_loss_weight = 0.28300000000000003\n",
      "classification ---- 1300 metric train_loss = 0.3323359878361225\n",
      "classification ---- 1300 metric conf_loss = 0.4933152803778648\n",
      "classification ---- 1300 metric conf_value = 0.6406126570701599\n",
      "classification ---- 1300 metric conf_loss_weight = 0.259\n",
      "classification ---- 1400 metric train_loss = 0.3725100360810757\n",
      "classification ---- 1400 metric conf_loss = 0.4972809043526649\n",
      "classification ---- 1400 metric conf_value = 0.6405066531896592\n",
      "classification ---- 1400 metric conf_loss_weight = 0.3360000000000001\n",
      "classification ---- 1500 metric train_loss = 0.39751452073454857\n",
      "classification ---- 1500 metric conf_loss = 0.4977338260412216\n",
      "classification ---- 1500 metric conf_value = 0.6395304065942764\n",
      "classification ---- 1500 metric conf_loss_weight = 0.3780000000000001\n",
      "classification ---- 4 metric test_f1 = 0.5726759838003606\n",
      "classification ---- 4 metric test_accuracy = 0.7905982905982906\n",
      "classification ---- 1600 metric train_loss = 0.3746194589138031\n",
      "classification ---- 1600 metric conf_loss = 0.49049299269914626\n",
      "classification ---- 1600 metric conf_value = 0.6445558506250382\n",
      "classification ---- 1600 metric conf_loss_weight = 0.3420000000000002\n",
      "classification ---- 1700 metric train_loss = 0.3792731000483036\n",
      "classification ---- 1700 metric conf_loss = 0.48946118652820586\n",
      "classification ---- 1700 metric conf_value = 0.645635005235672\n",
      "classification ---- 1700 metric conf_loss_weight = 0.3560000000000001\n",
      "classification ---- 1800 metric train_loss = 0.33531536638736725\n",
      "classification ---- 1800 metric conf_loss = 0.5006119349598884\n",
      "classification ---- 1800 metric conf_value = 0.6395006245374679\n",
      "classification ---- 1800 metric conf_loss_weight = 0.27\n",
      "classification ---- 1900 metric train_loss = 0.44860788598656653\n",
      "classification ---- 1900 metric conf_loss = 0.49794157534837724\n",
      "classification ---- 1900 metric conf_value = 0.6401478761434555\n",
      "classification ---- 1900 metric conf_loss_weight = 0.484\n",
      "classification ---- 2000 metric train_loss = 0.31582840979099275\n",
      "classification ---- 2000 metric conf_loss = 0.49394898742437365\n",
      "classification ---- 2000 metric conf_value = 0.6435637640953064\n",
      "classification ---- 2000 metric conf_loss_weight = 0.23500000000000007\n",
      "classification ---- 5 metric test_f1 = 0.6073238503513864\n",
      "classification ---- 5 metric test_accuracy = 0.7991452991452992\n",
      "classification ---- 3 metric train_accuracy = 0.791220556745182\n",
      "classification ---- 3 metric train_f1 = 0.5911671924426943\n",
      "classification ---- 2100 metric train_loss = 0.3908504992723465\n",
      "classification ---- 2100 metric conf_loss = 0.49431486666202545\n",
      "classification ---- 2100 metric conf_value = 0.6430688160657883\n",
      "classification ---- 2100 metric conf_loss_weight = 0.3760000000000001\n",
      "classification ---- 2200 metric train_loss = 0.3151989676058292\n",
      "classification ---- 2200 metric conf_loss = 0.4876467770338058\n",
      "classification ---- 2200 metric conf_value = 0.64947883695364\n",
      "classification ---- 2200 metric conf_loss_weight = 0.2500000000000001\n",
      "classification ---- 2300 metric train_loss = 0.3170645287632942\n",
      "classification ---- 2300 metric conf_loss = 0.49285554498434064\n",
      "classification ---- 2300 metric conf_value = 0.6467777764797211\n",
      "classification ---- 2300 metric conf_loss_weight = 0.2530000000000002\n",
      "classification ---- 2400 metric train_loss = 0.39117488205432893\n",
      "classification ---- 2400 metric conf_loss = 0.4925816041231155\n",
      "classification ---- 2400 metric conf_value = 0.6463213062286377\n",
      "classification ---- 2400 metric conf_loss_weight = 0.39400000000000013\n",
      "classification ---- 2500 metric train_loss = 0.3602566251158714\n",
      "classification ---- 2500 metric conf_loss = 0.5008688798546791\n",
      "classification ---- 2500 metric conf_value = 0.6408891385793686\n",
      "classification ---- 2500 metric conf_loss_weight = 0.32499999999999996\n",
      "classification ---- 6 metric test_f1 = 0.6068384214590848\n",
      "classification ---- 6 metric test_accuracy = 0.7970085470085471\n",
      "classification ---- 2600 metric train_loss = 0.40668194815516473\n",
      "classification ---- 2600 metric conf_loss = 0.48631836622953417\n",
      "classification ---- 2600 metric conf_value = 0.6487847745418549\n",
      "classification ---- 2600 metric conf_loss_weight = 0.41300000000000003\n",
      "classification ---- 2700 metric train_loss = 0.38886893004179\n",
      "classification ---- 2700 metric conf_loss = 0.48873516738414763\n",
      "classification ---- 2700 metric conf_value = 0.6494929170608521\n",
      "classification ---- 2700 metric conf_loss_weight = 0.3899999999999999\n",
      "classification ---- 2800 metric train_loss = 0.3523499895632267\n",
      "classification ---- 2800 metric conf_loss = 0.4917807194590569\n",
      "classification ---- 2800 metric conf_value = 0.6463132321834564\n",
      "classification ---- 2800 metric conf_loss_weight = 0.308\n",
      "classification ---- 2900 metric train_loss = 0.3192176778614521\n",
      "classification ---- 2900 metric conf_loss = 0.4877236208319664\n",
      "classification ---- 2900 metric conf_value = 0.6488104391098023\n",
      "classification ---- 2900 metric conf_loss_weight = 0.25099999999999995\n",
      "classification ---- 3000 metric train_loss = 0.3168842773139477\n",
      "classification ---- 3000 metric conf_loss = 0.48935953080654143\n",
      "classification ---- 3000 metric conf_value = 0.6498915553092957\n",
      "classification ---- 3000 metric conf_loss_weight = 0.2580000000000001\n",
      "classification ---- 7 metric test_f1 = 0.6082375847932378\n",
      "classification ---- 7 metric test_accuracy = 0.7991452991452992\n",
      "classification ---- 4 metric train_accuracy = 0.7965738758029979\n",
      "classification ---- 4 metric train_f1 = 0.6069331920918951\n",
      "classification ---- 3100 metric train_loss = 0.3802169206738472\n",
      "classification ---- 3100 metric conf_loss = 0.5071157625317574\n",
      "classification ---- 3100 metric conf_value = 0.6409074300527573\n",
      "classification ---- 3100 metric conf_loss_weight = 0.3729999999999999\n",
      "classification ---- 3200 metric train_loss = 0.24967286735773087\n",
      "classification ---- 3200 metric conf_loss = 0.5002968859672546\n",
      "classification ---- 3200 metric conf_value = 0.6437577480077743\n",
      "classification ---- 3200 metric conf_loss_weight = 0.1289999999999999\n",
      "classification ---- 3300 metric train_loss = 0.40127542659640314\n",
      "classification ---- 3300 metric conf_loss = 0.4987154969573021\n",
      "classification ---- 3300 metric conf_value = 0.6443266183137893\n",
      "classification ---- 3300 metric conf_loss_weight = 0.4130000000000004\n",
      "classification ---- 3400 metric train_loss = 0.3469511085748673\n",
      "classification ---- 3400 metric conf_loss = 0.4931245490908623\n",
      "classification ---- 3400 metric conf_value = 0.6461358392238616\n",
      "classification ---- 3400 metric conf_loss_weight = 0.3120000000000001\n",
      "classification ---- 3500 metric train_loss = 0.39113993287086485\n",
      "classification ---- 3500 metric conf_loss = 0.4965025332570076\n",
      "classification ---- 3500 metric conf_value = 0.6446375757455826\n",
      "classification ---- 3500 metric conf_loss_weight = 0.392\n",
      "classification ---- 8 metric test_f1 = 0.5356177277911329\n",
      "classification ---- 8 metric test_accuracy = 0.7243589743589743\n",
      "classification ---- 3600 metric train_loss = 0.35220963180065157\n",
      "classification ---- 3600 metric conf_loss = 0.49504382878541947\n",
      "classification ---- 3600 metric conf_value = 0.6456096291542053\n",
      "classification ---- 3600 metric conf_loss_weight = 0.31600000000000006\n",
      "classification ---- 3700 metric train_loss = 0.38272456496953966\n",
      "classification ---- 3700 metric conf_loss = 0.48540466248989106\n",
      "classification ---- 3700 metric conf_value = 0.6513048762083054\n",
      "classification ---- 3700 metric conf_loss_weight = 0.38599999999999995\n",
      "classification ---- 3800 metric train_loss = 0.3368669967353344\n",
      "classification ---- 3800 metric conf_loss = 0.49002467781305314\n",
      "classification ---- 3800 metric conf_value = 0.6477800852060318\n",
      "classification ---- 3800 metric conf_loss_weight = 0.2850000000000001\n",
      "classification ---- 3900 metric train_loss = 0.37336048677563666\n",
      "classification ---- 3900 metric conf_loss = 0.4902622428536415\n",
      "classification ---- 3900 metric conf_value = 0.6486040723323822\n",
      "classification ---- 3900 metric conf_loss_weight = 0.3699999999999999\n",
      "classification ---- 4000 metric train_loss = 0.2886181117594242\n",
      "classification ---- 4000 metric conf_loss = 0.4857097887992859\n",
      "classification ---- 4000 metric conf_value = 0.6514170515537262\n",
      "classification ---- 4000 metric conf_loss_weight = 0.19800000000000015\n",
      "classification ---- 9 metric test_f1 = 0.5337260928961749\n",
      "classification ---- 9 metric test_accuracy = 0.7222222222222222\n",
      "classification ---- 5 metric train_accuracy = 0.7425053533190579\n",
      "classification ---- 5 metric train_f1 = 0.5752972542931695\n",
      "classification ---- 4100 metric train_loss = 0.3516745676100254\n",
      "classification ---- 4100 metric conf_loss = 0.4971485149860382\n",
      "classification ---- 4100 metric conf_value = 0.6465601432323456\n",
      "classification ---- 4100 metric conf_loss_weight = 0.33\n",
      "classification ---- 4200 metric train_loss = 0.283539395108819\n",
      "classification ---- 4200 metric conf_loss = 0.4907432192564011\n",
      "classification ---- 4200 metric conf_value = 0.6510784256458283\n",
      "classification ---- 4200 metric conf_loss_weight = 0.20600000000000004\n",
      "classification ---- 4300 metric train_loss = 0.3877891838550568\n",
      "classification ---- 4300 metric conf_loss = 0.4965489688515663\n",
      "classification ---- 4300 metric conf_value = 0.6471864992380142\n",
      "classification ---- 4300 metric conf_loss_weight = 0.40100000000000013\n",
      "classification ---- 4400 metric train_loss = 0.3532005639374256\n",
      "classification ---- 4400 metric conf_loss = 0.4953034949302673\n",
      "classification ---- 4400 metric conf_value = 0.6458323103189468\n",
      "classification ---- 4400 metric conf_loss_weight = 0.32500000000000007\n",
      "classification ---- 4500 metric train_loss = 0.3409415166079998\n",
      "classification ---- 4500 metric conf_loss = 0.49096685320138933\n",
      "classification ---- 4500 metric conf_value = 0.6503388375043869\n",
      "classification ---- 4500 metric conf_loss_weight = 0.32\n",
      "classification ---- 10 metric test_f1 = 0.6117817780451847\n",
      "classification ---- 10 metric test_accuracy = 0.8055555555555556\n",
      "classification ---- 4600 metric train_loss = 0.3283515571057796\n",
      "classification ---- 4600 metric conf_loss = 0.49123686701059344\n",
      "classification ---- 4600 metric conf_value = 0.6498449891805649\n",
      "classification ---- 4600 metric conf_loss_weight = 0.28400000000000003\n",
      "classification ---- 4700 metric train_loss = 0.29655864417552946\n",
      "classification ---- 4700 metric conf_loss = 0.4931093680858612\n",
      "classification ---- 4700 metric conf_value = 0.6499875515699387\n",
      "classification ---- 4700 metric conf_loss_weight = 0.22699999999999998\n",
      "classification ---- 4800 metric train_loss = 0.3452681894600391\n",
      "classification ---- 4800 metric conf_loss = 0.5008615010976791\n",
      "classification ---- 4800 metric conf_value = 0.6454934316873551\n",
      "classification ---- 4800 metric conf_loss_weight = 0.32299999999999995\n",
      "classification ---- 4900 metric train_loss = 0.40562834575772283\n",
      "classification ---- 4900 metric conf_loss = 0.4867550474405289\n",
      "classification ---- 4900 metric conf_value = 0.6522322368621826\n",
      "classification ---- 4900 metric conf_loss_weight = 0.4359999999999999\n",
      "classification ---- 5000 metric train_loss = 0.3841962119936943\n",
      "classification ---- 5000 metric conf_loss = 0.48580223888158797\n",
      "classification ---- 5000 metric conf_value = 0.6507615709304809\n",
      "classification ---- 5000 metric conf_loss_weight = 0.3830000000000001\n",
      "classification ---- 11 metric test_f1 = 0.5420984014861416\n",
      "classification ---- 11 metric test_accuracy = 0.7286324786324786\n",
      "classification ---- 6 metric train_accuracy = 0.7451820128479657\n",
      "classification ---- 6 metric train_f1 = 0.5944212263097751\n",
      "classification ---- 5100 metric train_loss = 0.32823289930820465\n",
      "classification ---- 5100 metric conf_loss = 0.4918892538547516\n",
      "classification ---- 5100 metric conf_value = 0.647501677274704\n",
      "classification ---- 5100 metric conf_loss_weight = 0.273\n",
      "classification ---- 5200 metric train_loss = 0.34552481427788734\n",
      "classification ---- 5200 metric conf_loss = 0.4752569554746151\n",
      "classification ---- 5200 metric conf_value = 0.6564693433046341\n",
      "classification ---- 5200 metric conf_loss_weight = 0.31000000000000016\n",
      "classification ---- 5300 metric train_loss = 0.3469402547180653\n",
      "classification ---- 5300 metric conf_loss = 0.49186284869909286\n",
      "classification ---- 5300 metric conf_value = 0.6505570381879806\n",
      "classification ---- 5300 metric conf_loss_weight = 0.318\n",
      "classification ---- 5400 metric train_loss = 0.3400983170419931\n",
      "classification ---- 5400 metric conf_loss = 0.48586912482976913\n",
      "classification ---- 5400 metric conf_value = 0.6544516116380692\n",
      "classification ---- 5400 metric conf_loss_weight = 0.32899999999999996\n",
      "classification ---- 5500 metric train_loss = 0.34288171693682673\n",
      "classification ---- 5500 metric conf_loss = 0.49183419704437253\n",
      "classification ---- 5500 metric conf_value = 0.6487812405824661\n",
      "classification ---- 5500 metric conf_loss_weight = 0.306\n",
      "classification ---- 12 metric test_f1 = 0.6155379247717822\n",
      "classification ---- 12 metric test_accuracy = 0.8012820512820513\n",
      "classification ---- 5600 metric train_loss = 0.34011191338300706\n",
      "classification ---- 5600 metric conf_loss = 0.5006917586922646\n",
      "classification ---- 5600 metric conf_value = 0.6428355467319489\n",
      "classification ---- 5600 metric conf_loss_weight = 0.303\n",
      "classification ---- 5700 metric train_loss = 0.3168566928803921\n",
      "classification ---- 5700 metric conf_loss = 0.4845351979136467\n",
      "classification ---- 5700 metric conf_value = 0.6536272901296616\n",
      "classification ---- 5700 metric conf_loss_weight = 0.26700000000000007\n",
      "classification ---- 5800 metric train_loss = 0.3447535845637322\n",
      "classification ---- 5800 metric conf_loss = 0.4847002013027668\n",
      "classification ---- 5800 metric conf_value = 0.6529191046953201\n",
      "classification ---- 5800 metric conf_loss_weight = 0.3079999999999999\n",
      "classification ---- 5900 metric train_loss = 0.39357045382261274\n",
      "classification ---- 5900 metric conf_loss = 0.4856282356381416\n",
      "classification ---- 5900 metric conf_value = 0.6519996750354767\n",
      "classification ---- 5900 metric conf_loss_weight = 0.3929999999999999\n",
      "classification ---- 6000 metric train_loss = 0.25114910647273064\n",
      "classification ---- 6000 metric conf_loss = 0.49330289006233213\n",
      "classification ---- 6000 metric conf_value = 0.647619127035141\n",
      "classification ---- 6000 metric conf_loss_weight = 0.13299999999999998\n"
     ]
    }
   ],
   "source": [
    "classifier = CNNNetwork1D(in_channels= 3,num_filters= 32,num_layers= 3,output_dims= [len(train_dataset.label_to_index), 1])\n",
    "logger= Logger(name= \"classification\",verbose= True)\n",
    "logger.default_step_size = 500\n",
    "classification_trainer = ConfClassificationTrainer(classifier = classifier,device= device,logger= logger)\n",
    "classification_trainer.train(train_dataset= train_dataset,test_dataset= test_dataset,epochs=200,batch_size= 64,lr= .0001,use_balanced_sampler= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getConfScores(dataset,model):\n",
    "    model.eval()\n",
    "    confs = []\n",
    "    is_corrects = []\n",
    "    max_probs = []\n",
    "    loader = DataLoader(dataset,batch_size= 64)\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch in loader:\n",
    "            data,label = batch[\"data\"].float().to(device),batch[\"label\"].to(device)\n",
    "            model_out,batch_confs = model(data)\n",
    "\n",
    "            model_out = F.softmax(model_out, dim= -1)\n",
    "            batch_max_probs,batch_preds = torch.max(model_out,dim= -1)\n",
    "            max_probs.extend(batch_max_probs.cpu().numpy().tolist())\n",
    "            batch_is_corrects = label == batch_preds\n",
    "            is_corrects.extend(batch_is_corrects.cpu().numpy().tolist())\n",
    "            batch_confs = F.sigmoid(batch_confs[:,0]).cpu().numpy().tolist()\n",
    "            confs.extend(batch_confs)\n",
    "    \n",
    "    return np.array(confs),np.array(max_probs)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "confs,max_probs = getConfScores(dataset= train_dataset,model= classifier)\n",
    "ood_confs,ood_max_probs = getConfScores(dataset= ood_dataset,model= classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([200.,  20.,  31.,  17.,  23.,  31.,  37.,   4.,  18., 111.]),\n",
       " array([0.48343241, 0.53508627, 0.58674014, 0.638394  , 0.69004786,\n",
       "        0.74170172, 0.79335558, 0.84500945, 0.89666331, 0.94831717,\n",
       "        0.99997103]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(confs,alpha = .5)\n",
    "plt.hist(ood_confs,alpha = .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
