{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from typing import List, Dict\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from flowprintOptimal.sekigo.core.flowRepresentation import FlowRepresentation,PacketFlowRepressentation\n",
    "from flowprintOptimal.sekigo.dataAnalysis.vNATDataFrameProcessor import VNATDataFrameProcessor\n",
    "from flowprintOptimal.sekigo.core.flowConfig import FlowConfig\n",
    "import random\n",
    "from flowprintOptimal.sekigo.flowUtils.flowDatasets import PacketFlowDataset\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from flowprintOptimal.sekigo.flowUtils.commons import normalizePacketRep\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "from flowprintOptimal.sekigo.flowUtils.commons import saveFlows,loadFlows\n",
    "from flowprintOptimal.sekigo.dataAnalysis.dataFrameProcessor import UTMobileNetProcessor\n",
    "from flowprintOptimal.sekigo.flowUtils.dataGetter import getTrainTestOOD\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import json\n",
    "from flowprintOptimal.sekigo.modeling.trainers import NNClassificationTrainer\n",
    "from flowprintOptimal.sekigo.modeling.neuralNetworks import LSTMNetwork,TransformerGenerator,CNNNetwork1D\n",
    "from flowprintOptimal.sekigo.modeling.loggers import Logger\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "from flowprintOptimal.sekigo.earlyClassification.DQL.core import MemoryElement,Rewarder,State\n",
    "from flowprintOptimal.sekigo.earlyClassification.DQL.memoryFiller import MemoryFillerV2\n",
    "from flowprintOptimal.sekigo.earlyClassification.DQL.datasets import MemoryDataset\n",
    "from flowprintOptimal.sekigo.earlyClassification.DQL.trainers import EarlyClassificationtrainer\n",
    "from flowprintOptimal.sekigo.utils.documentor import Documenter\n",
    "from flowprintOptimal.sekigo.utils.evaluations import Evaluator,EarlyEvaluation,EarlyEvaluationV2\n",
    "import warnings\n",
    "from flowprintOptimal.sekigo.flowUtils.commons import dropPacketFromPacketRep\n",
    "from copy import deepcopy\n",
    "from flowprintOptimal.sekigo.flowUtils.flowDatasets import BaseFlowDataset\n",
    "warnings.filterwarnings('ignore')\n",
    "from focal_loss.focal_loss import FocalLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decider(nn.Module):\n",
    "    def __init__(self, in_dim) -> None:\n",
    "        super().__init__()\n",
    "        self.linear = nn.Sequential(nn.Linear(in_dim, in_dim//2), nn.ReLU(), nn.Linear(in_dim//2, in_dim//4), nn.ReLU(), nn.Linear(in_dim//4, 2))\n",
    "    def forward(self,X):\n",
    "        return self.linear(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = dict(\n",
    "    name = \"VNAT_no_sample_no_ood_samples\",\n",
    "    description = \"VNAT with OOD detection (no balancers used), no ood samples generated\",\n",
    "    \n",
    "    common_config = dict(\n",
    "        max_length = 15\n",
    "    ),\n",
    "    \n",
    "    full_model_kwargs = dict(\n",
    "        lstm_hidden_size = 256,\n",
    "        layers= 2, lstm_input_size = 3\n",
    "    ),\n",
    "\n",
    "    early_model_kwargs = dict(\n",
    "        lstm_input_size= 3,lstm_hidden_size= 256,layers = 2        \n",
    "    ),\n",
    "    \n",
    "    data_config = dict(\n",
    "        dataset_name = \"unibs\",\n",
    "        subsampleConfig = None,#dict(max_gap = 20, min_gap = 5),\n",
    "        max_flow_length = 80, # in seconds  ( each flow sample cannot excede this length)\n",
    "        test_size = .2,\n",
    "        ood_classes = [\"Skype\"],\n",
    "        do_balance = False\n",
    "\n",
    "    ),\n",
    "\n",
    "    rewarder_config = dict(\n",
    "        l = .5\n",
    "    ),\n",
    "\n",
    "    dataset_config = dict(\n",
    "        aug = [0,.2]\n",
    "    ),\n",
    "\n",
    "    memory_fillter_config = dict(\n",
    "        ood_config = dict(ood_aug = [.6,.9], ood_prob = .2),\n",
    "        min_length = 5,\n",
    "        use_balancer = False\n",
    "    ),\n",
    "    full_trainer_config = dict(\n",
    "        use_sampler = False\n",
    "    ),\n",
    "    early_trainer_config = dict(\n",
    "        use_sampler = False  # this is for giving more weight to wait samples\n",
    "    )\n",
    "\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full class distrubation\n",
      "BROWSERS    42855\n",
      "P2P         21514\n",
      "OTHER        5218\n",
      "MAIL         4521\n",
      "Skype        1280\n",
      "Name: count, dtype: int64\n",
      "using no sampling\n",
      "filtering max_flow_length = 80\n",
      "balancing\n",
      "keep_number = 1758\n",
      "post num packet filter class distrubation\n",
      "BROWSERS    1746\n",
      "MAIL        1717\n",
      "OTHER       1711\n",
      "P2P         1682\n",
      "Skype        894\n",
      "Name: count, dtype: int64\n",
      "------------------------------\n",
      "train class distrubation\n",
      "BROWSERS    1386\n",
      "MAIL        1380\n",
      "OTHER       1370\n",
      "P2P         1348\n",
      "Name: count, dtype: int64\n",
      "test class distrubation\n",
      "BROWSERS    360\n",
      "OTHER       341\n",
      "MAIL        337\n",
      "P2P         334\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_flows,test_flows,ood_flows = getTrainTestOOD(**configs[\"data_config\"], packet_limit= configs[\"common_config\"][\"max_length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PacketFlowDataset(flows= train_flows,label_to_index= None,aug= configs[\"dataset_config\"][\"aug\"])\n",
    "test_dataset = PacketFlowDataset(flows= test_flows,label_to_index= train_dataset.label_to_index)\n",
    "ood_dataset = PacketFlowDataset(flows= ood_flows, label_to_index= None) if (ood_flows != None and len(ood_flows) != 0) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(train_dataset.label_to_index)\n",
    "configs[\"full_model_kwargs\"][\"output_dim\"] = num_labels \n",
    "configs[\"early_model_kwargs\"][\"output_dim\"] = num_labels\n",
    "configs[\"rewarder_config\"][\"num_labels\"] = num_labels\n",
    "configs[\"rewarder_config\"][\"max_length\"] = configs[\"common_config\"][\"max_length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewarder = Rewarder(**configs[\"rewarder_config\"])\n",
    "memory_filler = MemoryFillerV2(dataset= train_dataset,rewarder= rewarder, min_length= configs[\"memory_fillter_config\"][\"min_length\"],\n",
    "                              max_length= rewarder.max_length,ood_config= configs[\"memory_fillter_config\"][\"ood_config\"], use_balancer= configs[\"memory_fillter_config\"][\"use_balancer\"]\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241296\n"
     ]
    }
   ],
   "source": [
    "memory = memory_filler.processDataset()\n",
    "print(len(memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyClassificationTrainerV2:\n",
    "    def __init__(self, decider ,predictor: LSTMNetwork, train_dataset: BaseFlowDataset, memory_dataset: MemoryDataset, hint_loss_alpha: float,\n",
    "                q_loss_alpha: float, hint_loss_gap: float, test_dataset: BaseFlowDataset, ood_dataset: BaseFlowDataset,\n",
    "                logger: Logger, model_replacement_steps: int, device: str):\n",
    "        self.device = device\n",
    "        self.predictor = predictor.to(device)\n",
    "        self.decider = decider.to(self.device)\n",
    "        self.lag_decider = deepcopy(decider).to(device)\n",
    "        self.lag_decider.eval()\n",
    "\n",
    "        self.hint_loss_alpha = hint_loss_alpha\n",
    "        self.q_loss_alpha = q_loss_alpha\n",
    "        self.hint_loss_gap = hint_loss_gap\n",
    "\n",
    "        self.train_dataset = train_dataset\n",
    "        self.memory_dataset = memory_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        self.ood_dataset = ood_dataset\n",
    "        self.logger = logger\n",
    "\n",
    "        self.best = dict(\n",
    "            score = 0,\n",
    "            predictor = deepcopy(self.predictor),\n",
    "            decider = deepcopy(self.decider)\n",
    "        )\n",
    "\n",
    "        self.evaluator = EarlyEvaluationV2(min_steps= memory_dataset.min_length, device= device,model= self.predictor, decider= self.decider)\n",
    "        self.mse_loss_function = nn.MSELoss(reduction= \"none\")\n",
    "        self.model_replacement_steps = model_replacement_steps\n",
    "\n",
    "        self.logger.setMetricReportSteps(metric_name= \"test_eval_f1\", step_size= 1)\n",
    "        self.logger.setMetricReportSteps(metric_name= \"train_eval_f1\", step_size= 1)\n",
    "        self.logger.setMetricReportSteps(metric_name= \"train_eval_time\", step_size= 1)\n",
    "        self.logger.setMetricReportSteps(metric_name= \"test_eval_time\", step_size= 1)\n",
    "        self.logger.setMetricReportSteps(metric_name= \"ood_eval\", step_size= 1)\n",
    "        self.logger.setMetricReportSteps(metric_name= \"ood_eval_time\", step_size= 1)\n",
    "        self.logger.setMetricReportSteps(metric_name= \"incorrect_ood_test\", step_size= 1)\n",
    "        self.logger.setMetricReportSteps(metric_name= \"incorrect_ood_train\", step_size= 1)\n",
    "        \n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss(reduction= \"none\")\n",
    "        self.focal_loss = FocalLoss(gamma= .7, reduction= \"none\")\n",
    "        self.softmax = nn.Softmax(dim= -1)\n",
    " \n",
    "\n",
    "    def __refreshLagModel(self):\n",
    "        self.lag_decider = deepcopy(self.decider)\n",
    "        self.lag_decider.eval()\n",
    "    \n",
    "\n",
    "\n",
    "    def eval(self,dataset : BaseFlowDataset):\n",
    "        metrices = self.evaluator.getMetrices(dataset= dataset,ood_dataset= None)\n",
    "        return metrices[\"macro_f1\"],metrices[\"time\"],metrices[\"incorrect_ood\"]\n",
    "    \n",
    "\n",
    "    def evalTrain(self):\n",
    "        f1,average_time,incorrect_ood = self.eval(dataset= self.train_dataset)\n",
    "        self.logger.addMetric(metric_name= \"train_eval_f1\", value= f1)\n",
    "        self.logger.addMetric(metric_name= \"train_eval_time\", value= average_time)\n",
    "        self.logger.addMetric(metric_name= \"incorrect_ood_train\", value = incorrect_ood)\n",
    "\n",
    "    def evalTest(self):\n",
    "        f1,average_time,incorrect_ood = self.eval(dataset= self.test_dataset)\n",
    "\n",
    "        if f1 >= self.best[\"score\"]:\n",
    "            self.best[\"score\"] = f1\n",
    "            self.best[\"predictor\"] = deepcopy(self.predictor)\n",
    "            self.best[\"decider\"] = deepcopy(self.decider)\n",
    "        \n",
    "        self.logger.addMetric(metric_name= \"test_eval_f1\", value= f1)\n",
    "        self.logger.addMetric(metric_name= \"test_eval_time\", value= average_time)\n",
    "        self.logger.addMetric(metric_name= \"incorrect_ood_test\", value= incorrect_ood)\n",
    "\n",
    "    def evalOOD(self):\n",
    "        metrices = self.evaluator.getMetrices(ood_dataset= self.ood_dataset, dataset= None)\n",
    "        self.logger.addMetric(metric_name= \"ood_eval\", value= metrices[\"ood_accuracy\"])\n",
    "        self.logger.addMetric(metric_name= \"ood_eval_time\", value= metrices[\"ood_time\"])\n",
    "\n",
    "\n",
    "    \n",
    "    def trainStep(self, steps, batch: dict, lam: float, predictor_optimizer, decider_optimizer):\n",
    "        state,next_state,action,reward,is_terminal = batch[\"state\"].to(self.device), batch[\"next_state\"].to(self.device),\\\n",
    "                                                    batch[\"action\"].to(self.device), batch[\"reward\"].to(self.device),batch[\"is_terminal\"].to(self.device)\n",
    "        \n",
    "        label, state_length = batch[\"label\"].to(self.device), batch[\"state_length\"].to(self.device)\n",
    "\n",
    "        predictor_state_output,predictor_state_features = self.predictor(state)\n",
    "        predicted_values = self.decider(predictor_state_features)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            next_state_max_actions_model = torch.argmax(self.decider(self.predictor(next_state)[1]),dim = -1,keepdim= True)\n",
    "            next_state_values_lag_model = self.lag_decider(self.predictor(next_state)[1])\n",
    "            next_state_values_for_max_action = torch.gather(input= next_state_values_lag_model, dim= 1, index= next_state_max_actions_model) # (BS,1)\n",
    "            next_state_values_for_max_action = next_state_values_for_max_action*(~(is_terminal.unsqueeze(-1)))\n",
    "\n",
    "\n",
    "            # calculate reward\n",
    "            predicted_classification = torch.argmax(predictor_state_output, dim= -1)\n",
    "            correct_classification = (predicted_classification == label)  # this covers ood as well\n",
    "            do_predict = (action == 1)\n",
    "            reward[(correct_classification & do_predict) ] = 1\n",
    "            reward[((~correct_classification) & do_predict)] = -1\n",
    "            reward[~do_predict] = -.1\n",
    "            \n",
    "\n",
    "\n",
    "            target = reward + lam*(next_state_values_for_max_action.squeeze()) # (BS)\n",
    "        \n",
    "        \n",
    "        predicted_values_for_taken_action = torch.gather(input= predicted_values, dim= 1,index= action.unsqueeze(-1)).squeeze() # (BS)\n",
    "        q_loss = self.mse_loss_function(target, predicted_values_for_taken_action).mean()\n",
    "        \n",
    "        #predicted_classification = torch.argmax(predictor_state_output, dim= -1)\n",
    "        #correct_classification = (predicted_classification == label)\n",
    "        #decider_labels = torch.zeros_like(label)\n",
    "        #decider_labels[correct_classification] = 1\n",
    "        #q_loss = self.focal_loss(self.softmax(predicted_values), decider_labels).mean()\n",
    "        #q_loss = self.cross_entropy_loss(predicted_values,decider_labels).mean()\n",
    "\n",
    "        ood_mask = torch.ones_like(label).float()\n",
    "        ood_mask[label == -1] = 0\n",
    "        label[label == -1] = 0 # dummy label\n",
    "        cross_entropy_loss = (self.cross_entropy_loss(predictor_state_output,label)*(state_length/self.memory_dataset.max_length)*ood_mask).mean()\n",
    "\n",
    "        loss = q_loss + cross_entropy_loss\n",
    "\n",
    "        self.logger.addMetric(metric_name= \"q_loss\", value= q_loss.item())\n",
    "        self.logger.addMetric(metric_name= \"cross_entropy_loss\", value= cross_entropy_loss.item())\n",
    "\n",
    "        decider_optimizer.zero_grad()\n",
    "        predictor_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        predictor_optimizer.step()\n",
    "        decider_optimizer.step()\n",
    "\n",
    "\n",
    "        if steps%self.model_replacement_steps == 0:\n",
    "            self.hint_memory = []\n",
    "            self.__refreshLagModel()\n",
    "        \n",
    "\n",
    "    def train(self,epochs : int,batch_size = 64,lr = .001,lam = .99):\n",
    "        # TODO add batch_sampler\n",
    "        \"\"\"\n",
    "        Can stress enough how important the shuffle == True is in the Dataloader\n",
    "        \"\"\"\n",
    "       \n",
    "        train_dataloader = DataLoader(dataset= self.memory_dataset, collate_fn= self.memory_dataset.collateFn, batch_size= batch_size,drop_last= True, shuffle= True)\n",
    "        predictor_optimizer = torch.optim.Adam(params= self.predictor.parameters(), lr = lr)\n",
    "        decider_optimizer = torch.optim.Adam(params= self.decider.parameters(), lr = lr)\n",
    "        steps = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for batch in train_dataloader:\n",
    "                self.trainStep(steps = steps,batch= batch,lam= lam, predictor_optimizer= predictor_optimizer, decider_optimizer= decider_optimizer)\n",
    "                steps += 1            \n",
    "\n",
    "                if steps%1000 == 0:\n",
    "                    self.evalTest()\n",
    "                    if self.ood_dataset != None:\n",
    "                        self.evalOOD()\n",
    "                if steps%2000 == 0:\n",
    "                    self.evalTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_dataset = MemoryDataset(memories= memory,num_classes= len(train_dataset.label_to_index),\n",
    "                               min_length= memory_filler.min_length,max_length= memory_filler.max_length)\n",
    "predictor = LSTMNetwork(**configs[\"early_model_kwargs\"])\n",
    "logger = Logger(verbose= True)\n",
    "logger.default_step_size = 1000\n",
    "decider = Decider(in_dim= configs[\"early_model_kwargs\"][\"lstm_hidden_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddq_model = EarlyClassificationTrainerV2(decider= decider,predictor= predictor,train_dataset = train_dataset,test_dataset= test_dataset,memory_dataset= memory_dataset,hint_loss_gap= .05,\n",
    "                                       ood_dataset= ood_dataset,hint_loss_alpha= 0,q_loss_alpha= 1,\n",
    "                                       logger= logger,device=device,model_replacement_steps= 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ---- 1000 metric q_loss = 0.41060874742269515\n",
      " ---- 1000 metric cross_entropy_loss = 0.6940028650164605\n",
      " ---- 1 metric test_eval_f1 = 0.42347371375009146\n",
      " ---- 1 metric test_eval_time = 6.330903790087463\n",
      " ---- 1 metric incorrect_ood_test = 0.021137026239067054\n",
      " ---- 1 metric ood_eval = 0.0\n",
      " ---- 1 metric ood_eval_time = 5.10178970917226\n",
      " ---- 2000 metric q_loss = 0.39067640374600887\n",
      " ---- 2000 metric cross_entropy_loss = 0.607127954185009\n",
      " ---- 2 metric test_eval_f1 = 0.5721010407426271\n",
      " ---- 2 metric test_eval_time = 7.004373177842566\n",
      " ---- 2 metric incorrect_ood_test = 0.0036443148688046646\n",
      " ---- 2 metric ood_eval = 0.0\n",
      " ---- 2 metric ood_eval_time = 10.980984340044742\n",
      " ---- 1 metric train_eval_f1 = 0.5342392939869054\n",
      " ---- 1 metric train_eval_time = 7.435083880379286\n",
      " ---- 1 metric incorrect_ood_train = 0.027169948942377828\n",
      " ---- 3000 metric q_loss = 0.38608128279447557\n",
      " ---- 3000 metric cross_entropy_loss = 0.5768830538988113\n",
      " ---- 3 metric test_eval_f1 = 0.7144037764397771\n",
      " ---- 3 metric test_eval_time = 6.1384839650145775\n",
      " ---- 3 metric incorrect_ood_test = 0.0\n",
      " ---- 3 metric ood_eval = 0.0\n",
      " ---- 3 metric ood_eval_time = 6.041387024608501\n",
      " ---- 4000 metric q_loss = 0.38420223408937454\n",
      " ---- 4000 metric cross_entropy_loss = 0.544868154257536\n",
      " ---- 4 metric test_eval_f1 = 0.6966866920287235\n",
      " ---- 4 metric test_eval_time = 5.566326530612245\n",
      " ---- 4 metric incorrect_ood_test = 0.0\n",
      " ---- 4 metric ood_eval = 0.0\n",
      " ---- 4 metric ood_eval_time = 5.2885906040268456\n",
      " ---- 2 metric train_eval_f1 = 0.6534670619202574\n",
      " ---- 2 metric train_eval_time = 5.542669584245076\n",
      " ---- 2 metric incorrect_ood_train = 0.0\n",
      " ---- 5000 metric q_loss = 0.38294431994855405\n",
      " ---- 5000 metric cross_entropy_loss = 0.5188849121630191\n",
      " ---- 5 metric test_eval_f1 = 0.5854274226497815\n",
      " ---- 5 metric test_eval_time = 5.948979591836735\n",
      " ---- 5 metric incorrect_ood_test = 0.0014577259475218659\n",
      " ---- 5 metric ood_eval = 0.0022371364653243847\n",
      " ---- 5 metric ood_eval_time = 6.318791946308725\n",
      " ---- 6000 metric q_loss = 0.3741679379492998\n",
      " ---- 6000 metric cross_entropy_loss = 0.49223834842443465\n",
      " ---- 6 metric test_eval_f1 = 0.7533026111474859\n",
      " ---- 6 metric test_eval_time = 5.408892128279883\n",
      " ---- 6 metric incorrect_ood_test = 0.0\n",
      " ---- 6 metric ood_eval = 0.0\n",
      " ---- 6 metric ood_eval_time = 5.251677852348993\n",
      " ---- 3 metric train_eval_f1 = 0.7161115148557262\n",
      " ---- 3 metric train_eval_time = 5.517505470459518\n",
      " ---- 3 metric incorrect_ood_train = 0.0\n",
      " ---- 7000 metric q_loss = 0.3670461476296186\n",
      " ---- 7000 metric cross_entropy_loss = 0.46297234135866167\n",
      " ---- 7 metric test_eval_f1 = 0.7865128214590333\n",
      " ---- 7 metric test_eval_time = 5.384839650145772\n",
      " ---- 7 metric incorrect_ood_test = 0.0\n",
      " ---- 7 metric ood_eval = 0.0\n",
      " ---- 7 metric ood_eval_time = 5.149888143176733\n",
      " ---- 8000 metric q_loss = 0.36138180759549143\n",
      " ---- 8000 metric cross_entropy_loss = 0.437185028642416\n",
      " ---- 8 metric test_eval_f1 = 0.808561115541872\n",
      " ---- 8 metric test_eval_time = 5.338921282798834\n",
      " ---- 8 metric incorrect_ood_test = 0.0\n",
      " ---- 8 metric ood_eval = 0.0\n",
      " ---- 8 metric ood_eval_time = 5.282997762863535\n",
      " ---- 4 metric train_eval_f1 = 0.756262039050472\n",
      " ---- 4 metric train_eval_time = 5.524799416484318\n",
      " ---- 4 metric incorrect_ood_train = 0.0\n",
      " ---- 9000 metric q_loss = 0.3468070280700922\n",
      " ---- 9000 metric cross_entropy_loss = 0.40901503878831863\n",
      " ---- 9 metric test_eval_f1 = 0.7992948154378249\n",
      " ---- 9 metric test_eval_time = 5.469387755102041\n",
      " ---- 9 metric incorrect_ood_test = 0.0\n",
      " ---- 9 metric ood_eval = 0.0\n",
      " ---- 9 metric ood_eval_time = 5.39821029082774\n",
      " ---- 10000 metric q_loss = 0.33534211464226243\n",
      " ---- 10000 metric cross_entropy_loss = 0.37661561773717406\n",
      " ---- 10 metric test_eval_f1 = 0.8371701544621111\n",
      " ---- 10 metric test_eval_time = 5.345481049562682\n",
      " ---- 10 metric incorrect_ood_test = 0.0\n",
      " ---- 10 metric ood_eval = 0.0\n",
      " ---- 10 metric ood_eval_time = 5.228187919463087\n",
      " ---- 5 metric train_eval_f1 = 0.7738946872875441\n",
      " ---- 5 metric train_eval_time = 5.439460247994165\n",
      " ---- 5 metric incorrect_ood_train = 0.0\n",
      " ---- 11000 metric q_loss = 0.321749605089426\n",
      " ---- 11000 metric cross_entropy_loss = 0.33798520201444626\n",
      " ---- 11 metric test_eval_f1 = 0.7906218707748062\n",
      " ---- 11 metric test_eval_time = 5.358600583090379\n",
      " ---- 11 metric incorrect_ood_test = 0.0\n",
      " ---- 11 metric ood_eval = 0.0\n",
      " ---- 11 metric ood_eval_time = 6.533557046979865\n",
      " ---- 12000 metric q_loss = 0.3021120285987854\n",
      " ---- 12000 metric cross_entropy_loss = 0.2935957209765911\n",
      " ---- 12 metric test_eval_f1 = 0.8486358834110023\n",
      " ---- 12 metric test_eval_time = 5.411807580174927\n",
      " ---- 12 metric incorrect_ood_test = 0.0\n",
      " ---- 12 metric ood_eval = 0.0\n",
      " ---- 12 metric ood_eval_time = 5.628635346756152\n",
      " ---- 6 metric train_eval_f1 = 0.6478272771562466\n",
      " ---- 6 metric train_eval_time = 5.765864332603939\n",
      " ---- 6 metric incorrect_ood_train = 0.0005470459518599562\n",
      " ---- 13000 metric q_loss = 0.2840212138146162\n",
      " ---- 13000 metric cross_entropy_loss = 0.24941899558901787\n",
      " ---- 13 metric test_eval_f1 = 0.8502744733134752\n",
      " ---- 13 metric test_eval_time = 6.336734693877551\n",
      " ---- 13 metric incorrect_ood_test = 0.0\n",
      " ---- 13 metric ood_eval = 0.0\n",
      " ---- 13 metric ood_eval_time = 6.1029082774049215\n",
      " ---- 14000 metric q_loss = 0.25587684984505177\n",
      " ---- 14000 metric cross_entropy_loss = 0.20309332406520844\n",
      " ---- 14 metric test_eval_f1 = 0.8672997069466049\n",
      " ---- 14 metric test_eval_time = 5.685131195335277\n",
      " ---- 14 metric incorrect_ood_test = 0.0\n",
      " ---- 14 metric ood_eval = 0.0\n",
      " ---- 14 metric ood_eval_time = 5.465324384787472\n",
      " ---- 7 metric train_eval_f1 = 0.6594724354679453\n",
      " ---- 7 metric train_eval_time = 5.968271334792123\n",
      " ---- 7 metric incorrect_ood_train = 0.00036469730123997083\n",
      " ---- 15000 metric q_loss = 0.23339801453799008\n",
      " ---- 15000 metric cross_entropy_loss = 0.16919399666786195\n",
      " ---- 15 metric test_eval_f1 = 0.8822162140936851\n",
      " ---- 15 metric test_eval_time = 6.266763848396502\n",
      " ---- 15 metric incorrect_ood_test = 0.0\n",
      " ---- 15 metric ood_eval = 0.0\n",
      " ---- 15 metric ood_eval_time = 5.694630872483222\n",
      " ---- 16000 metric q_loss = 0.20795950070023536\n",
      " ---- 16000 metric cross_entropy_loss = 0.14172897818684577\n",
      " ---- 16 metric test_eval_f1 = 0.8774174152350623\n",
      " ---- 16 metric test_eval_time = 6.3330903790087465\n",
      " ---- 16 metric incorrect_ood_test = 0.0\n",
      " ---- 16 metric ood_eval = 0.0\n",
      " ---- 16 metric ood_eval_time = 5.794183445190156\n",
      " ---- 8 metric train_eval_f1 = 0.6775625504822274\n",
      " ---- 8 metric train_eval_time = 6.726477024070022\n",
      " ---- 8 metric incorrect_ood_train = 0.002188183807439825\n",
      " ---- 17000 metric q_loss = 0.19223220546543598\n",
      " ---- 17000 metric cross_entropy_loss = 0.12544298259541392\n",
      " ---- 17 metric test_eval_f1 = 0.7093176037100045\n",
      " ---- 17 metric test_eval_time = 5.9074344023323615\n",
      " ---- 17 metric incorrect_ood_test = 0.0007288629737609329\n",
      " ---- 17 metric ood_eval = 0.0\n",
      " ---- 17 metric ood_eval_time = 6.008948545861298\n",
      " ---- 18000 metric q_loss = 0.17082144859433174\n",
      " ---- 18000 metric cross_entropy_loss = 0.11020913489162922\n",
      " ---- 18 metric test_eval_f1 = 0.7142847761746628\n",
      " ---- 18 metric test_eval_time = 7.060495626822157\n",
      " ---- 18 metric incorrect_ood_test = 0.0007288629737609329\n",
      " ---- 18 metric ood_eval = 0.0011185682326621924\n",
      " ---- 18 metric ood_eval_time = 6.895973154362416\n",
      " ---- 9 metric train_eval_f1 = 0.6814165933128824\n",
      " ---- 9 metric train_eval_time = 7.317833698030634\n",
      " ---- 9 metric incorrect_ood_train = 0.0020058351568198397\n",
      " ---- 19000 metric q_loss = 0.15964177522808312\n",
      " ---- 19000 metric cross_entropy_loss = 0.10347907757386565\n",
      " ---- 19 metric test_eval_f1 = 0.7181593733742404\n",
      " ---- 19 metric test_eval_time = 6.354227405247814\n",
      " ---- 19 metric incorrect_ood_test = 0.0014577259475218659\n",
      " ---- 19 metric ood_eval = 0.0011185682326621924\n",
      " ---- 19 metric ood_eval_time = 6.600671140939597\n",
      " ---- 20000 metric q_loss = 0.14908550008758903\n",
      " ---- 20000 metric cross_entropy_loss = 0.09541617159172892\n",
      " ---- 20 metric test_eval_f1 = 0.7129304828992519\n",
      " ---- 20 metric test_eval_time = 6.170553935860059\n",
      " ---- 20 metric incorrect_ood_test = 0.0007288629737609329\n",
      " ---- 20 metric ood_eval = 0.0\n",
      " ---- 20 metric ood_eval_time = 5.649888143176733\n",
      " ---- 10 metric train_eval_f1 = 0.6808054706401638\n",
      " ---- 10 metric train_eval_time = 6.4237782640408465\n",
      " ---- 10 metric incorrect_ood_train = 0.003464624361779723\n",
      " ---- 21000 metric q_loss = 0.13888696417212487\n",
      " ---- 21000 metric cross_entropy_loss = 0.09082004713267088\n",
      " ---- 21 metric test_eval_f1 = 0.6946418546221084\n",
      " ---- 21 metric test_eval_time = 5.744169096209912\n",
      " ---- 21 metric incorrect_ood_test = 0.0007288629737609329\n",
      " ---- 21 metric ood_eval = 0.0\n",
      " ---- 21 metric ood_eval_time = 5.491051454138702\n",
      " ---- 22000 metric q_loss = 0.13496143611520528\n",
      " ---- 22000 metric cross_entropy_loss = 0.08580266790091992\n",
      " ---- 22 metric test_eval_f1 = 0.8999005988602893\n",
      " ---- 22 metric test_eval_time = 6.389212827988338\n",
      " ---- 22 metric incorrect_ood_test = 0.0\n",
      " ---- 22 metric ood_eval = 0.0\n",
      " ---- 22 metric ood_eval_time = 5.586129753914989\n",
      " ---- 11 metric train_eval_f1 = 0.6766143331538879\n",
      " ---- 11 metric train_eval_time = 6.588986141502553\n",
      " ---- 11 metric incorrect_ood_train = 0.0023705324580598104\n",
      " ---- 23000 metric q_loss = 0.1250300747603178\n",
      " ---- 23000 metric cross_entropy_loss = 0.07839109018817544\n",
      " ---- 23 metric test_eval_f1 = 0.9110788290944842\n",
      " ---- 23 metric test_eval_time = 6.591107871720117\n",
      " ---- 23 metric incorrect_ood_test = 0.0\n",
      " ---- 23 metric ood_eval = 0.0011185682326621924\n",
      " ---- 23 metric ood_eval_time = 5.67337807606264\n",
      " ---- 24000 metric q_loss = 0.1242738107778132\n",
      " ---- 24000 metric cross_entropy_loss = 0.0789134862255305\n",
      " ---- 24 metric test_eval_f1 = 0.8868233382146401\n",
      " ---- 24 metric test_eval_time = 7.164723032069971\n",
      " ---- 24 metric incorrect_ood_test = 0.0\n",
      " ---- 24 metric ood_eval = 0.0022371364653243847\n",
      " ---- 24 metric ood_eval_time = 5.624161073825503\n",
      " ---- 12 metric train_eval_f1 = 0.676902662776004\n",
      " ---- 12 metric train_eval_time = 7.0262582056892775\n",
      " ---- 12 metric incorrect_ood_train = 0.0032822757111597373\n",
      " ---- 25000 metric q_loss = 0.11074501877930015\n",
      " ---- 25000 metric cross_entropy_loss = 0.0703552273325622\n",
      " ---- 25 metric test_eval_f1 = 0.7046530965253903\n",
      " ---- 25 metric test_eval_time = 6.324344023323615\n",
      " ---- 25 metric incorrect_ood_test = 0.0007288629737609329\n",
      " ---- 25 metric ood_eval = 0.0\n",
      " ---- 25 metric ood_eval_time = 5.87248322147651\n",
      " ---- 26000 metric q_loss = 0.11631346513703465\n",
      " ---- 26000 metric cross_entropy_loss = 0.0717481198515743\n",
      " ---- 26 metric test_eval_f1 = 0.7183186446176524\n",
      " ---- 26 metric test_eval_time = 6.910349854227405\n",
      " ---- 26 metric incorrect_ood_test = 0.0014577259475218659\n",
      " ---- 26 metric ood_eval = 0.0\n",
      " ---- 26 metric ood_eval_time = 5.638702460850112\n",
      " ---- 13 metric train_eval_f1 = 0.6825643318745656\n",
      " ---- 13 metric train_eval_time = 6.948212983223924\n",
      " ---- 13 metric incorrect_ood_train = 0.004741064916119621\n",
      " ---- 27000 metric q_loss = 0.10780576145462692\n",
      " ---- 27000 metric cross_entropy_loss = 0.06634308552928268\n",
      " ---- 27 metric test_eval_f1 = 0.9114232592350442\n",
      " ---- 27 metric test_eval_time = 6.283527696793003\n",
      " ---- 27 metric incorrect_ood_test = 0.0\n",
      " ---- 27 metric ood_eval = 0.0022371364653243847\n",
      " ---- 27 metric ood_eval_time = 5.655480984340045\n",
      " ---- 28000 metric q_loss = 0.10351965635828674\n",
      " ---- 28000 metric cross_entropy_loss = 0.06296327664330602\n",
      " ---- 28 metric test_eval_f1 = 0.7213261503058119\n",
      " ---- 28 metric test_eval_time = 6.205539358600583\n",
      " ---- 28 metric incorrect_ood_test = 0.0007288629737609329\n",
      " ---- 28 metric ood_eval = 0.0\n",
      " ---- 28 metric ood_eval_time = 5.46420581655481\n",
      " ---- 14 metric train_eval_f1 = 0.6834168964906088\n",
      " ---- 14 metric train_eval_time = 6.2490882567469\n",
      " ---- 14 metric incorrect_ood_train = 0.0018234865061998542\n",
      " ---- 29000 metric q_loss = 0.09948555635847152\n",
      " ---- 29000 metric cross_entropy_loss = 0.05965003818273544\n",
      " ---- 29 metric test_eval_f1 = 0.7191098758128914\n",
      " ---- 29 metric test_eval_time = 6.170553935860059\n",
      " ---- 29 metric incorrect_ood_test = 0.0007288629737609329\n",
      " ---- 29 metric ood_eval = 0.0011185682326621924\n",
      " ---- 29 metric ood_eval_time = 5.552572706935123\n",
      " ---- 30000 metric q_loss = 0.10162188195064664\n",
      " ---- 30000 metric cross_entropy_loss = 0.061511769756674765\n",
      " ---- 30 metric test_eval_f1 = 0.7205836434883417\n",
      " ---- 30 metric test_eval_time = 6.436588921282799\n",
      " ---- 30 metric incorrect_ood_test = 0.0007288629737609329\n",
      " ---- 30 metric ood_eval = 0.0011185682326621924\n",
      " ---- 30 metric ood_eval_time = 5.578299776286354\n",
      " ---- 15 metric train_eval_f1 = 0.6885709921918944\n",
      " ---- 15 metric train_eval_time = 6.512946754194019\n",
      " ---- 15 metric incorrect_ood_train = 0.005105762217359592\n",
      " ---- 31000 metric q_loss = 0.08883415207453071\n",
      " ---- 31000 metric cross_entropy_loss = 0.05476362269930542\n",
      " ---- 31 metric test_eval_f1 = 0.8975880537073342\n",
      " ---- 31 metric test_eval_time = 5.908892128279883\n",
      " ---- 31 metric incorrect_ood_test = 0.0\n",
      " ---- 31 metric ood_eval = 0.0\n",
      " ---- 31 metric ood_eval_time = 5.668903803131991\n",
      " ---- 32000 metric q_loss = 0.09607121734507382\n",
      " ---- 32000 metric cross_entropy_loss = 0.054331226555630566\n",
      " ---- 32 metric test_eval_f1 = 0.72247224284486\n",
      " ---- 32 metric test_eval_time = 6.269679300291545\n",
      " ---- 32 metric incorrect_ood_test = 0.0014577259475218659\n",
      " ---- 32 metric ood_eval = 0.0011185682326621924\n",
      " ---- 32 metric ood_eval_time = 5.768456375838926\n",
      " ---- 16 metric train_eval_f1 = 0.6865108020216144\n",
      " ---- 16 metric train_eval_time = 6.471918307804522\n",
      " ---- 16 metric incorrect_ood_train = 0.00437636761487965\n",
      " ---- 33000 metric q_loss = 0.08619958106987179\n",
      " ---- 33000 metric cross_entropy_loss = 0.051181891743093726\n",
      " ---- 33 metric test_eval_f1 = 0.8743229726957451\n",
      " ---- 33 metric test_eval_time = 5.606413994169096\n",
      " ---- 33 metric incorrect_ood_test = 0.0\n",
      " ---- 33 metric ood_eval = 0.0\n",
      " ---- 33 metric ood_eval_time = 5.530201342281879\n",
      " ---- 34000 metric q_loss = 0.0885140688046813\n",
      " ---- 34000 metric cross_entropy_loss = 0.04907044894900173\n",
      " ---- 34 metric test_eval_f1 = 0.8945500019617634\n",
      " ---- 34 metric test_eval_time = 5.69533527696793\n",
      " ---- 34 metric incorrect_ood_test = 0.0\n",
      " ---- 34 metric ood_eval = 0.0\n",
      " ---- 34 metric ood_eval_time = 5.272930648769575\n",
      " ---- 17 metric train_eval_f1 = 0.6822621081774811\n",
      " ---- 17 metric train_eval_time = 5.74507658643326\n",
      " ---- 17 metric incorrect_ood_train = 0.002552881108679796\n",
      " ---- 35000 metric q_loss = 0.08676690660789609\n",
      " ---- 35000 metric cross_entropy_loss = 0.05171737622097135\n",
      " ---- 35 metric test_eval_f1 = 0.7270899798266706\n",
      " ---- 35 metric test_eval_time = 6.11661807580175\n",
      " ---- 35 metric incorrect_ood_test = 0.0007288629737609329\n",
      " ---- 35 metric ood_eval = 0.0011185682326621924\n",
      " ---- 35 metric ood_eval_time = 5.636465324384788\n",
      " ---- 36000 metric q_loss = 0.08240605367999523\n",
      " ---- 36000 metric cross_entropy_loss = 0.047557993225753305\n",
      " ---- 36 metric test_eval_f1 = 0.901866482024551\n",
      " ---- 36 metric test_eval_time = 6.085276967930029\n",
      " ---- 36 metric incorrect_ood_test = 0.0\n",
      " ---- 36 metric ood_eval = 0.0\n",
      " ---- 36 metric ood_eval_time = 5.817673378076063\n",
      " ---- 18 metric train_eval_f1 = 0.6740959533115813\n",
      " ---- 18 metric train_eval_time = 6.080415754923414\n",
      " ---- 18 metric incorrect_ood_train = 0.004194018964259664\n",
      " ---- 37000 metric q_loss = 0.07469807534758001\n",
      " ---- 37000 metric cross_entropy_loss = 0.042323824861086906\n",
      " ---- 37 metric test_eval_f1 = 0.7101659092239554\n",
      " ---- 37 metric test_eval_time = 5.827259475218659\n",
      " ---- 37 metric incorrect_ood_test = 0.002186588921282799\n",
      " ---- 37 metric ood_eval = 0.0022371364653243847\n",
      " ---- 37 metric ood_eval_time = 5.353467561521253\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mddq_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlam\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.99\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 154\u001b[0m, in \u001b[0;36mEarlyClassificationTrainerV2.train\u001b[0;34m(self, epochs, batch_size, lr, lam)\u001b[0m\n\u001b[1;32m    151\u001b[0m steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainStep(steps \u001b[38;5;241m=\u001b[39m steps,batch\u001b[38;5;241m=\u001b[39m batch,lam\u001b[38;5;241m=\u001b[39m lam, predictor_optimizer\u001b[38;5;241m=\u001b[39m predictor_optimizer, decider_optimizer\u001b[38;5;241m=\u001b[39m decider_optimizer)\n\u001b[1;32m    156\u001b[0m         steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m            \n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/UNSW/flowprintOptimal/sekigo/earlyClassification/DQL/datasets.py:51\u001b[0m, in \u001b[0;36mMemoryDataset.collateFn\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     48\u001b[0m next_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x : torch\u001b[38;5;241m.\u001b[39mtensor(x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_state\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mfloat(), batch))\n\u001b[1;32m     50\u001b[0m state \u001b[38;5;241m=\u001b[39m pack_sequence(state,enforce_sorted\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 51\u001b[0m next_state \u001b[38;5;241m=\u001b[39m \u001b[43mpack_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43menforce_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m is_terminal \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x : x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_terminal\u001b[39m\u001b[38;5;124m\"\u001b[39m],batch)))\u001b[38;5;241m.\u001b[39mbool()\n\u001b[1;32m     55\u001b[0m reward \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x : x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m\"\u001b[39m],batch)))\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/utils/rnn.py:484\u001b[0m, in \u001b[0;36mpack_sequence\u001b[0;34m(sequences, enforce_sorted)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Packs a list of variable length Tensors.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \n\u001b[1;32m    454\u001b[0m \u001b[38;5;124;03mConsecutive call of the next functions: ``pad_sequence``, ``pack_padded_sequence``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;124;03m    a :class:`PackedSequence` object\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    483\u001b[0m lengths \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor([v\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m sequences])\n\u001b[0;32m--> 484\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_padded_sequence(\u001b[43mpad_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m)\u001b[49m, lengths, enforce_sorted\u001b[38;5;241m=\u001b[39menforce_sorted)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/utils/rnn.py:399\u001b[0m, in \u001b[0;36mpad_sequence\u001b[0;34m(sequences, batch_first, padding_value)\u001b[0m\n\u001b[1;32m    395\u001b[0m         sequences \u001b[38;5;241m=\u001b[39m sequences\u001b[38;5;241m.\u001b[39munbind(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# assuming trailing dimensions and type of all the Tensors\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;66;03m# in sequences are same and fetching those from sequences[0]\u001b[39;00m\n\u001b[0;32m--> 399\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_value\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ddq_model.train(epochs= 20, batch_size= 128, lr= 3e-4, lam= .99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = EarlyEvaluationV2(min_steps= 5, device = device, model = predictor, decider = decider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'micro_f1': 0.7592301355500637,\n",
       " 'macro_f1': 0.7644449466867931,\n",
       " 'accuracy': 0.7592301355500637,\n",
       " 'cm': array([[1299,   39,   65,  869,  276],\n",
       "        [  33, 3005,   25,   36,   27],\n",
       "        [  62,   22, 1320,   79,   25],\n",
       "        [ 415,   34,   46, 2172,  493],\n",
       "        [ 150,   22,   15,  482, 2342]]),\n",
       " 'incorrect_ood': 0.0,\n",
       " 'time': 5.061184752490077}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.getMetrices(dataset= test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
